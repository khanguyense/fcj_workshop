[{"uri":"https://khanguyense.github.io/fcj_workshop/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Tuấn Kha\nSố điện thoại: 0835173787\nEmail: khantse183212@fpt.edu.vn\nTrường: Đại học FPT cơ sở Hồ Chí Minh\nNgành: Kĩ thuật phần mềm\nLớp: AWS092025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 06/09/2025 đến ngày 9/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.12-week12/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản (Cloud Fundamentals, IAM, Budget, Support).\nTuần 2: Học VPC cơ bản và các kiến thức networking nền tảng.\nTuần 3: Nâng cao EC2 trong VPC, NAT Gateway, Security Group, DNS Resolver.\nTuần 4: VPC Peering, Transit Gateway và kết nối phức tạp giữa VPC.\nTuần 5: Compute Services: EC2, Auto Scaling, Backup và Storage Gateway.\nTuần 6: Storage nâng cao: S3, Glacier, FSx và Storage Gateway.\nTuần 7: IAM nâng cao, AWS Organizations, Identity Center, KMS.\nTuần 8: Database Services, ETL (Kinesis/Glue/Athena), DMS Migration.\nTuần 9: Workshop – Thiết kế kiến trúc hệ thống trên AWS (Architecture Design).\nTuần 10: Workshop – Xây dựng Database + Backend + Frontend.\nTuần 11: Workshop – Hoàn thiện FE + Deploy toàn bộ hệ thống.\nTuần 12: Workshop – Kiểm tra, test, tối ưu \u0026amp; viết báo cáo tổng hợp.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản (Cloud Fundamentals, IAM, Budget, Support).\nTuần 2: Học VPC cơ bản và các kiến thức networking nền tảng.\nTuần 3: Nâng cao EC2 trong VPC, NAT Gateway, Security Group, DNS Resolver.\nTuần 4: VPC Peering, Transit Gateway và kết nối phức tạp giữa VPC.\nTuần 5: Compute Services: EC2, Auto Scaling, Backup và Storage Gateway.\nTuần 6: Storage nâng cao: S3, Glacier, FSx và Storage Gateway.\nTuần 7: IAM nâng cao, AWS Organizations, Identity Center, KMS.\nTuần 8: Database Services, ETL (Kinesis/Glue/Athena), DMS Migration.\nTuần 9: Workshop – Thiết kế kiến trúc hệ thống trên AWS (Architecture Design).\nTuần 10: Workshop – Xây dựng Database + Backend + Frontend.\nTuần 11: Workshop – Hoàn thiện FE + Deploy toàn bộ hệ thống.\nTuần 12: Workshop – Kiểm tra, test, tối ưu \u0026amp; viết báo cáo tổng hợp.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Nâng cao hiệu quả đào tạo phân tích bộ gen vi khuẩn với Amazon WorkSpaces\nTác giả: Satsawat Natakarnkitkul, Charlie Lee, và Sikharin Kongpaiboon\nNgày đăng: ngày 04 tháng 04 năm 2025|\nDanh mục: Amazon WorkSpaces, Education, Healthcare, Higher education, Public Sector | Permalink|\nCác hội thảo phân tích bộ gen vi khuẩn yêu cầu các công cụ bioinformatics chuyên biệt và sức mạnh tính toán lớn để xử lý dữ liệu giải trình tự. Khi Trung tâm Nghiên cứu Y khoa Siriraj lên kế hoạch tổ chức “Hội thảo Nanopore: chuỗi hội thảo tin sinh học về bộ gen vi khuẩn” cho hơn 60 nhà nghiên cứu, họ đã gặp phải thách thức phổ biến: làm thế nào để cung cấp môi trường tính toán hiệu suất cao, đồng nhất cho các phân tích bộ gen phức tạp. Amazon Web Services (AWS) đã giải quyết vấn đề này thông qua Amazon WorkSpaces, thay đổi cách Trung tâm Nghiên cứu Y khoa Siriraj cung cấp đào tạo thực hành về bộ gen vi khuẩn.\nBạn có thể sử dụng Amazon WorkSpaces để cấp phát các máy tính để bàn ảo trên nền tảng đám mây, gọi là WorkSpaces, cho người dùng của mình. Những máy tính để bàn này có thể chạy Microsoft Windows, Amazon Linux 2, Ubuntu Linux, Rocky Linux hoặc Red Hat Enterprise Linux. WorkSpaces loại bỏ nhu cầu mua sắm và triển khai phần cứng hoặc cài đặt phần mềm phức tạp. Bạn có thể nhanh chóng thêm hoặc bớt người dùng khi nhu cầu thay đổi. Người dùng có thể truy cập máy tính để bàn ảo của mình từ nhiều thiết bị hoặc trình duyệt web khác nhau. Với những lợi ích này, người dùng có thể làm việc hiệu quả mà không cần phải lo lắng về máy tính để bàn của họ.\nThách thức Các hội thảo đào tạo về bộ gen vi khuẩn do Trung tâm Nghiên cứu Y khoa Siriraj tổ chức thường gặp phải nhiều khó khăn tài nguyên tính toán, cài đặt phần mềm, cũng như khả năng tiếp cận và mở rộng cơ sở hạ tầng.\nMột trong những thách thức lớn nhất là sự khác biệt về cấu hình phần cứng giữa các học viên. Nhiều người dùng phải sử dụng laptop cá nhân với hệ điều hành, tốc độ xử lý, bộ nhớ khác nhau, dẫn đến hiệu suất không đồng đều. Sự khác biệt này thường gây ra lỗi hệ thống, tốc độ xử lý chậm và không thể chạy các phân tích genome đòi hỏi tài nguyên lớn hiệu quả.\nViệc cài đặt và cấu hình phần mềm là trở ngại chính. Các công cụ bioinformatics như EPI2ME, phổ biến trong việc lắp ráp và phân tích bộ gen vi khuẩn, yêu cầu các gói phụ thuộc (dependencies) và cấu hình đặc thù. Đảm bảo tương thích trên nhiều thiết bị khác nhau thường làm gián đoạn tiến độ, khiến giảng viên mất thời gian xử lý sự cố thay vì tập trung vào thực hành.\nXử lý dữ liệu bộ gen vi khuẩn cần máy tính mạnh mà phần đông học viên không có sẵn. Thiếu tài nguyên tính toán dẫn đến việc không hoàn thành bài tập, gây thất vọng và làm giảm hiệu quả học tập. Laptop cá nhân thường không đủ khả năng xử lý các phép tính phức tạp trong phân tích dữ liệu DNA, làm hạn chế việc thực hành.\nPhương pháp giảng dạy truyền thống cũng giới hạn số lượng học viên mà tổ chức có thể đào tạo. Nhiều tổ chức thiếu cơ sở hạ tầng cần thiết để đáp ứng nhu cầu đào tạo ngày càng tăng, đặc biệt cho các buổi đào tạo kết hợp hoặc trực tuyến.\nXây dựng môi trường học tập trên nền tảng đám mây Oxford Nanopore Centre of Excellence (Thái Lan), Yip In Tsoi ( Đối tác AWS) và AWS đã phối hợp khởi xướng và tổ chức một hội thảo nhằm giải quyết những thách thức cấp bách này trong đào tạo tin sinh học, đặc biệt liên quan đến giới hạn phần cứng, vấn đề tương thích phần mềm, và sức mạnh tính toán. Hội thảo hợp tác này sử dụng WorkSpaces như một môi trường tính toán tập trung trên đám mây cho tất cả học viên, cung cấp một môi trường học tập tiêu chuẩn trên đám mây. WorkSpaces là dịch vụ máy tính để bàn ảo được quản lý toàn phần, cung cấp tài nguyên tính toán đã được cấu hình sẵn, giúp đảm bảo mọi học viên có cùng môi trường làm việc.\nMột trong những lợi ích chính của WorkSpaces là loại bỏ sự trì hoãn do cài đặt và cấu hình phần mềm. Tất cả các công cụ bioinformatics cần thiết cho hội thảo—bao gồm EPI2ME—đã được cài đặt sẵn và tối ưu, giúp học viên bắt đầu thực hành ngay lập tức.\nSức mạnh tính toán của WorkSpaces đóng vai trò quan trọng nâng cao trải nghiệm hội thảo. Nhờ truy cập nguồn tài nguyên đám mây mạnh mẽ, học viên có thể thực hiện lắp ráp bộ gen, căn chỉnh trình tự, và phân tích so sánh genome mà không gặp giới hạn về hiệu suất. Sự đồng đều trong tài nguyên tính toán giúp mọi học viên hoàn thành bài tập cùng tiến độ, tạo môi trường học tập hiệu quả hơn.\nKhả năng mở rộng và tiếp cận cũng là điểm mạnh của WorkSpaces. Học viên có thể đăng nhập WorkSpaces từ bất kỳ thiết bị nào, loại bỏ giới hạn về địa lý và phần cứng. Tính linh hoạt của WorkSpaces cũng giúp tổ chức dễ dàng đáp ứng số lượng học viên lớn mà không phải lo lắng về hạ tầng tính toán.\nKết quả hội thảo Trong ba ngày hội thảo, WorkSpaces được sử dụng rộng rãi. Học viên tham gia các bài tập như giải trình tự bằng công nghệ Oxford Nanopore (ONT), lắp ráp bộ gen bằng EPI2ME, và phân tích so sánh bộ gen gồm cgMLST và nghiên cứu ổ dịch.\nViệc triển khai WorkSpaces giúp hội thảo diễn ra suôn sẻ mà không gặp khó khăn kỹ thuật, cải thiện đáng kể so với các lần trước khi việc cài đặt và khắc phục lỗi có thể mất đến 3 giờ đồng hồ. Hiệu suất tính toán được giữ ổn định, giúp học viên tập trung phân tích dữ liệu thay vì gặp sự cố hoặc xử lý chậm.\nPhản hồi từ học viên cho thấy WorkSpaces đã giúp nâng cao hiệu quả đào tạo tin sinh học. Nhiều học viên cho biết môi trường tính toán tiêu chuẩn giúp họ tập trung vào nội dung học mà không phải lo ngại về hạn chế phần cứng hay lỗi phần mềm. Giảng viên cũng nhận thấy hiệu quả giảng dạy được cải thiện rõ rệt khi không phải mất thời gian xử lý các vấn đề kỹ thuật.\nTương lai phát triển Việc tích hợp thành công WorkSpaces với hội thảo Nanopore cho thấy công nghệ đám mây có thể thay đổi cách đào tạo. Bởi vì các rào cản công nghệ truyền thống đã được loại bỏ, học viên có thể tập trung hơn vào phân tích bộ gen vi khuẩn.\nTrong tương lai, có tiềm năng mở rộng sử dụng WorkSpaces trong các chương trình đào tạo genomics khác—đặc biệt là các dự án quy mô lớn—như:\nNâng cao khả năng phân tích bộ gen với AWS HealthOmics Xử lý và phân tích bộ dữ liệu lớn với AWS Batch Tự động hóa quy trình phân tích genome với AWS Lambda Những giải pháp này có thể cải thiện hơn nữa giáo dục tin sinh học bằng cách tối ưu hóa quy trình phân tích dữ liệu. Các tổ chức cũng đang nghiên cứu tích hợp WorkSpaces vào các mô hình học từ xa, giúp mở rộng sự tham gia của sinh viên và nhà nghiên cứu trên toàn cầu.\nĐể tìm hiểu thêm và bắt đầu, hãy liên hệ với nhóm tài khoản AWS của bạn hoặc nhóm hỗ trợ AWS Public Sector team.\nTài nguyên bổ sung Genomics on AWS Amazon WorkSpaces Documentation Siriraj Long-read Lab (Si-LoL), Oxford Nanopore Centre of Excellence (Thailand) Được đồng viết bởi Oxford Nanopore Centre of Excellence (Thailand), YIP In Tsoi (Đối tác AWS), và AWS.\nTAGS : Amazon Workspaces,AWS education,AWS for higher education,AWS healthcare, genomics, healthcare\nTác giả: Satsawat Natakarnkitkul: Trưởng nhóm dữ liệu và AI cho khu vực ASEAN tại AWS Thái Lan, dẫn dắt các sáng kiến AI tạo sinh trên khắp Đông Nam Á. Với hơn một thập kỷ kinh nghiệm trong chuyển đổi số và các giải pháp AI/ML, ông là chuyên gia đầu ngành trong trí tuệ nhân tạo, khoa học dữ liệu, và kiến trúc đám mây. Ông thường xuyên phát biểu tại các sự kiện công nghệ khu vực ASEAN, và nhiệt huyết sử dụng công nghệ mới như AI tạo sinh để tạo giá trị thực tế trong khu vực công.\nCharlie Lee: Chuyên gia hàng đầu về ngành genomics khu vực châu Á - Thái Bình Dương và Nhật Bản của AWS, có bằng tiến sĩ khoa học máy tính chuyên sâu về tin sinh học. Ông là nhà lãnh đạo trong lĩnh vực tin sinh học, genomics, và chẩn đoán phân tử, đam mê thúc đẩy nghiên cứu và cải thiện chăm sóc sức khỏe qua genomics với các công nghệ giải trình tự tiên tiến và điện toán đám mây.\nSikharin Kongpaiboon: Kiến trúc sư giải pháp tại AWS, hỗ trợ khách hàng hiểu và áp dụng tốt nhất các giải pháp đám mây, tối ưu triển khai. Ông phối hợp chặt chẽ với khách hàng để thiết kế kiến trúc đám mây có khả năng mở rộng, linh hoạt, và chịu lỗi cao, giúp giải quyết các thách thức kinh doanh và tăng tính nhanh nhẹn, hiệu quả, và an toàn.\nCác tài nguyên: AWS in the Public Sector\nAWS for Government\nAWS for Education\nAWS for Nonprofits\nAWS for Public Sector Health\nAWS for Aerospace and Satellite Solutions\nCase Studies\nFix This Podcast\nAdditional Resources\nContact Us\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng cường deployment guardrails với tính năng rolling update cho inference component trên Amazon SageMaker AI inference\nBài viết này có đồng tác giả là : Melanie Li, Andrew Smith, Dustin Liu, Vivek Gangasani, Shikhar Mishra, và June Won\nNgày: 25 tháng 3, 2025 | in Amazon SageMaker, Amazon SageMaker AI, Intermediate (200) Permalink | Comments | Share\nTriển khai các mô hình một cách hiệu quả, tin cậy và tiết kiệm chi phí là một thách thức quan trọng đối với các tổ chức ở mọi quy mô. Khi ngày càng nhiều tổ chức triển khai các foundation model (FM) và các mô hình machine learning (ML) khác vào môi trường production, họ phải đối mặt với những thách thức liên quan đến việc tận dụng tài nguyên, hiệu quả chi phí và duy trì tính khả dụng cao trong quá trình cập nhật. Amazon SageMaker AI đã giới thiệu chức năng inference component có thể giúp các tổ chức giảm chi phí triển khai mô hình bằng cách tối ưu hóa việc sử dụng tài nguyên thông qua khả năng đóng gói và mở rộng mô hình thông minh. Inference component trừu tượng hóa các mô hình ML và cho phép phân bổ tài nguyên chuyên dụng cũng như các chính sách mở rộng cụ thể cho từng mô hình.\nTuy nhiên, việc cập nhật các mô hình này—đặc biệt trong môi trường production với các SLA về độ trễ nghiêm ngặt—về mặt lịch sử có nguy cơ gây downtime hoặc tắc nghẽn tài nguyên. Các triển khai blue/green truyền thống thường gặp khó khăn với những hạn chế về năng lực, khiến việc cập nhật trở nên khó dự đoán đối với các mô hình sử dụng GPU nặng. Để giải quyết vấn đề này, chúng tôi rất vui mừng công bố một cải tiến mạnh mẽ khác cho RageMaker AI:tính năng rolling update cho inference component endpoint, một tính năng được thiết kế để đơn giản hóa việc cập nhật cho các mô hình có kích thước khác nhau đồng thời giảm thiểu chi phí vận hành.\nTrong bài viết này, chúng tôi thảo luận về những thách thức mà các tổ chức phải đối mặt khi cập nhật mô hình trong production. Sau đó, chúng tôi đi sâu vào tính năng rolling update mới cho inference component và cung cấp các ví dụ thực tế sử dụng các mô hình DeepSeek distilled để minh họa tính năng này. Cuối cùng, chúng tôi khám phá cách thiết lập rolling update trong các tình huống khác nhau.\nNhững thách thức với triển khai blue/green Theo truyền thống, RageMaker AI inference đã hỗ trợ mô hình triển khai blue/green để cập nhật inference component trong production. Mặc dù có hiệu quả trong nhiều tình huống, cách tiếp cận này đi kèm với những thách thức cụ thể:\nKém hiệu quả về tài nguyên – Triển khai blue/green yêu cầu cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Đối với các inference component chạy trên các GPU instance đắt tiền như P4d hoặc G5, điều này có nghĩa là có khả năng tăng gấp đôi yêu cầu tài nguyên trong quá trình triển khai. Hãy xem xét một ví dụ trong đó khách hàng có 10 bản sao của một inference component phân bố trên 5 instance ml.p4d.24xlarge, tất cả đều hoạt động với công suất đầy đủ. Với triển khai blue/green, SageMaker AI sẽ cần cung cấp thêm năm instance ml.p4d.24xlarge để lưu trữ phiên bản mới của inference component trước khi chuyển đổi lưu lượng và ngừng sử dụng các instance cũ. Tài nguyên tính toán hạn chế – Đối với khách hàng sử dụng các GPU instance mạnh mẽ như dòng P hoặc G, năng lực cần thiết có thể không có sẵn trong một Availability Zone hoặc Region nhất định. Điều này thường dẫn đến các ngoại lệ về năng lực instance trong quá trình triển khai, gây ra lỗi cập nhật và rollback. Chuyển đổi theo kiểu tất cả hoặc không có gì – Các triển khai blue/green truyền thống chuyển toàn bộ lưu lượng cùng một lúc hoặc dựa trên lịch trình được cấu hình. Điều này để lại không gian hạn chế cho việc xác thực dần dần và tăng phạm vi ảnh hưởng nếu có vấn đề phát sinh với triển khai mới. Mặc dù triển khai blue/green đã là một chiến lược đáng tin cậy cho các bản cập nhật zero-downtime, những hạn chế của nó trở nên rõ ràng khi triển khai các large language model (LLM) quy mô lớn hoặc các mô hình thông lượng cao trên các GPU instance cao cấp. Những thách thức này đòi hỏi một cách tiếp cận tinh tế hơn—một cách tiếp cận xác thực các bản cập nhật từng bước trong khi tối ưu hóa việc sử dụng tài nguyên. Rolling update cho inference component được thiết kế để loại bỏ sự cứng nhắc của các triển khai blue/green. Bằng cách cập nhật các mô hình theo các batch được kiểm soát, mở rộng cơ sở hạ tầng một cách linh hoạt và tích hợp các kiểm tra an toàn theo thời gian thực, chiến lược này đảm bảo các triển khai vẫn tiết kiệm chi phí, đáng tin cậy và có khả năng thích ứng—ngay cả đối với các workload sử dụng GPU nặng.\nRolling deployment để cập nhật inference component Như đã đề cập trước đó, inference component được giới thiệu như một tính năng của RageMaker AI để tối ưu hóa chi phí; chúng cho phép bạn định nghĩa và triển khai các tài nguyên cụ thể cần thiết cho workload suy luận mô hình của bạn. Bằng cách điều chỉnh đúng kích thước tài nguyên tính toán để phù hợp với yêu cầu của mô hình, bạn có thể tiết kiệm chi phí trong quá trình cập nhật so với các phương pháp triển khai truyền thống.\nVới rolling update, RageMaker AI triển khai các phiên bản mô hình mới theo các batch inference component có thể cấu hình trong khi mở rộng instance một cách linh hoạt. Điều này đặc biệt có tác động đối với các LLM:\nTính linh hoạt về kích thước batch – Khi cập nhật các inference component trong một SageMaker AI endpoint, bạn có thể chỉ định kích thước batch cho mỗi bước rolling. Đối với mỗi bước, RageMaker AI cung cấp năng lực dựa trên kích thước batch được chỉ định trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Các mô hình nhỏ hơn như DeepSeek Distilled Llama 8B có thể sử dụng các batch lớn hơn để cập nhật nhanh chóng, và các mô hình lớn hơn như DeepSeek Distilled Llama 70B sử dụng các batch nhỏ hơn để hạn chế tranh chấp GPU. Bảo vệ an toàn tự động – Các alarm Amazon CloudWatch tích hợp giám sát các metric trên một inference component. Bạn có thể cấu hình các alarm để kiểm tra xem phiên bản mới được triển khai của inference component có hoạt động đúng hay không. Nếu các alarm CloudWatch được kích hoạt, RageMaker AI sẽ bắt đầu một rollback tự động. Chức năng mới được triển khai thông qua các phần mở rộng cho RageMaker AI API, chủ yếu với các tham số mới trong API Update Inference Component:\nsagemaker_client.update_inference_component(\nInferenceComponentName=inference_component_name,\nRuntimeConfig={ \u0026ldquo;CopyCount\u0026rdquo;: number },\nSpecification={ \u0026hellip; },\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: { # Value must be between 5% to 50% of the IC\u0026rsquo;s total copy count.\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;: 1 # Minimum value of 1\n},\n\u0026ldquo;MaximumExecutionTimeoutInSeconds\u0026rdquo;: 600, #Minimum value of 600. Maximum value of 28800.\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;:1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120 # Minimum value of 0. Maximum value of 3600\n}\n},\nAutoRollbackConfiguration={\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\n\u0026ldquo;AlarmName\u0026rdquo;: \u0026ldquo;string\u0026rdquo; #Optional\n}\n]\n},\n)\nĐoạn code trên sử dụng các tham số sau:\nMaximumBatchSize – Đây là một tham số bắt buộc và định nghĩa kích thước batch cho mỗi bước rolling trong quy trình triển khai. Đối với mỗi bước, RageMaker AI cung cấp năng lực trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Giá trị phải nằm trong khoảng từ 5–50% số lượng bản sao của inference component. Type – Tham số này có thể chứa một giá trị như COPY_COUNT | CAPACITY_PERCENT, chỉ định loại năng lực endpoint. Value – Định nghĩa kích thước năng lực, dưới dạng số lượng bản sao inference component hoặc phần trăm năng lực. MaximumExecutionTimeoutSeconds – Đây là thời gian tối đa mà rolling deployment sẽ dành cho việc thực thi tổng thể. Vượt quá giới hạn này sẽ gây ra timeout. RollbackMaximumBatchSize – Đây là kích thước batch cho một rollback về endpoint fleet cũ. Nếu trường này vắng mặt, giá trị được đặt thành mặc định, là 100% tổng năng lực. Khi sử dụng mặc định, RageMaker AI cung cấp toàn bộ năng lực của fleet cũ cùng một lúc trong quá trình rollback. Value – Tham số Value của cấu trúc này sẽ chứa giá trị mà Type sẽ được thực thi. Đối với chiến lược rollback, nếu bạn không chỉ định các trường trong đối tượng này, hoặc nếu bạn đặt Value thành 100%, thì SageMaker AI sử dụng chiến lược rollback blue/green và roll lưu lượng trở lại fleet blue. WithIntervalInSeconds – Đây là giới hạn thời gian cho tổng triển khai. Vượt quá giới hạn này sẽ gây ra timeout. AutoRollbackConfiguration – Đây là cấu hình rollback tự động để xử lý lỗi triển khai endpoint và khôi phục. AlarmName – Alarm CloudWatch này được cấu hình để giám sát các metric trên một InferenceComponent Bạn có thể cấu hình nó để kiểm tra xem phiên bản mới được triển khai của InferenceComponent có hoạt động đúng hay không. Để biết thêm thông tin về SageMaker AI API, tham khảo SageMaker AI API Reference.\nTrải nghiệm khách hàng Hãy cùng khám phá cách rolling update hoạt động trong thực tế với một số tình huống phổ biến, sử dụng các LLM có kích thước khác nhau. Bạn có thể tìm thấy notebook ví dụ trong GitHub repo.\nTình huống 1: Nhiều cluster GPU đơn Trong tình huống này, giả sử bạn đang chạy một endpoint với ba instance ml.g5.2xlarge, mỗi instance có một GPU duy nhất. Endpoint lưu trữ một inference component yêu cầu một CPU accelerator, có nghĩa là mỗi instance chứa một bản sao. Khi bạn muốn cập nhật inference component để sử dụng phiên bản inference component mới, bạn có thể sử dụng rolling update để giảm thiểu sự gián đoạn.\nBạn có thể cấu hình một rolling update với kích thước batch là một, có nghĩa là RageMaker AI sẽ cập nhật từng bản sao một. Trong quá trình cập nhật, RageMaker AI trước tiên xác định năng lực có sẵn trong các instance hiện có. Vì không có instance hiện tại nào có không gian cho các workload tạm thời bổ sung, RageMaker AI sẽ khởi chạy các instance ml.g5.2xlarge mới từng cái một để triển khai một bản sao của phiên bản inference component mới lên một GPU instance. Sau khoảng thời gian chờ được chỉ định và container của inference component mới vượt qua kiểm tra healthy, RageMaker AI loại bỏ một bản sao của phiên bản cũ (vì mỗi bản sao được lưu trữ trên một instance, instance này sẽ được dỡ bỏ tương ứng), hoàn tất bản cập nhật cho batch đầu tiên.\nQuy trình này lặp lại cho bản sao thứ hai của inference component, cung cấp một quá trình chuyển đổi suôn sẻ với zero downtime. Bản chất dần dần của bản cập nhật giảm thiểu rủi ro và cho phép bạn duy trì tính khả dụng nhất quán trong suốt quy trình triển khai. Sơ đồ sau đây cho thấy quy trình này.\nTình huống 2: Cập nhật với rollback tự động Trong một tình huống khác, bạn có thể đang cập nhật inference component của mình từ Llama-3.1-8B-Instruct sang DeepSeek-R1-Distill-Llama-8B, nhưng phiên bản mô hình mới có các kỳ vọng API khác nhau. Trong trường hợp sử dụng này, bạn đã cấu hình một alarm CloudWatch để giám sát lỗi 4xx, điều này sẽ cho biết các vấn đề về tương thích API.\nBạn có thể bắt đầu một rolling update với kích thước batch là một bản sao. RageMaker AI triển khai bản sao đầu tiên của phiên bản mới trên một GPU instance mới. Khi instance mới sẵn sàng phục vụ lưu lượng, RageMaker AI sẽ chuyển tiếp một phần các yêu cầu invocation đến mô hình mới này. Tuy nhiên, trong ví dụ này, phiên bản mô hình mới, đang thiếu cấu hình biến môi trường \u0026ldquo;MESSAGES_API_ENABLED\u0026rdquo;, sẽ bắt đầu trả về lỗi 4xx khi nhận các yêu cầu ở định dạng Messages API.\nAlarm CloudWatch được cấu hình phát hiện các lỗi này và chuyển sang trạng thái alarm. RageMaker AI tự động phát hiện trạng thái alarm này và bắt đầu quy trình rollback theo cấu hình rollback. Theo kích thước batch rollback được chỉ định, RageMaker AI loại bỏ phiên bản mô hình mới có vấn đề và duy trì phiên bản gốc đang hoạt động, ngăn chặn sự gián đoạn dịch vụ trên diện rộng. Endpoint trở về trạng thái ban đầu với lưu lượng được xử lý bởi phiên bản mô hình gốc hoạt động đúng.\nĐoạn code sau đây cho thấy cách thiết lập một alarm CloudWatch để giám sát lỗi 4xx:\nCreate alarm cloudwatch.put_metric_alarm(\nAlarmName=f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors',\nComparisonOperator=\u0026lsquo;GreaterThanThreshold\u0026rsquo;,\nEvaluationPeriods=1,\nMetricName=\u0026lsquo;Invocation4XXErrors\u0026rsquo;,\nNamespace=\u0026lsquo;AWS/SageMaker\u0026rsquo;,\nPeriod=300,\nStatistic=\u0026lsquo;Sum\u0026rsquo;,\nThreshold=5.0,\nActionsEnabled=True,\nAlarmDescription=\u0026lsquo;Alarm when greather than 5 4xx errors\u0026rsquo;,\nDimensions=[\n{\n\u0026lsquo;Name\u0026rsquo;: \u0026lsquo;InferenceComponentName\u0026rsquo;,\n\u0026lsquo;Value\u0026rsquo;: inference_component_name\n},\n],\n)\nSau đó bạn có thể sử dụng alarm CloudWatch này trong yêu cầu cập nhật:\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120,\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n}\n},\n\u0026lsquo;AutoRollbackConfiguration\u0026rsquo;: {\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\u0026ldquo;AlarmName\u0026rdquo;: f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors\u0026rsquo;}\n]\n}\n}\nTình huống 3: Cập nhật với năng lực đầy đủ trong các instance hiện có Nếu một endpoint hiện có có nhiều GPU accelerator và không phải tất cả các accelerator đều được sử dụng, bản cập nhật có thể sử dụng các GPU accelerator hiện có mà không cần khởi chạy các instance mới cho endpoint. Xem xét nếu bạn có một endpoint được cấu hình với hai instance ml.g5.12xlarge ban đầu có bốn GPU accelerator trong mỗi instance. Endpoint lưu trữ hai inference component: IC-1 yêu cầu một accelerator và IC-2 cũng yêu cầu một accelerator. Trên một instance ml.g5.12xlarge, có bốn bản sao của IC-1 đã được tạo; trên instance khác, hai bản sao của IC-2 đã được tạo. Vẫn còn hai GPU accelerator có sẵn trên instance thứ hai.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Nó sẽ tạo hai bản sao của phiên bản IC-1 mới trên instance thứ hai. Khi các container đã khởi động và chạy, SageMaker AI sẽ hướng lưu lượng đến các IC-1 mới và sau đó bắt đầu định tuyến lưu lượng đến các inference component mới. RageMaker AI cũng sẽ loại bỏ hai trong số các bản sao IC-1 cũ khỏi instance. Bạn không bị tính phí cho đến khi các inference component mới bắt đầu nhận các invocation và tạo ra các phản hồi.\nBây giờ có thêm hai GPU slot trống. RageMaker AI sẽ cập nhật batch thứ hai, và nó sẽ sử dụng các GPU accelerator trống vừa có sẵn. Sau khi các quy trình hoàn tất, endpoint có bốn IC-1 với phiên bản mới và hai bản sao của IC-2 không bị thay đổi.\nTình huống 4: Cập nhật yêu cầu năng lực instance bổ sung Xem xét nếu bạn có một endpoint được cấu hình với ban đầu một instance ml.g5.12xlarge (tổng cộng 4 GPU) và được cấu hình managed instance scaling (MIS) với số instance tối đa được đặt thành hai. Endpoint lưu trữ hai inference component: IC-1 yêu cầu 1 GPU với hai bản sao (Llama 8B), và IC-2 (mô hình DeepSeek Distilled Llama 14B) cũng yêu cầu 1 GPU với hai bản sao—sử dụng tất cả 4 GPU có sẵn.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng không có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Thay vì làm thất bại bản cập nhật, vì bạn đã cấu hình MIS, RageMaker AI sẽ tự động cung cấp một instance g5.12.xlarge thứ hai để lưu trữ các inference component mới.\nTrong quá trình cập nhật, RageMaker AI triển khai hay bản sao của phiên bản IC-1 mới lên instance mới được cung cấp, như được hiển thị trong sơ đồ sau. Sau khi các inference component mới đã khởi động và chạy, RageMaker AI bắt đầu loại bỏ các bản sao IC-1 cũ khỏi các instance gốc. Đến cuối bản cập nhật, instance đầu tiên sẽ lưu trữ IC-2 sử dụng 2 GPU, và instance thứ hai mới được cung cấp sẽ lưu trữ IC-1 đã cập nhật với hai bản sao sử dụng 2 GPU. Sẽ có các không gian mới có sẵn trong hai instance, và bạn có thể triển khai thêm các bản sao inference component hoặc các mô hình mới vào cùng một endpoint bằng cách sử dụng các tài nguyên GPU có sẵn. Nếu bạn thiết lập managed instance auto scaling và đặt inference component auto scaling về không, bạn có thể scale down các bản sao inference component về không, điều này sẽ dẫn đến instance tương ứng được scale down. Khi inference component được scale up, SageMaker AI sẽ khởi chạy các inference component trong instance hiện có với các GPU accelerator có sẵn, như đã đề cập trong tình huống 3.\nTình huống 5: Cập nhật đối mặt với năng lực không đủ Trong các tình huống không có đủ năng lực GPU, RageMaker AI cung cấp phản hồi rõ ràng về các ràng buộc năng lực. Xem xét nếu bạn có một endpoint chạy trên 30 instance ml.g6e.16xlarge, mỗi instance đã được sử dụng đầy đủ với các inference component. Bạn muốn cập nhật một inference component hiện có bằng cách sử dụng rolling deployment với kích thước batch là 4, nhưng sau khi bốn batch đầu tiên được cập nhật, không có đủ năng lực GPU có sẵn cho phần còn lại của bản cập nhật. Trong trường hợp này, RageMaker AI sẽ tự động rollback về thiết lập trước đó và dừng quy trình cập nhật.\nCó thể có hai trường hợp cho trạng thái cuối cùng của rollback này. Trong trường hợp đầu tiên, rollback đã thành công vì có năng lực mới có sẵn để khởi chạy các instance cho phiên bản mô hình cũ. Tuy nhiên, có thể có một trường hợp khác trong đó vấn đề năng lực vẫn tồn tại trong quá trình rolling back, và endpoint sẽ hiển thị là UPDATE_ROLLBACK_FAILED. Các instance hiện có vẫn có thể phục vụ lưu lượng, nhưng để chuyển endpoint ra khỏi trạng thái failed, bạn cần liên hệ với nhóm AWS support của mình.\nCác cân nhắc bổ sung Như đã đề cập trước đó, khi sử dụng triển khai blue/green để cập nhật các inference component trên một endpoint, bạn cần cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Khi bạn đang sử dụng rolling update cho các inference component trên endpoint, bạn có thể sử dụng phương trình sau để tính số lượng service quota tài khoản cho loại instance cần thiết. GPU instance cần thiết cho endpoint có X số GPU accelerator, và mỗi bản sao inference component yêu cầu Y số GPU accelerator. Kích thước batch tối đa được đặt thành Z và endpoint hiện tại có N instance. Do đó, service quota cấp tài khoản cần thiết cho loại instance này cho endpoint phải lớn hơn đầu ra của phương trình:\nROUNDUP(Z x Y / X) + N\nVí dụ, giả sử endpoint hiện tại có 8 (N) instance ml.g5.12xlarge, có 4 GPU accelerator của mỗi instance. Bạn đặt kích thước batch tối đa thành 2 (Z) bản sao, và mỗi bản sao cần 1 (Y) GPU accelerator. Giá trị service quota AWS tối thiểu cho ml.g5.12xlarge là ROUNDUP(2 x 1 / 4) + 8 = 9. Trong một tình huống khác, khi mỗi bản sao của inference component yêu cầu 4 GPU accelerator, thì service quota cấp tài khoản cần thiết cho cùng một instance phải là ROUNDUP(2 x 4 / 4) + 8 = 10.\nKết luận Các bản cập nhật cuốn chiếu (rolling updates) cho các thành phần suy luận đại diện cho một bước tiến quan trọng trong khả năng triển khai của SageMaker AI. Tính năng này trực tiếp giải quyết các thách thức trong việc cập nhật mô hình đang chạy trong môi trường sản xuất, đặc biệt là với những khối lượng công việc nặng về GPU. Nó giúp loại bỏ việc phải ước lượng dung lượng thủ công, đồng thời giảm thiểu rủi ro khi cần hoàn tác (rollback).\nBằng cách kết hợp quy trình cập nhật theo lô (batch-based updates) cùng với các biện pháp bảo vệ tự động, SageMaker AI đảm bảo rằng các quá trình triển khai luôn linh hoạt và ổn định.\nCác lợi ích chính bao gồm:\nGiảm chi phí tài nguyên trong quá trình triển khai, không cần cấp phát thêm cụm máy chủ dự phòng. Cải thiện cơ chế bảo vệ trong quá trình triển khai nhờ cập nhật dần và khả năng tự động hoàn tác khi xảy ra lỗi. Duy trì khả năng hoạt động liên tục trong khi cập nhật, với kích thước lô có thể cấu hình. Đơn giản hóa việc triển khai các mô hình phức tạp cần nhiều bộ tăng tốc (multi-accelerator models). Dù bạn đang triển khai mô hình nhỏ gọn hay các mô hình lớn sử dụng nhiều bộ tăng tốc, rolling updates mang lại một phương pháp hiệu quả hơn, tiết kiệm chi phí và an toàn hơn để giữ cho các mô hình máy học của bạn luôn được cập nhật trong môi trường sản xuất.\nChúng tôi khuyến khích bạn dùng thử khả năng mới này trên các endpointSageMaker AI của mình và khám phá cách nó có thể nâng cao hiệu quả hoạt động ML của bạn. Để biết thêm thông tin, vui lòng tham khảo SageMaker AI documentation hoặc liên hệ với nhóm tài khoản AWS của bạn.\nVề các tác giả Melanie Li, Tiến sĩ, là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS, trụ sở tại Sydney, Úc. Cô tập trung vào việc hỗ trợ khách hàng xây dựng các giải pháp ứng dụng các công cụ AI và máy học tiên tiến nhất. Cô đã tham gia vào nhiều sáng kiến Generative AI trên toàn khu vực APJ, tận dụng sức mạnh của Large Language Models (LLMs). Trước khi gia nhập AWS, Tiến sĩ Li từng đảm nhiệm vai trò nhà khoa học dữ liệu trong lĩnh vực tài chính và bán lẻ.\nAndrew Smith là Kỹ sư Hỗ trợ Đám mây trong nhóm SageMaker, Vision \u0026amp; Other tại AWS, trụ sở Sydney, Úc. Anh hỗ trợ khách hàng sử dụng nhiều dịch vụ AI/ML của AWS, đặc biệt có chuyên môn sâu về Amazon SageMaker. Ngoài công việc, anh thích dành thời gian cho gia đình, bạn bè và tìm hiểu các công nghệ mới.\nDustin Liu là Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, tập trung hỗ trợ các công ty khởi nghiệp và doanh nghiệp SaaS trong lĩnh vực dịch vụ tài chính và bảo hiểm (FSI). Anh có nền tảng đa dạng trong kỹ thuật dữ liệu (data engineering), khoa học dữ liệu (data science) và máy học (machine learning), đồng thời đam mê ứng dụng AI/ML để thúc đẩy đổi mới và chuyển đổi doanh nghiệp.\nVivek Gangasani là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS. Anh giúp các công ty khởi nghiệp về Generative AI xây dựng các giải pháp sáng tạo bằng cách sử dụng dịch vụ AWS và hạ tầng tính toán tăng tốc. Hiện tại, anh tập trung vào việc phát triển các chiến lược tinh chỉnh (fine-tuning) và tối ưu hiệu năng suy luận (inference performance) cho các mô hình ngôn ngữ lớn (LLMs). Ngoài công việc, Vivek thích leo núi, xem phim và khám phá ẩm thực.\nShikher Mishra là Kỹ sư Phát triển Phần mềm (Software Development Engineer) thuộc nhóm SageMaker Inference, với hơn 9 năm kinh nghiệm trong ngành. Anh đam mê xây dựng các giải pháp mở rộng, hiệu quả, giúp khách hàng triển khai và quản lý ứng dụng máy học một cách dễ dàng. Thời gian rảnh, Shikher yêu thích thể thao ngoài trời, leo núi và du lịch.\nJune Won là Quản lý sản phẩm (Product Manager) của Amazon SageMaker JumpStart. Anh tập trung vào việc giúp khách hàng dễ dàng tìm kiếm và sử dụng các mô hình nền tảng (foundation models) để xây dựng ứng dụng Generative AI. Kinh nghiệm của anh tại Amazon còn bao gồm phát triển ứng dụng mua sắm di động và giải pháp giao hàng chặng cuối (last-mile delivery).\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/3-blogstranslated/3.2-blog2/","title":"Blog 1","tags":[],"description":"","content":"Thông báo kết thúc hỗ trợ và khả năng khám phá nâng cao cho Amazon EKS Ngày 05 tháng 03 năm 2025\nTác giả: Praseeda Sathaye (Principal Solutions Architect, Containers \u0026amp; OSS), AJ Davis (AWS Enterprise Support) và Arvind Viswanathan (Principal Solutions Architect)\nGiới thiệu Trong thế giới ứng dụng container hóa đang phát triển nhanh chóng, việc duy trì khả năng phục hồi và khả năng quan sát trên các môi trường Kubernetes đã trở thành một thách thức quan trọng. Khi các tổ chức ngày càng áp dụng Amazon Elastic Kubernetes Service (Amazon EKS) để quản lý khối lượng công việc container hóa của họ, nhu cầu về quản lý vòng đời phiên bản cluster và cơ chế khám phá trở nên cực kỳ quan trọng. Khi môi trường Amazon EKS trở nên phức tạp hơn và mở rộng trên nhiều AWS Regions và tài khoản, người dùng thường gặp khó khăn trong việc theo dõi phiên bản cluster, vòng đời hỗ trợ và trạng thái triển khai tổng thể.\nGiám sát chủ động vòng đời cluster EKS và kết thúc hỗ trợ là rất quan trọng để đảm bảo tính bảo mật, ổn định và tuân thủ của các triển khai Kubernetes. Hơn nữa, việc có được khả năng hiển thị các triển khai cluster EKS trên toàn bộ AWS Organization là điều cần thiết cho việc quản lý tài nguyên hiệu quả, lập kế hoạch chiến lược và duy trì bảng kiểm kê chính xác.\nTrong bài viết này, để giải quyết những điểm yếu này, chúng tôi chia sẻ hai giải pháp mạnh mẽ cung cấp khả năng quan sát các cluster EKS:\nThông báo kết thúc hỗ trợ Khám phá và báo cáo Giải pháp đầu tiên sử dụng AWS Health, Amazon EventBridge và Amazon Simple Notification Service (Amazon SNS)/Amazon Simple Queue Service (Amazon SQS) để giám sát các sự kiện cụ thể của Amazon EKS, đặc biệt đối với các cluster sắp kết thúc hỗ trợ (tiêu chuẩn và mở rộng). Việc cung cấp thông báo sớm khi một cluster EKS sắp kết thúc cửa sổ hỗ trợ cho phép giải pháp này trao quyền cho bạn chủ động lập kế hoạch và cập nhật phiên bản Kubernetes của cluster.\nBổ sung cho điều này, giải pháp thứ hai là một cơ chế khám phá và báo cáo tự động xác định và tổng hợp thông tin chi tiết về các cluster EKS trên tất cả các AWS Regions và tài khoản trong Organization của bạn. Khả năng hiển thị toàn diện này về các phiên bản cluster, tags liên quan và các chi tiết chính khác giúp kiểm tra tuân thủ, quản lý bảng kiểm kê tài nguyên chính xác và lập kế hoạch nâng cấp chiến lược.\nCùng nhau, hai giải pháp này cung cấp một framework mạnh mẽ để quản lý vòng đời cluster EKS hiệu quả, cho phép các tổ chức luôn đi trước các vấn đề tiềm ẩn, tối ưu hóa việc sử dụng tài nguyên và đưa ra các quyết định sáng suốt phù hợp với mục tiêu chiến lược dài hạn của họ.\nĐiều kiện tiên quyết Bạn cần những điều sau để hoàn thành hướng dẫn:\nMột AWS account với Organizations được bật Gói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support để sử dụng AWS Health API Kiến thức cơ bản về Amazon EKS, AWS Health, EventBridge, AWS Lambda, AWS Identity and Access Management (IAM), Amazon S3, Amazon SNS, Amazon SQS và AWS Cloud Development Kit (AWS CDK) Khả năng ủy quyền từ tài khoản quản lý đến tài khoản tooling được sử dụng để tập trung thông báo và thực hiện khám phá cluster EKS trên toàn bộ Organization Kiến thức về Python Thiết lập ban đầu Các bước sau hướng dẫn bạn qua quá trình thiết lập ban đầu.\nBật AWS Health Organizational View trong tài khoản quản lý Bật Organizational View in AWS Health để có được chế độ xem tập trung, tổng hợp các sự kiện AWS Health trên toàn bộ Organization của bạn. Bạn có thể xác minh rằng điều này được bật thông qua console hoặc bằng cách chạy lệnh sau bằng AWS Command Line Interface (AWS CLI):\naws health describe-health-service-status-for-organization. Bạn sẽ thấy kết quả sau:\n{\u0026ldquo;healthServiceAccessStatusForOrganization\u0026rdquo;: \u0026ldquo;ENABLED\u0026rdquo; }\nGói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support là cần thiết để sử dụng AWS Health API và hoàn thành bước này.\nỦy quyền quản trị từ tài khoản quản lý đến tài khoản tooling trung tâm Thiết lập một tài khoản AWS trong Organization làm tài khoản tooling cho giải pháp này. Tài khoản này được sử dụng để tập trung thông báo và khám phá.\nTừ tài khoản quản lý, ủy quyền quản trị AWS CloudFormation StackSets bằng cách làm theo các bước được mô tả trong bài viết này: CloudFormation StackSets delegated administration.\nKết quả tương tự cũng có thể đạt được bằng cách chạy lệnh sau từ tài khoản quản lý. Thay thế 012345678901 bằng AWS account ID của tài khoản tooling của bạn.\naws organizations register-delegated-administrator \\\n\u0026ndash;serviceprincipal=member.org.stacksets.cloudformation.amazonaws.com \\\n\u0026ndash;account-id=\u0026ldquo;012345678901\u0026rdquo;\nĐây là lần duy nhất chúng ta cần truy cập tài khoản quản lý. Các bước còn lại được hoàn thành từ trong tài khoản tooling.\nBootstrap AWS CDK Chọn một Region chính nơi tất cả báo cáo và sự kiện được hợp nhất trong tài khoản tooling trung tâm. Đặt biến AWS_DEFAULT_REGION thành Region chính này.\nĐối với giải pháp khám phá và báo cáo, bạn phải bootstrap AWS CDK trong Region chính này trên toàn bộ Organization. Hơn nữa, AWS CDK cũng phải được bootstrap trong tất cả các AWS Regions nơi các cluster EKS được triển khai để nhận thông báo kết thúc hỗ trợ. Để đơn giản hóa hướng dẫn này, chúng tôi chỉ demo triển khai tài nguyên đến Region chính mà bạn đã chọn.\nCác bước để bootstrap AWS CDK trên nhiều AWS Regions và tài khoản có sẵn trong bài viết này: Bootstrapping multiple AWS accounts for AWS CDK using CloudFormation StackSets.\nTải xuống các AWS CDK stacks Chúng tôi cung cấp các AWS CDK stacks để bạn nhanh chóng triển khai giải pháp trong môi trường của mình. Tải mã từ our GitHub repository và thiết lập môi trường bằng cách chạy các lệnh sau trong thư mục cdk:\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\nHướng dẫn chi tiết Các bước sau sẽ hướng dẫn bạn qua các giải pháp này.\nGiải pháp 1: Thông báo kết thúc hỗ trợ cluster EKS Giải pháp đầu tiên của chúng tôi giải quyết nhu cầu quan trọng về nhận thức kịp thời về các sự kiện vòng đời cluster EKS, đặc biệt là việc tiếp cận ngày kết thúc hỗ trợ tiêu chuẩn. Việc sử dụng AWS Health, EventBridge và Amazon SNS (và tùy chọn Amazon SQS) cho phép chúng tôi tạo một hệ thống tập trung:\nGiám sát các sự kiện AWS Health trên nhiều AWS Regions và tài khoản Tập trung vào các sự kiện cụ thể của Amazon EKS, đặc biệt là AWS_EKS_PLANNED_LIFECYCLE_EVENT Cung cấp thông báo sớm khi một cluster EKS còn 180 ngày nữa sẽ đạt đến cuối giai đoạn hỗ trợ tiêu chuẩn và hỗ trợ mở rộng Cách tiếp cận tập trung này đảm bảo rằng người dùng Amazon EKS nhận được đủ thời gian để lập kế hoạch và thực hiện nâng cấp phiên bản, duy trì tính bảo mật và ổn định của môi trường Kubernetes của họ, như được hiển thị trong hình sau.\nHình 1: Tổng quan giải pháp – thông báo kết thúc hỗ trợ\nBước 1: Triển khai AWS CDK stack eks-health-events Triển khai AWS CDK stack eks-health-events vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-health-events \u0026ndash;app \u0026ldquo;python3 tooling_account.py\u0026rdquo; —require-approval never\nĐiều này triển khai AWS CDK app trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nEvent bus SNS topic và SQS queue để giám sát các sự kiện EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SNS EventBridge rule để chuyển tiếp giám sát các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SQS Resource policies cho các event rules để publish đến Amazon SNS và Amazon SQS Bước 2: Triển khai AWS CDK stack eks-health-events-stack-set Triển khai AWS CDK stack eks-health-events-stack-set.\ncdk deploy eks-health-events-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; —require-approval never\nĐiều này sử dụng CloudFormation StackSets để triển khai các tài nguyên sau vào Region chính đã chọn trên tất cả các tài khoản trong Organization ngoại trừ tài khoản Management:\nLocal event bus EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến central event bus được cung cấp trong Bước 2 Resource policies cho các event rules để publish đến central event bus Bước 3: Cấu hình thông báo SNS Duyệt đến dịch vụ Amazon SNS có tên eks-health-events-EKSHealthEvents- và tạo một subscription cho topic mới được tạo (ví dụ: địa chỉ email nhóm).\nBước 4: Xác thực giải pháp Bạn có thể kiểm tra và xác thực rằng các EventBridge rules, SQS queue và SNS topic đã được tạo bởi các CloudFormation stacks có tên eks-health-events và eks-health-events-stack-set. Từ thời điểm này trở đi, khi các cluster EKS của bạn còn 180 ngày nữa sẽ đạt đến cuối hỗ trợ (tiêu chuẩn và mở rộng), các EventBridge rules sẽ áp dụng và Amazon SNS và/hoặc Amazon SQS được kích hoạt, như được hiển thị trong các hình sau.\nHình 2: Xác thực triển khai EventBridge\nHình 3: Xác thực triển khai SQS\nHình 4: Xác thực triển khai SNS\nHình 5: Mẫu thông báo kết thúc hỗ trợ\nGiải pháp 2: Khám phá và báo cáo cluster EKS Bổ sung cho giải pháp thông báo kết thúc hỗ trợ cluster EKS, giải pháp thứ hai của chúng tôi cung cấp cái nhìn toàn diện về các cluster EKS trên toàn bộ Organization. Giải pháp này:\nXác định các cluster EKS trong tất cả các AWS Regions và tài khoản trong một Organization Thu thập thông tin chi tiết về từng cluster, chẳng hạn như chi tiết tài khoản, region, tên cluster, phiên bản và các tags liên quan Tổng hợp dữ liệu về các phiên bản cluster, cung cấp thông tin chi tiết về phân phối phiên bản Tạo cả báo cáo chi tiết và tóm tắt, được lưu trữ tập trung để truy cập trực tiếp Việc cung cấp khả năng hiển thị trên toàn tổ chức này cho phép giải pháp giúp các nhóm duy trì bảng kiểm kê chính xác về tài nguyên Amazon EKS, tạo điều kiện thuận lợi cho việc kiểm tra tuân thủ và hỗ trợ lập kế hoạch nâng cấp chiến lược, như được hiển thị trong hình sau.\nHình 6: Tổng quan giải pháp – khám phá và báo cáo\nBước 1: Triển khai AWS CDK stack eks-discovery Triển khai AWS CDK stack eks-discovery-lambda vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-discovery-lambda —require-approval never\nĐiều này triển khai AWS CDK stack có tên eks-discovery-lambda trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nLambda function để khám phá các cluster EKS trên tất cả các AWS Regions và tài khoản S3 bucket để lưu trữ kết quả SNS topic cho thông báo EventBridge scheduler để thực thi định kỳ Các IAM roles và policies cần thiết Lambda function thu thập chi tiết cluster, tạo báo cáo và gửi thông báo.\nBước 2: Sửa đổi EventBridge scheduler theo nhu cầu Nếu bạn muốn tùy chỉnh lịch khám phá cluster EKS, hãy điều hướng đến EventBridge và trong phần schedules tìm EKSDiscoveryWeeklySchedule mới được tạo. Đây là một scheduler dựa trên cron, như được hiển thị trong hình sau.\nHình 7: Tùy chỉnh lịch cho khám phá cluster\nĐể nhận thông báo từ Amazon SNS, bạn phải tạo một subscription cho topic. Để làm điều này, hãy điều hướng đến dịch vụ Amazon SNS, tìm Topic mới được tạo có tên EKSDiscoverySNSTopic và cấu hình giao thức để đáp ứng yêu cầu của bạn (ví dụ: gửi email đến một nhóm).\nBước 3: Triển khai cross-account role mà Lambda function có thể assume để thực hiện khám phá Lambda function bạn triển khai trong Bước 1 dựa vào một cross-account role trong mỗi tài khoản trong Organization để thực hiện khám phá cluster.\nTriển khai AWS CDK stack eks-discovery-stack-set để triển khai cross-account role này.\ncdk deploy eks-discovery-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;require-approval never\nBước 4: Xác thực giải pháp Để xác thực giải pháp, hãy điều hướng đến Lambda function mới được tạo và test với một event mới và một đối tượng JSON rỗng. Khi Lambda hoàn thành, hãy xác minh rằng S3 bucket nhận được file zip và xác nhận rằng bạn đã nhận được thông báo SNS, như được hiển thị trong các hình sau.\nHình 8: Mẫu output khám phá cluster trong S3 bucket\nHình 9: Mẫu nội dung của output file\nHình 10: Mẫu danh sách clusters\nHình 11: Mẫu số lượng clusters theo phiên bản\nBước 5: (Tùy chọn) Giám sát giải pháp Bạn có thể muốn giám sát giải pháp. Điều này có thể được thực hiện bằng cách thiết lập Amazon CloudWatch Alarms để giám sát việc thực thi của Lambda function và bất kỳ lỗi tiềm ẩn nào. Hơn nữa, hãy thường xuyên xem xét các báo cáo được tạo trong S3 bucket và định kỳ xem xét và cập nhật các quyền IAM nếu cần.\nKhắc phục sự cố Đảm bảo rằng tất cả các IAM roles và policies được thiết lập chính xác và có các quyền cần thiết. Kiểm tra CloudWatch Logs để tìm bất kỳ thông báo lỗi nào trong các Lambda functions hoặc EventBridge rules. Cân nhắc về bảo mật Xem xét và điều chỉnh các IAM roles và policies để tuân thủ nguyên tắc đặc quyền tối thiểu và môi trường của bạn. Thường xuyên kiểm toán quyền truy cập vào hệ thống quản lý sự kiện tập trung. Dọn dẹp Chạy các lệnh sau để dọn dẹp các tài nguyên đã cung cấp:\ncdk destroy \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;all \u0026ndash;force\ncdk destroy \u0026ndash;all \u0026ndash;force\nLệnh đầu tiên xóa các CloudFormation StackSets đã được triển khai trên toàn bộ Organization bằng AWS CDK App có tên stack_sets.py.\nLệnh thứ hai dọn dẹp các tài nguyên được cung cấp trong tài khoản tooling trung tâm bằng AWS CDK App có tên tooling_account.py.\nKết luận Hướng dẫn này có thể giúp bạn thiết lập một hệ thống mạnh mẽ sử dụng các dịch vụ AWS để cung cấp thông báo chủ động về kết thúc hỗ trợ tiêu chuẩn. Điều này cho phép lập kế hoạch kịp thời cho các nâng cấp, giảm thiểu rủi ro từ các cluster lỗi thời trong khi duy trì tính bảo mật, ổn định và tuân thủ. Hơn nữa, giải pháp khám phá và báo cáo cluster Amazon EKS đánh dấu một bước tiến đáng kể trong việc quản lý các môi trường Kubernetes đa tài khoản phức tạp trên AWS. Giải pháp tăng cường khả năng hiển thị, hợp lý hóa nỗ lực tuân thủ, tạo điều kiện thuận lợi cho việc lập kế hoạch chiến lược và hỗ trợ ra quyết định sáng suốt cho việc nâng cấp cluster và phân bổ tài nguyên.\nKhi các tổ chức tiếp tục mở rộng quy mô ứng dụng container hóa của họ, các giải pháp này trở thành tài sản vô giá. Chúng cho phép các nhóm duy trì cái nhìn tổng quan rõ ràng về cảnh quan Amazon EKS của họ, tối ưu hóa việc sử dụng tài nguyên và đảm bảo các thực hành quản lý nhất quán trên các triển khai đa dạng. Việc triển khai các giải pháp này cho phép bạn thực hiện một bước tiến đáng kể trong việc quản lý khả năng quan sát, khả năng phục hồi và quản trị của các môi trường Amazon EKS của bạn. Đến lượt nó, điều này đảm bảo thành công lâu dài và khả năng mở rộng của các sáng kiến Kubernetes của bạn trên AWS.\nChúng tôi khuyến nghị thử cả hai giải pháp để bắt đầu tăng cường khả năng quan sát cluster EKS của bạn ngay hôm nay!\nNguồn gốc: AWS Containers Blog Ngày xuất bản: 12 tháng 3, 2025 Danh mục: Amazon EKS, AWS Health, Container Management, Kubernetes\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Hiểu cấu trúc tài khoản AWS và vai trò của Root User. Học cách tạo và bảo mật tài khoản AWS. Thiết lập IAM User, IAM Group và gán chính sách quyền. Kích hoạt MFA và cấu hình cảnh báo chi phí. Làm quen với giao diện AWS Management Console. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tổng quan về tài khoản AWS và trách nhiệm của Root User - Hiểu các khái niệm IAM (User, Group, Policy) 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/ 2 - Tạo tài khoản AWS - Thêm phương thức thanh toán - Xác thực email \u0026amp; số điện thoại - Đăng nhập lần đầu và khám phá AWS Console 09/10/2025 09/10/2025 https://000001.awsstudygroup.com/ 3 - Bảo mật tài khoản Root + Kích hoạt MFA + Cấu hình password policy + Giảm thiểu việc sử dụng Root User - Thiết lập Billing Preferences \u0026amp; theo dõi Free Tier 09/11/2025 09/11/2025 https://000001.awsstudygroup.com/ 4 - Tạo IAM Group (Administrators) - Gắn AdministratorAccess policy - Tạo IAM User - Cấu hình đăng nhập cho user và bật MFA 09/12/2025 09/12/2025 https://000001.awsstudygroup.com/ 5 - Tạo Budget và Billing Alerts - Kiểm tra danh sách bảo mật tài khoản - Thực hành đăng nhập bằng IAM User - Khám phá giao diện AWS Console - Tổng kết bài học \u0026amp; các vấn đề phát sinh 09/13/2025 09/13/2025 https://000001.awsstudygroup.com/ Thành tựu Tuần 1: Hiểu rõ các thành phần của tài khoản AWS:\nRoot User IAM Users IAM Groups Policies Tạo và kích hoạt thành công tài khoản AWS mới.\nBảo mật tài khoản Root bằng MFA và thiết lập tiêu chuẩn mật khẩu.\nThiết lập Billing Preferences, theo dõi Free Tier và cấu hình ngân sách cảnh báo chi phí.\nTạo IAM Group và IAM User theo đúng best practices của AWS.\nKích hoạt MFA cho IAM User và thực hành quy trình đăng nhập bảo mật.\nLàm quen với AWS Management Console và cách tìm kiếm dịch vụ nhanh chóng.\nHoàn thành các bước bảo mật nền tảng trước khi bắt đầu sử dụng các dịch vụ AWS trong các tuần tiếp theo.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hiểu AWS Budgets và cách sử dụng để quản lý, giám sát chi phí AWS. Nắm được các loại Budget: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Thực hành tạo Budget bằng Template, tự cấu hình và dọn dẹp (clean up) tài nguyên sau khi xong. Hiểu dịch vụ AWS Support: các gói hỗ trợ, cách truy cập, cách tạo và quản lý yêu cầu hỗ trợ (support case). Nâng cao ý thức về kiểm soát chi phí và quy trình nhờ AWS hỗ trợ khi có sự cố. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan AWS Budgets + AWS Budgets là gì? + Lý do cần sử dụng Budget để kiểm soát chi phí + Các loại Budget: Cost, Usage, RI, Savings Plans 09/16/2025 09/16/2025 https://000007.awsstudygroup.com/ 2 - Thực hành Budgets (1): + Tạo Budget bằng Template + Tạo Cost Budget với ngưỡng cảnh báo (threshold) + Xem chi tiết Budget và cấu hình thông báo 09/17/2025 09/17/2025 https://000007.awsstudygroup.com/ 3 - Thực hành Budgets (2): + Tạo Usage Budget cho một dịch vụ cụ thể (ví dụ: EC2) + Tạo RI Budget + Hiểu khi nào nên dùng từng loại Budget 09/18/2025 09/18/2025 https://000007.awsstudygroup.com/ 4 - Thực hành Budgets (3): + Tạo Savings Plans Budget + Xem cách Budget gửi cảnh báo khi chi phí vượt ngưỡng + Thực hiện Clean Up: xoá các Budget / tài nguyên không cần sau khi hoàn thành workshop 09/19/2025 09/19/2025 https://000007.awsstudygroup.com/ 5 - Tìm hiểu AWS Support: + Các gói hỗ trợ (Support Plans) và sự khác nhau giữa chúng + Cách truy cập AWS Support Center - Thực hành: + Vào Support Center + Tạo một support case + Xem, cập nhật, đóng yêu cầu hỗ trợ 09/20/2025 09/20/2025 https://000009.awsstudygroup.com/ Thành tựu Tuần 2: Hiểu rõ AWS Budgets là gì và cách hỗ trợ quản lý chi phí AWS. Phân biệt được các loại Budget: Cost, Usage, RI và Savings Plans, và khi nào nên áp dụng từng loại. Tạo thành công nhiều Budget khác nhau bằng Template và cấu hình chi tiết trong AWS Console. Thiết lập cảnh báo (alert) khi chi phí hoặc mức sử dụng vượt quá ngưỡng cho phép, giúp chủ động kiểm soát chi phí. Biết cách dọn dẹp (clean up) Budget và tài nguyên liên quan sau khi kết thúc bài thực hành. Nắm được mục đích của AWS Support và các gói hỗ trợ khác nhau. Thực hành truy cập Support Center, tạo mới, theo dõi và đóng một yêu cầu hỗ trợ (support case). Nâng cao nhận thức về quản lý chi phí và quy trình hỗ trợ khi vận hành hệ thống trên AWS. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Academic Research Chatbot Giải pháp AWS RAG-based hỗ trợ học thuật và nghiên cứu học tập thông minh 1. Tóm tắt điều hành Academic Research Chatbot là trợ lý AI hỗ trợ nghiên cứu học thuật, giúp sinh viên và giảng viên tra cứu, tóm tắt và phân tích tài liệu khoa học (PDF, bài báo) thông qua hội thoại tự nhiên có trích dẫn nguồn chính xác.\nĐiểm nổi bật của giải pháp:\nCông nghệ lõi: Kết hợp IDP (Amazon Textract) để xử lý tài liệu (kể cả bản scan) và RAG (Amazon Bedrock - Claude 3.5 Sonnet) để sinh câu trả lời thông minh. Kiến trúc tối ưu: Mô hình Hybrid sử dụng 1 EC2 t3.small kết hợp các dịch vụ Serverless (Amplify, Cognito, S3, DynamoDB) để cân bằng hiệu năng và chi phí. Tính khả thi: Phục vụ ~50 người dùng nội bộ với chi phí vận hành ~60 USD/tháng, thời gian triển khai nhanh (20 ngày) và tận dụng tối đa AWS Free Tier. 2. Tuyên bố vấn đề Vấn đề hiện tại Sinh viên và researcher phải làm việc với số lượng lớn tài liệu học thuật (paper hội nghị, journal, luận văn, báo cáo kỹ thuật). Nhiều tài liệu là scan PDF cũ (trước năm 2000), không có text layer, khiến việc tìm kiếm nội dung, số liệu, bảng biểu rất tốn thời gian. Các công cụ AI công cộng (ChatGPT, Perplexity, NotebookLM, v.v.) không được kết nối trực tiếp với kho tài liệu nội bộ của trường/khoa, khó đảm bảo bảo mật và quyền truy cập theo môn học hoặc nhóm nghiên cứu. Hạ tầng hiện tại không có một điểm truy cập thống nhất để:\nQuản lý tài liệu nghiên cứu theo bộ môn/đề tài. Cho phép researcher đặt câu hỏi trực tiếp trên chính các paper của mình. Đảm bảo câu trả lời có trích dẫn rõ ràng (paper, trang, bảng, mục). Hệ quả: nghiên cứu viên phải đọc thủ công, note tay, copy số liệu từ nhiều paper; giảng viên khó tổng hợp nhanh thông tin khi chuẩn bị bài giảng hoặc đề tài; dữ liệu học thuật phân tán trên nhiều máy cá nhân, khó chuẩn hóa và tái sử dụng. Giải pháp Academic Research Chatbot đề xuất xây dựng một nền tảng hỏi – đáp học thuật nội bộ dựa trên AWS, nơi:\nDev/Admin nạp kho tài liệu nghiên cứu: Upload PDF vào Amazon S3, metadata được lưu trong Amazon DynamoDB. Một EC2 worker tiêu thụ hàng đợi Amazon SQS, gọi Amazon Textract để OCR, trích xuất text, bảng, biểu mẫu, kể cả tài liệu scan. Worker chuẩn hóa/chunk nội dung, gửi sang Amazon Bedrock Titan Text Embeddings v2 để sinh embedding, và index vào Qdrant trên EC2. Researchers đặt câu hỏi qua giao diện web (Amplify + CloudFront): Câu hỏi được embed, truy vấn Qdrant để lấy các đoạn liên quan nhất (Retrieval). Các đoạn này được chuyển vào Claude 3.5 Sonnet trên Amazon Bedrock để sinh câu trả lời có citation chính xác (paper, page, section, table) và giải thích theo ngữ cảnh học thuật. Toàn bộ truy cập được bảo vệ bởi Amazon Cognito (phân quyền researcher vs admin), log \u0026amp; metric được giám sát qua Amazon CloudWatch + SNS (cảnh báo khi có lỗi worker, queue backlog, CPU EC2 cao). Lợi ích và hoàn vốn đầu tư (ROI) Hiệu quả học thuật:\nGiảm 40–60% thời gian researcher phải bỏ ra để tìm số liệu, F1-score, p-value, sample size, thiết bị thí nghiệm hoặc mô tả phương pháp từ nhiều paper khác nhau. Giảm sai sót khi trích dẫn do quên trang/bảng, vì chatbot luôn trả kèm nguồn và vị trí. Quản lý tri thức nội bộ: Tài liệu nghiên cứu được tập trung về một kho S3 + DynamoDB, dễ backup, phân quyền, và mở rộng. Có thể tái sử dụng cho nhiều khoá học, đề tài và lab khác nhau mà không phải xây hệ thống mới. Chi phí hạ tầng thấp \u0026amp; dễ kiểm soát: Mô hình hybrid 1 EC2 + managed AI services giúp chi phí vận hành cho 50 users nội bộ giữ ở mức khoảng \u0026lt; 50 USD/tháng, chủ yếu trả cho EC2, 2–3 VPC endpoint interface và phần sử dụng Bedrock/Textract. Hệ thống được thiết kế để triển khai trong khoảng 20 ngày bởi team 4 người, phù hợp làm dự án nghiên cứu/thực tập nhưng vẫn có chất lượng kiến trúc sản phẩm. Giá trị dài hạn: Tạo nền tảng để sau này tích hợp thêm dashboard phân tích hành vi học tập, module recommend paper, hoặc mở rộng sang trợ lý học tập đa ngôn ngữ và đa lĩnh vực. 3. Kiến trúc giải pháp Academic Research Chatbot áp dụng mô hình AWS Hybrid RAG Architecture với IDP (Intelligent Document Processing), kết hợp một EC2 duy nhất (FastAPI + Qdrant + Worker) với các dịch vụ AI managed (Textract, Bedrock) để vừa tối ưu chi phí, vừa đảm bảo hiệu năng cho khoảng 50 người dùng nội bộ.\nLuồng xử lý dữ liệu và hội thoại\nDịch vụ AWS sử dụng\nFrontend: Route 53, CloudFront, Amplify (DNS, CDN, Host React App). Auth: Cognito (Xác thực \u0026amp; phân quyền researcher/admin). Compute: EC2 t3.small (FastAPI + Qdrant + Worker). AI/ML: Bedrock (Claude 3.5 Sonnet, Titan Embeddings v2). IDP: Textract (OCR cho PDF scan). Storage: S3, DynamoDB (File PDF gốc + Metadata/Status). Queue: SQS (Hàng đợi xử lý tài liệu). Network: VPC, ALB, VPC Endpoints (Bảo mật, routing, kết nối AWS Services). Monitoring: CloudWatch, SNS (Logs, Metrics, Alerts). CI/CD: CodePipeline, CodeBuild (Auto deploy backend). Thiết kế thành phần\nNgười dùng: Researchers: hỏi – đáp, tra cứu nội dung học thuật. Dev/Admin: upload, quản lý và re-index tài liệu. Xử lý tài liệu (IDP): PDF được Dev/Admin upload lên S3. Worker trên EC2 gọi Textract để OCR và trích xuất text/bảng. Lập chỉ mục (Indexing \u0026amp; Vector DB): Worker chuẩn hoá, chia chunk nội dung. Gọi Bedrock Titan Embeddings v2 tạo embedding. Lưu embedding + metadata vào Qdrant trên EC2. Hội thoại AI (RAG): FastAPI embed câu hỏi, truy vấn Qdrant lấy top-k đoạn liên quan. Gửi context + câu hỏi vào Claude 3.5 Sonnet (Bedrock) để sinh câu trả lời kèm citation. Quản lý người dùng: Cognito xác thực và phân quyền researcher / admin. Lưu trữ \u0026amp; trạng thái: DynamoDB lưu metadata tài liệu (doc_id, status, owner, …) và (tuỳ chọn) lịch sử chat. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần chính — nền tảng web (UI + auth) và backend RAG + IDP — triển khai qua 4 giai đoạn:\nNghiên cứu \u0026amp; chốt kiến trúc: Rà soát yêu cầu (50 researcher, 1 EC2, IDP + RAG). Chốt kiến trúc VPC, EC2 (FastAPI + Qdrant + Worker), Amplify, Cognito, S3, SQS, DynamoDB, Textract, Bedrock. POC \u0026amp; kiểm tra kết nối: Tạo EC2, VPC endpoints, thử gọi Textract, Titan Embeddings, Claude 3.5 Sonnet. Chạy Qdrant đơn giản trên EC2, test insert/search vector. Tạo skeleton FastAPI + một màn hình Chat UI tối giản trên Amplify. Hoàn thiện tính năng chính: Xây /api/chat (FastAPI) + RAG pipeline: embed query → Qdrant → Claude + citation. Xây /api/admin/: upload PDF, lưu S3 + DynamoDB, đưa message vào SQS. Viết Worker trên EC2: SQS → Textract → normalize/chunk → Titan → Qdrant → update DynamoDB. Hoàn thiện Chat UI và Admin UI (upload + xem trạng thái tài liệu). Kiểm thử, tối ưu, triển khai demo nội bộ: Test end-to-end với một tập ~50–100 paper. Thêm CloudWatch Logs/Alarms, SNS notify khi lỗi hoặc queue backlog. Điều chỉnh cấu hình EC2, Qdrant, batch size để tối ưu thời gian và chi phí. Chuẩn bị tài liệu hướng dẫn sử dụng và demo cho nhóm 50 researcher. Yêu cầu kỹ thuật Frontend \u0026amp; Auth: React/Next.js host trên AWS Amplify, CDN CloudFront, DNS Route 53. Amazon Cognito quản lý định danh và phân quyền (Researcher/Admin). Backend \u0026amp; Compute: EC2 t3.small (Private Subnet) chạy All-in-one: FastAPI, Qdrant Vector DB và Worker. Xử lý bất đồng bộ: Worker đọc SQS, kích hoạt Textract và Bedrock để index dữ liệu. IDP \u0026amp; RAG: Lưu trữ: S3 (File gốc), DynamoDB (Metadata \u0026amp; Trạng thái). AI Core: Textract (OCR tài liệu scan), Bedrock Titan (Embedding), Claude 3.5 Sonnet (Trả lời câu hỏi). Mạng \u0026amp; Observability: Network: VPC Private Subnet, VPC Endpoints để kết nối bảo mật tới AWS Services. Monitoring: CloudWatch Logs/Metrics + SNS cảnh báo sự cố (CPU cao, lỗi Worker). 5. Lộ trình \u0026amp; Mốc triển khai Dự án được thực hiện trong khoảng 6 tuần với các giai đoạn cụ thể:\nTuần 1-2 (Ngày 1-10): Nghiên cứu \u0026amp; Thiết kế Thiết kế kiến trúc chi tiết, xác định scope, dịch vụ sử dụng. Lên kế hoạch tối ưu chi phí vận hành và triển khai. Tuần 3 (Ngày 11-15): Thiết lập hạ tầng AWS Cấu hình VPC, Subnets, Security Groups, IAM Roles. Triển khai EC2 t3.small, S3 bucket, DynamoDB tables. Thiết lập VPC Endpoints (Gateway + Interface). Tuần 4 (Ngày 16-20): Backend APIs \u0026amp; IDP Pipeline Xây dựng FastAPI endpoints (/api/chat, /api/admin/upload). Tích hợp IDP pipeline: SQS → Worker → Textract → Embeddings → Qdrant. Kết nối Bedrock (Titan Embeddings + Claude 3.5 Sonnet). Tuần 5 (Ngày 21-25): Testing \u0026amp; Error Handling Kiểm thử end-to-end với tập ~50-100 papers. Xử lý edge cases, retry logic, error handling. Tối ưu chunking strategy và retrieval accuracy. Tuần 6 (Ngày 26-30): Deployment \u0026amp; Documentation Hoàn thiện UI/UX cho Admin và Researcher. Thiết lập CloudWatch Alarms + SNS notifications. Chuẩn bị tài liệu hướng dẫn và demo cho nhóm 50 researcher. 6. Ước tính ngân sách Chi phí hạ tầng (ước tính theo tháng)\nCompute \u0026amp; Storage: EC2 t3.small: $10.08 (720h). EBS gp3: $2.40 (30GB). Network: NAT Gateway: $21.60. VPC Interface Endpoints: $14.60 (2 endpoints cho Textract, Bedrock). VPC Gateway Endpoints: FREE (S3, DynamoDB). AI \u0026amp; Operations: Bedrock Claude 3.5 Sonnet: $25.00 (50 users). Bedrock Titan Embeddings: $0.75 (750 papers). CloudWatch + Data Transfer: $1.90. Free Tier (12 tháng đầu)\nWeb \u0026amp; Auth: S3, CloudFront, Cognito, Amplify (FREE). Serverless: DynamoDB, SQS, SNS (Always FREE). IDP: Textract AnalyzeDocument (100 pages/month trong 3 tháng đầu). Tổng cộng: ~$60-76/tháng (tùy mức sử dụng Bedrock).\n7. Đánh giá rủi ro Ma trận rủi ro\nHallucination (AI bịa đặt): Ảnh hưởng cao, xác suất trung bình. Vượt ngân sách (AI Services): Ảnh hưởng trung bình, xác suất trung bình. Sự cố hạ tầng (EC2/Qdrant): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nChất lượng AI: Bắt buộc trích dẫn nguồn (citation), giới hạn context đầu vào từ Qdrant. Chi phí: Thiết lập AWS Budgets/Alarms, kiểm soát số lượng tài liệu ingest. Hạ tầng \u0026amp; Bảo mật: Backup EBS định kỳ, mã hóa dữ liệu (S3/DynamoDB), phân quyền chặt chẽ qua Cognito/IAM. Kế hoạch dự phòng\nSự cố hệ thống: Khôi phục từ Snapshot, tạm dừng ingestion (buffer qua SQS). Vượt chi phí: Tạm khóa tính năng upload mới, giới hạn hạn ngạch truy vấn trong ngày. 8. Kết quả kỳ vọng Cải tiến kỹ thuật\nChuyển đổi kho tài liệu rời rạc (PDF/Scan) thành tri thức số có thể truy vấn và trích dẫn tự động. Giảm đáng kể thời gian tra cứu thủ công nhờ công nghệ RAG + IDP. Giá trị dài hạn Xây dựng nền tảng nghiên cứu số hóa cho 50+ researcher, dễ dàng mở rộng quy mô. Tạo tiền đề phát triển các tính năng nâng cao: Gợi ý tài liệu, phân tích xu hướng nghiên cứu và hỗ trợ viết tổng quan (Literature Review). "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hiểu sâu hơn về kiểm soát truy cập với AWS IAM: User, Group, Policy, Role. Biết cách thiết kế mô hình phân quyền an toàn dựa trên IAM Role và nguyên tắc “least privilege”. Thực hành tạo IAM Group, IAM User, IAM Role và kịch bản Switch Role. Nắm các khái niệm mạng cơ bản trong Amazon VPC: Subnet, Route Table, Internet Gateway, NAT Gateway. Thực hành xây dựng VPC, cấu hình Security Group, Network ACL và làm quen với Site-to-Site VPN. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan về IAM Access Control + IAM User \u0026amp; IAM Group + IAM Policy + IAM Role - Ôn lại mục tiêu bảo mật và nguyên tắc least privilege 09/23/2025 09/23/2025 https://000002.awsstudygroup.com/ 2 - Thực hành IAM (1): + Tạo Admin IAM Group + Tạo Admin User và thêm vào group + Đăng nhập bằng Admin User và kiểm tra quyền 09/24/2025 09/24/2025 https://000002.awsstudygroup.com/ 3 - Thực hành IAM (2): + Tạo Admin Role + Tạo OperatorUser + Cấu hình trust relationship cho Switch Role + Test Switch Role từ OperatorUser + Rà soát \u0026amp; dọn dẹp cấu hình không cần thiết 09/25/2025 09/25/2025 https://000002.awsstudygroup.com/ 4 - Học lý thuyết về Amazon VPC: + Subnet + Route Table + Internet Gateway + NAT Gateway - So sánh và hiểu vai trò: + Security Group + Network ACL 09/26/2025 09/26/2025 https://000003.awsstudygroup.com/ 5 - Thực hành VPC \u0026amp; Networking: + Tạo VPC, Subnet, Internet Gateway, Route Table, Security Group + Bật VPC Flow Logs + Tạo EC2 trong VPC và test kết nối + Đọc và hiểu các bước cấu hình Site-to-Site VPN 09/27/2025 09/27/2025 https://000003.awsstudygroup.com/ Thành tựu Tuần 3: Hiểu rõ hơn về các thành phần IAM trong kiểm soát truy cập:\nIAM User, IAM Group IAM Policy và cách gán quyền IAM Role và trust relationship Xây dựng được cấu trúc IAM cơ bản cho quản trị:\nTạo Admin Group, Admin User Kiểm tra quyền dựa trên group thay vì gán trực tiếp Thực hành mô hình phân quyền nâng cao:\nTạo Admin Role và OperatorUser Cấu hình và test Switch Role trong Console Áp dụng nguyên tắc least privilege khi phân quyền Nắm được các khái niệm chính của Amazon VPC:\nSubnet, Route Table, Internet Gateway, NAT Gateway Phân biệt Security Group và Network ACL Tự tay xây dựng một môi trường VPC nhỏ:\nTạo VPC, subnet, routing, lớp bảo mật Khởi tạo EC2 trong VPC và kiểm tra kết nối Bật VPC Flow Logs để quan sát traffic Nắm được luồng tổng quát để thiết lập AWS Site-to-Site VPN cho môi trường hybrid.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 6 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEVENt 1 Tên sự kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 - 17:00 , ngày 18/9/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software\nThời gian: 14:00 - 16:30, ngày 3/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nThời gian: 8:00 - 11:3, ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 8:30 - 17:00, ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 8:30 - 12:00, ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: Next Step: Create Your Workspace \u0026amp; Connect Your Cloud\nThời gian: 8:30 - 12:00, ngày 6/12/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hiểu cách khởi tạo và quản lý EC2 Windows và Linux. Thực hành triển khai ứng dụng trên EC2 (Node.js \u0026amp; AWS User Management App). Hiểu IAM governance và quản lý chi phí EC2 thông qua IAM. Hiểu cách ứng dụng truy cập dịch vụ AWS qua IAM Role thay cho Access Key. Thực hành gán IAM Role cho EC2 và kiểm tra quyền truy cập của ứng dụng. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu giới thiệu EC2 \u0026amp; bước chuẩn bị + Khái niệm EC2 + Các tài nguyên cần thiết + Yêu cầu IAM \u0026amp; networking 09/30/2025 09/30/2025 https://000004.awsstudygroup.com/ 2 - Khởi tạo EC2: + Tạo Windows Server 2022 instance + Tạo Amazon Linux instance + Kết nối và kiểm tra truy cập 10/01/2025 10/01/2025 https://000004.awsstudygroup.com/ 3 - Triển khai ứng dụng: + Triển khai AWS User Management App trên Amazon Linux 2 + Triển khai Node.js App trên Windows EC2 10/02/2025 10/02/2025 https://000004.awsstudygroup.com/ 4 - IAM Governance \u0026amp; Authorization: + Hiểu governance chi phí \u0026amp; sử dụng với IAM + So sánh Access Key vs IAM Role + Rủi ro của việc dùng Access Key lâu dài 10/03/2025 10/03/2025 https://000048.awsstudygroup.com/ 5 - Thực hành IAM Role cho EC2: + Tạo IAM Role cho EC2 + Gán Role vào EC2 instance + Kiểm tra ứng dụng truy cập AWS qua Role + Clean up resource sau bài học 10/04/2025 10/04/2025 https://000048.awsstudygroup.com/ Thành tựu Tuần 4: Khởi tạo thành công EC2 Windows và Linux. Hiểu cách chuẩn bị môi trường EC2 để triển khai ứng dụng. Triển khai thành công 2 ứng dụng: AWS User Management App (Linux) Node.js App (Windows) Hiểu rõ IAM governance \u0026amp; ảnh hưởng của IAM tới chi phí và bảo mật. Nắm được lý do không nên dùng Access Key cho ứng dụng. Tạo và gán IAM Role cho EC2, giúp ứng dụng truy cập AWS service an toàn. Kiểm tra thành công quyền truy cập dựa trên IAM Role. Dọn dẹp tài nguyên để tránh phát sinh chi phí. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Tìm hiểu các thành phần chính của EC2 và cách vận hành compute trong AWS. Nắm cơ chế Auto Scaling, EBS, Instance Store, User Data, Metadata. Thực hành backup, Storage Gateway và triển khai EC2 phục vụ cho lưu trữ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về EC2, các loại instance, AMI, key pair - Biết được EBS, Instance Store, User Data, Metadata 06/10/2025 06/10/2025 https://youtu.be/-t5h4N6vfBs?si=GeVdhO9IEDjzzS_D https://youtu.be/e7XeKdOVq40?si=T3I4pgPoEfVytcU3 https://youtu.be/yAR6QRT3N1k?si=GQghyBwLCpijrDON https://youtu.be/hKr_TfGP7NY?si=gR2MqaLAFrqL-KBo https://youtu.be/6IHNDJ85aoQ?si=M0puk6DJpliO7ahf https://youtu.be/_v_43Wi7zjo?si=qNDVWzKcQFNO2mGh https://youtu.be/Ew3QRaKJQSA?si=xNvXvD8yFhnSMJby 3 - Nắm bắt được EC2 Auto Scaling và cách scale VM - tìm hiểu về các dịch vụ lưu trữ và compute (EFS/FSx, Lightsail, MGN overview) 07/10/2025 07/10/2025 https://youtu.be/bbLcPitXJSY?si=eyVnxvL9ho0LpUYy https://youtu.be/hFVYG8WqfU0?si=9Px4wmR4IRZxk15n 4 - Thực hành: + Deploy AWS Backup + Create backup plan + Test restore \u0026amp; cleanup + Dọn dẹp backup 08/10/2025 08/10/2025 https://000013.awsstudygroup.com 5 - Thực hành: + Create S3 bucket để làm Storage Gateway + Create EC2 cho Storage Gateway + Create Storage Gateway + File Share + Dọn dẹp Storage Gateway 09/10/2025 09/10/20255 https://000024.awsstudygroup.com 6 - Thực hành: + Create bucket, upload dữ liệu + Enable static website hosting + Cấu hình public access block + Cấu hình CloudFront và test website + Dọn dẹp website + CloudFront + bucket 10/10/2025 10/10/2025 https://000057.awsstudygroup.com Kết quả đạt được tuần 5: Tổng quát:\nTrong tuần này tôi đã hiểu cơ chế vận hành EC2, các loại storage của instance, Auto Scaling và backup. Đồng thời làm quen Storage Gateway và triển khai S3 static website Lý thuyết đã học:\nKhái niệm về kiến trúc EC2, AMI, key pair EBS vs Instance Store User Data / Metadata EC2 Auto Scaling Storage Gateway và nền tảng về Backup Thực hành với bài lab:\nTạo backup plan + test restore Tạo Storage Gateway + file share Tạo static website bằng S3 + CloudFront "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 08/09/2025 đến 09/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia học tập và thực hành qua các workshop chuyên sâu về điện toán đám mây AWS, qua đó cải thiện kỹ năng làm việc với dịch vụ đám mây, phân tích công nghệ, viết báo cáo kỹ thuật và giao tiếp trong môi trường chuyên nghiệp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Điểm mạnh Tiếp thu kiến thức mới nhanh. Tuân thủ các nguyên tắc trong công việc Có trách nhiệm với công việc được giao. Hòa đồng, hỗ trợ tốt trong làm việc nhóm. Điểm cần cải thiện Tự tin giao tiếp: Cần chủ động hơn về mặc giao tiếp Đào sâu vấn đề: Tìm tòi sâu giải pháp xử lí công việc thay vì là bề mặt Kế hoạch phát triển Lập thời gian biểu chi tiết cho việc học và ôn tập hợp lí hơn. Tích cực tham gia phát biểu trong các buổi thảo luận. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Tìm hiểu tổng quan các dịch vụ lưu trữ trên AWS (S3, Glacier, Backup, Storage Gateway, Snow Family). Nắm rõ cách S3 hoạt động: access point, storage class, CORS, static website hosting. Thực hành toàn bộ quy trình với S3, Backup, Storage Gateway, File System. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu tổng quan các dịch vụ lưu trữ AWS: S3, EBS, Backup, Storage Gateway, Snow Family - Tìm hiểu Access Point, Storage Class và các mô hình truy cập dữ liệu - Nắm rõ S3 static website, CORS, Object key, Glacier 13/10/2025 13/10/2025 https://youtu.be/hsCfP0IxoaM?si=O3vMWs7Trr1fugJD https://youtu.be/_yunukwcAwc?si=ZhkTKr-_OkyUNImI https://youtu.be/mPBjB6Ltl_Q?si=qs6j0n7AeD2Mxwbz https://youtu.be/YXn8Q_Hpsu4?si=XojTnkR_LLC1KwEv 3 Thực hành: + Create S3 bucket + Deploy hạ tầng backup + Create backup plan và set up notification + Test restore và Dọn dẹp tài nguyên backup 14/10/2025 14/10/2025 https://000013.awsstudygroup.com 4 - Tìm hiểu VMware Workstation - Thực hành: + Export VM từ on-prem + Upload VM lên AWS + Import thành EC2 + Export lại thành AMI + Dọn dẹp môi trường import/export 15/10/2025 15/10/2025 https://000014.awsstudygroup.com 5 - Thực hành: + Create Storage Gateway + Create File Share nâng cao + kết nối File Share trên máy on-prem + Dọn dẹp Storage Gateway + File Shares 16/10/2025 16/10/2025 https://000024.awsstudygroup.com 6 - Thực hành(lab25): + Create FSx file system (SSD/HDD, Multi-AZ) + Create và cấu hình file shares + Test và giám sát hiệu năng + Quản lý user sessions + quotas - Thực hành(lab57): + Create bucket, upload dữ liệu, bật static website + Cấu hình public access + set quyền đối tượng + Create và cấu hình CloudFront phân phối nội dung\n+ Enable versioning và replication object - Dọn dẹp môi trường(lab25) bucket, CloudFront, replication 17/10/2025 17/10/2025 https://000025.awsstudygroup.com https://000057.awsstudygroup.com Kết quả đạt được tuần 6: Tổng quát:\nTrong tuần này tôi đã nắm được hệ sinh thái lưu trữ của AWS như S3, Glacier, Backup, Storage Gateway và các file system. Tập trung thực hành nhiều để hiểu cách quản lý dữ liệu, backup–restore và các cơ chế lưu trữ của AWS. Lý thuyết đã học:\nKhái niệm về S3 Storage Class, Access Point, CORS Học về Glacier, lifecycle, backup concepts Storage Gateway, file system kiến trúc Import/export máy ảo Thực hành với bài lab:\nBackup \u0026amp; restore Import máy ảo on-prem lên AWS Tạo file system Multi-AZ Tạo static website, CloudFront, versioning, replication Thực hành Storage Gateway – tạo file share, Kết nối thử, kiểm tra truyền dữ liệu giữa on-prem và AWS "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại AWS thông qua chương trình FCJ rất chuyên nghiệp và có nhiều sự hỗ trợ. Không gian học tập và làm việc được tổ chức một cách nghiêm túc và được vận hành tốt, giúp có thể tập trung học hỏi và tiếp thu kiến thức một cách hiệu quả nhất. Thông qua đó, AWS đã tổ chức các buổi workshop thường xuyên giúp em bổ sung kiến thức và cập nhập công nghệ mới hiện có.\n2. Sự hỗ trợ của mentor / team admin\nMentor luôn hướng dẫn em rất chi tiết, giải thích rõ ràng khi em chưa hiểu và luôn khuyến khích em đặt câu hỏi để học tốt hơn. Em đặc biệt trân trọng việc mentor cho phép em tự thử và tự giải quyết vấn đề thay vì chỉ đưa đáp án, giúp em chủ động và tiến bộ nhanh. Bên cạnh đó, team admin cũng luôn nhiệt tình hỗ trợ, chuẩn bị đầy đủ thủ tục và tài liệu, tạo điều kiện để em làm việc thuận lợi. Khi em có bất kỳ thắc mắc nào, mentor và team admin luôn phản hồi nhanh, giải đáp chi tiết và động viên em cố gắng học tập mỗi ngày.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nTrong quá trình thực tập, em đã học được rất nhiều kỹ năng quan trọng, từ kỹ thuật như làm việc với các dịch vụ AWS, cho đến kỹ năng mềm như phối hợp nhóm, trình bày và viết báo cáo. Đặc biệt, những buổi sharing từ các chuyên gia và anh hiện đang là việc tại FCJ đã mang đến cho em nhiều góc nhìn mới và là cơ hội quý giá để em mở rộng kiến thức cũng như định hướng phát triển bản thân.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người luôn tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn giữ được sự vui vẻ. Khi có dự án gấp, tất cả đều cùng nhau nỗ lực và hỗ trợ mà không phân biệt vị trí hay vai trò.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi em cần. Bên cạnh đó, việc được tham gia các buổi đào tạo nội bộ, workshop và chia sẻ kiến thức cũng là một điểm cộng lớn, giúp em học hỏi thêm nhiều kỹ năng thực tế.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nTrong suốt thời gian thực tập, em hài lòng nhất khi được tham gia trực tiếp vào các công việc liên quan đến DevOps và AWS. Việc được tự tay triển khai hạ tầng, cấu hình dịch vụ và xử lý các vấn đề thực tế giúp em tiến bộ rất nhanh. Em cũng học hỏi được nhiều tư duy DevSecOps từ mentor, đặc biệt là trong quản lý IAM, CI/CD và vận hành hệ thống.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nEm nghĩ công ty có thể bổ sung thêm các buổi thực hành DevOps nâng cao, chẳng hạn như xây dựng CI/CD pipeline hoàn chỉnh, mô phỏng sự cố (incident simulation) hoặc làm thêm mini-project theo nhóm. Điều này sẽ giúp thực tập sinh có góc nhìn rộng hơn về vận hành hệ thống trong thực tế.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nCó! Chương trình mang lại kiến thức DevOps và AWS rất thực tế, được thực hành chứ không chỉ học lý thuyết. Mentor hỗ trợ tận tâm, môi trường chuyên nghiệp nhưng thân thiện, và đặc biệt phù hợp cho sinh viên muốn theo hướng Cloud/DevOps.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nEm nghĩ là chương trình thêm những bài thực thành theo nhóm rồi mới làm một bài tổng kết.\nBạn có muốn tiếp tục chương trình này trong tương lai? Nếu được tiếp tục, em hy vọng sẽ được tham gia vào các nội dung nâng cao hơn, chẳng hạn như xây dựng hệ thống DevOps hoàn chỉnh, triển khai CI/CD đa môi trường, tối ưu chi phí AWS\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Tìm hiểu toàn bộ IAM: user, group, role, policy, permission boundary. Tìm hiểu cơ chế xác thực và phân quyền trong AWS, cách viết policy JSON và cách evaluate. Làm quen AWS Organizations, OU, Service Control Policy (SCP). Thực hành lab IAM + Organization để hình dung cách quản lý tài khoản ở quy mô lớn. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu tổng quan IAM: user, group, role, policy - Nắm cách hoạt động của policy evaluation: explicit deny, implicit deny, allow 20/10/2025 20/10/2025 https://youtu.be/tsobAlSg19g?si=9f3mlIWPtrCcNuKg https://youtu.be/N_vlJGAqZxo?si=e8oiWCObco95CoKh 3 - Thực hành: + Create user/group/role + Gán inline policy \u0026amp; managed policy + Test truy cập S3/EC2 theo từng policy - Tìm hiểu permission boundary và session policy 21/10/2025 21/10/2025 https://000028.awsstudygroup.com 4 - Tìm hiểu AWS Organizations: cấu trúc OU, tạo nhiều account - Khái niệm SCP, deny list, allow list 22/10/2025 22/10/2025 https://youtu.be/5oQY8Rogz9Y?si=h8DlUb8ZLI4HbbvM https://youtu.be/NW1xrMkNMjU?si=dhT0T3y2JYVK8QwT 5 - Thực hành: + Create Organization + OU + Áp dụng SCP deny Ec2 / deny S3 + Kiểm tra hiệu lực SCP kết hợp IAM polic + Sắp xếp lại OU, remove SCP 23/10/2025 23/10/2025 https://000030.awsstudygroup.com https://000044.awsstudygroup.com/ 6 - Làm việc nhóm: + Thảo luận ý tưởng về workshop + Cách thực hiện + Chia phần cho workshop 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Tổng quát:\nTrong tuần này tôi đã nắm được nền tảng quản lý truy cập AWS, bao gồm IAM và Organizations. Hiểu cách vận hành của policy, cách viết, cách đánh giá quyền, và cách áp dụng SCP trong môi trường nhiều account. Lý thuyết đã học:\nKhái niệm về User – Group – Role – Policy và cơ chế evaluate Inline policy, managed policy, permission boundary Cấu trúc AWS Organizations, OU Khái niệm SCP và sự khác biệt so với IAM policy Landing Zone – Control Tower overview Thực hành với bài lab:\nTạo user/group/role và test truy cập Viết policy JSON và thử deny/allow theo từng hành vi Tạo Organization, OU và áp SCP Kiểm tra sự kết hợp SCP + IAM policy trong thực tế "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Tìm hiểu hệ thống cơ sở dữ liệu trên AWS: RDS, Aurora, Redshift, ElastiCache. Thực hành xây dựng database subnet group, test kết nối, backup \u0026amp; restore. Tìm hiểu các dịch vụ phân tích dữ liệu như Kinesis, Glue, Athena, QuickSight. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Database: RDS, Aurora, Redshift, ElastiCache - Tìm hiểu về kiến trúc multi-AZ, read replica, backup/restore 27/10/2025 27/10/2025 https://youtu.be/OOD2RwWuLRw?si=9JsOs0PNfO1TdAUl https://youtu.be/qbrobQZrokY?si=ePJjzYXWg3qE_Ca6 https://youtu.be/UvdiRW34aNI?si=8g3FwgsJ3VLT-_nf 3 - Thực hành: + Create VPC + SG cho EC2 + RDS + Create DB subnet group + Deploy EC2 + Tạo RDS instance + Backup \u0026amp; Restore 28/10/2025 28/10/2025 https://000005.awsstudygroup.com 4 - Thực hành: + Kết nối MSSQL/Oracle + Schema Conversion + Create DMS Task + Inspect logs, troubleshoot 29/10/2025 29/10/20255 https://000043.awsstudygroup.com 5 - Tìm hiểu tổng quan về Data Analytics (Kinesis, Glue, Athena, QuickSight) - Thực hành: + Create DynamoDB table + Enable autoscaling + CRUD test Create Global Table và dọn dẹp resources 30/10/2025 30/10/2025 https://000039.awsstudygroup.com 6 - Thực hành(lab35): + Create S3 bucket + Create Kinesis Firehose ingestion + Glue crawler + Query dữ liệu bằng Athena + Create dashboard QuickSight - Thực hành(lab40): + Kiểm tra cost allocation + CTagging resource + Query bổ sung và dọn dẹp Resources 31/10/2025 31/10/2025 https://000035.awsstudygroup.com https://000040.awsstudygroup.com Kết quả đạt được tuần 8: Tổng quát:\nTrong tuần này tôi tập trung học các dịch vụ database và data analytics trên AWS, bao gồm RDS, Aurora, DynamoDB, DMS, Kinesis, Glue, Athena và QuickSight. Tôi hiểu rõ kiến trúc triển khai database, cách kết nối, backup/restore, autoscaling cũng như pipeline phân tích dữ liệu đầu cuối từ ingestion -\u0026gt; ETL -\u0026gt; query -\u0026gt; visualization. Lý thuyết đã học:\nKhái niệm về Kiến trúc của RDS, Aurora, Multi-AZ, read replicas Backup, snapshot, parameter group, option group DynamoDB: partition key, sort key, throughput, autoscaling, DAX Tổng quan Data Analytics: Kinesis Firehose, Glue crawler, Athena, QuickSight Kiến thức về Database Migration: schema conversion, DMS task Thực hành với bài lab:\nTạo VPC + security group riêng cho EC2/RDS Tạo DB subnet group, deploy EC2 và RDS MySQL Backup \u0026amp; Restore database Kết nối MSSQL/Oracle, thực hành Schema Conversion \u0026amp; tạo DMS task Tạo DynamoDB table, bật autoscaling, CRUD test, tạo Global Table và cleanup Xây dựng pipeline: Kinesis Firehose -\u0026gt; S3, chạy Glue crawler, query dữ liệu bằng Athena và dựng dashboard trên QuickSight. Thực hành các tác vụ bổ sung: tagging, cost allocation và cleanup "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Tìm hiểu tổng quan kiến trúc Serverless và các thành phần chính: API Gateway, Lambda, DynamoDB. Thiết kế kiến trúc tổng thể cho ứng dụng: backend, frontend, xác thực, bảo mật và tích hợp. Nghiên cứu lớp bảo mật (Edge \u0026amp; Security): CloudFront, Route 53, WAF. Tìm hiểu hệ thống xác thực với Amazon Cognito và cách cấp token cho API. Phân tích cách triển khai CI/CD với CodePipeline, CodeBuild, GitLab và IaC (CloudFormation). Tìm hiểu hệ thống quan sát/giám sát: CloudWatch, X-Ray, SNS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu kiến trúc Serverless - API Gateway, Lambda, DynamoDB \u0026amp; cơ chế tích hợp 03/11/2025 03/11/2025 3 - Thiết kế kiến trúc tổng thể (BE + FE + Auth + Edge) - Vẽ sơ đồ kiến trúc \u0026amp; luồng request 04/11/2025 04/11/2025 4 - Tìm hiểu CloudFront, Route 53, WAF - Thiết kế lớp bảo mật trước API Gateway 05/11/2025 05/11/2025 5 - Tìm hiểu Cognito (User Pool, Token) - Phân tích cách API Gateway validate JWT token 06/11/2025 06/11/2025 6 - Tìm hiểu CI/CD: CloudFormation, CodePipeline, CodeBuild - Hệ thống quan sát: CloudWatch, X-Ray, SNS 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Tổng quát:\nTrong tuần này tôi tập trung hiểu và thiết kế kiến trúc Serverless cho ứng dụng. Tôi đã nắm rõ luồng hoạt động của API Gateway – Lambda – DynamoDB, đồng thời nghiên cứu lớp bảo mật bằng CloudFront/WAF và hệ thống xác thực bằng Cognito. Tôi cũng nắm được quy trình CI/CD và cơ chế logging/monitoring để chuẩn bị cho các tuần code tiếp theo. Lý thuyết đã học:\nKiến trúc Serverless, nguyên tắc pay-per-use và autoscaling. API Gateway REST API, Lambda integration, DynamoDB table workflow. CloudFront + WAF + Route 53 để bảo vệ API. Cognito User Pool \u0026amp; Token (ID/Access), JWT flow qua API Gateway authorizer. CI/CD với CodePipeline + CodeBuild + CloudFormation. CloudWatch logs/metrics, SNS alert, tracing bằng X-Ray. Thực hành / Sản phẩm:\nSơ đồ kiến trúc tổng thể ứng dụng (BE – FE – Auth – Edge). Luồng request từ client -\u0026gt; CloudFront -\u0026gt; API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB. Diagram bảo mật: CDN, DNS, WAF, throttling \u0026amp; protection tại API Gateway. Phác thảo pipeline tự động triển khai bằng CloudFormation \u0026amp; CodePipeline. Thiết kế flow xác thực Cognito -\u0026gt; API Gateway JWT Authorizer. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thiện 100% Backend CRUD bằng .NET chạy trên Aspire AppHost. Xây dựng và kiểm thử mô hình dữ liệu DynamoDB trên môi trường local (Docker). Tích hợp DynamoDB Local với NoSQL Workbench để validate mô hình. Làm việc cùng nhóm FE để hoàn thiện giao diện cơ bản và kết nối API local. Chuẩn bị nền tảng vững chắc trước khi chuyển sang tuần 11 (chuyển code lên Lambda + API Gateway). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Kiểm tra \u0026amp; cài đặt lại môi trường BE: .NET SDK, Docker Desktop, NoSQL Workbench - Nắm sơ đồ kiến trúc hệ thống và luồng xử lý backend 10/11/2025 10/11/2025 3 - Setup DynamoDB Local bằng Docker - Kết nối \u0026amp; trực quan hóa bằng NoSQL Workbench, test CRUD thủ công 11/11/2025 11/11/2025 4 - Code DAL/Repository bằng .NET + AWSSDK.DynamoDBv2 - Tích hợp DI vào Aspire AppHost - Viết logic nghiệp vụ tại BLL 12/11/2025 12/11/2025 5 - Viết API Controllers CRUD - Test unit \u0026amp; integration trên môi trường local 13/11/2025 13/11/2025 6 - Làm việc chung với nhóm FE - Build giao diện sơ bộ (List/Create) - FE kết nối API Local, test end-to-end 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Tổng quát:\nTrong tuần này tôi đã hoàn thiện toàn bộ phần backend chạy local bằng Aspire AppHost, xây dựng mô hình dữ liệu DynamoDB, test CRUD và tích hợp với frontend. Nhờ đảm bảo kiến trúc và code local hoàn chỉnh, tôi có nền tảng vững chắc để chuyển sang Lambda/API Gateway ở tuần 11. Lý thuyết đã học:\nThiết kế dữ liệu DynamoDB theo Single-Table Design, Access Pattern, PK/SK. Kiến thức về DynamoDB Local, NoSQL Workbench, Docker setup. Cách sử dụng AWSSDK.DynamoDBv2 trong .NET và tích hợp DI. Cấu trúc Backend ASP.NET (Controller -\u0026gt; BLL -\u0026gt; Repository). Cách FE gọi API local, xử lý response và render dữ liệu. Thực hành / Sản phẩm:\nTạo DynamoDB Local bằng Docker và quản lý schema qua NoSQL Workbench. Build Repository + BLL + Controllers bằng .NET 8 / Aspire AppHost. Hoàn thiện 5–6 API CRUD (POST/GET/PUT/DELETE/List). Viết unit test cho BLL và integration test cho API. FE team triển khai giao diện List + Create và test thành công với API local. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Hoàn thiện giao diện FE cùng nhóm Frontend. Phối hợp kiểm thử end-to-end giữa FE và BE. Tìm hiểu quy trình deploy tổng thể hệ thống (API, FE, cơ sở dữ liệu, hạ tầng) để nắm kiến thức chung, dù không phải người chịu trách nhiệm chính. Chuẩn bị các ghi chú cần thiết cho tuần 12 (viết tài liệu \u0026amp; tổng kết). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm việc chung với nhóm FE để hoàn thiện giao diện còn thiếu - - Rà soát lại API contract giữa FE và BE 17/11/2025 17/11/2025 3 - FE tích hợp API đầy đủ các luồng CRUD - Fix lỗi sai schema, payload, status code trong quá trình FE test 18/11/2025 18/11/2025 4 - Test end-to-end toàn bộ luồng: List -\u0026gt; Create -\u0026gt; Update -\u0026gt; Delete từ FE tới BEI - Cập nhật lại response model/validation cho phù hợp FE 19/11/2025 19/11/2025 \u0026lt; 5 - Tìm hiểu quy trình deploy của nhóm (CI/CD, API Gateway, Lambda, S3 + CloudFront) - Ghi chú các bước để chuẩn bị cho tuần 12 viết tài liệu 20/11/2025 20/11/2025 6 - Tổng hợp issue FE và BE trong tuần + - Rà soát lại toàn bộ phần BE để chuẩn bị cho môi trường deploy (dù không trực tiếp triển khai) 21/11/2025 21/11/20255 Kết quả đạt được tuần 11: Tổng quát:\nTrong tuần này tôi chủ yếu phối hợp với nhóm FE để hoàn thiện giao diện và tích hợp API. Sau khi BE đã xong ở tuần 10, tôi hỗ trợ fix lỗi, chuẩn hóa contract API và kiểm thử end-to-end. Ngoài ra, tôi cũng tìm hiểu quy trình deploy của nhóm (Lambda, API Gateway, S3/CloudFront, CI/CD) để chuẩn bị cho việc viết tài liệu ở tuần 12. Lý thuyết đã học:\nCách FE gọi API CRUD và debug request. API Contract: schema input/output, error format, status code. Quy trình deploy: .NET -\u0026gt; Lambda, API Gateway routing, FE build -\u0026gt; S3/CloudFront. Tổng quan CI/CD pipeline và chuẩn bị code cho deploy (config, logging). Thực hành / Sản phẩm:\nPhối hợp FE hoàn thiện màn hình List/Create/Update/Delete. Điều chỉnh backend theo yêu cầu FE (schema, validation, status code). Test end-to-end toàn bộ luồng FE ↔ BE trên local. Ghi chú quy trình deploy để dùng cho tuần 12. Tổng hợp lỗi FE và BE và cập nhật backlog nhóm. "},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://khanguyense.github.io/fcj_workshop/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]