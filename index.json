[{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Create a gateway endpoint","tags":[],"description":"","content":" Open the Amazon VPC console In the navigation pane, choose Endpoints, then click Create Endpoint: You will see 6 existing VPC endpoints that support AWS Systems Manager (SSM). These endpoints were deployed automatically by the CloudFormation Templates for this workshop.\nIn the Create endpoint console: Specify name of the endpoint: s3-gwe In service category, choose AWS services In Services, type s3 in the search box and choose the service with type gateway For VPC, select VPC Cloud from the drop-down. For Configure route tables, select the route table that is already associated with two subnets (note: this is not the main route table for the VPC, but a second route table created by CloudFormation). For Policy, leave the default option, Full Access, to allow full access to the service. You will deploy a VPC endpoint policy in a later lab module to demonstrate restricting access to S3 buckets based on policies. Do not add a tag to the VPC endpoint at this time. Click Create endpoint, then click x after receiving a successful creation message. "},{"uri":"https://khanguyense.github.io/fcj_workshop/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Nguyen Tuan Kha\nPhone Number: 0835173787\nEmail: khantse183212@fpt.edu.vn\nUniversity: FPT University Ho Chi Minh campus\nMajor: Software Engineer\nClass: AWS092025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 06/09/2025 to 09/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"VPC endpoints VPC endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components. They allow communication between your compute resources and AWS services without imposing availability risks. Compute resources running in VPC can access Amazon S3 using a Gateway endpoint. PrivateLink interface endpoints can be used by compute resources running in VPC or on-premises. Workshop overview In this workshop, you will use two VPCs.\n\u0026ldquo;VPC Cloud\u0026rdquo; is for cloud resources such as a Gateway endpoint and an EC2 instance to test with. \u0026ldquo;VPC On-Prem\u0026rdquo; simulates an on-premises environment such as a factory or corporate datacenter. An EC2 instance running strongSwan VPN software has been deployed in \u0026ldquo;VPC On-prem\u0026rdquo; and automatically configured to establish a Site-to-Site VPN tunnel with AWS Transit Gateway. This VPN simulates connectivity from an on-premises location to the AWS cloud. To minimize costs, only one VPN instance is provisioned to support this workshop. When planning VPN connectivity for your production workloads, AWS recommends using multiple VPN devices for high availability. "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Prepare the environment","tags":[],"description":"","content":"To prepare for this part of the workshop you will need to:\nDeploying a CloudFormation stack Modifying a VPC route table. These components work together to simulate on-premises DNS forwarding and name resolution.\nDeploy the CloudFormation stack The CloudFormation template will create additional services to support an on-premises simulation:\nOne Route 53 Private Hosted Zone that hosts Alias records for the PrivateLink S3 endpoint One Route 53 Inbound Resolver endpoint that enables \u0026ldquo;VPC Cloud\u0026rdquo; to resolve inbound DNS resolution requests to the Private Hosted Zone One Route 53 Outbound Resolver endpoint that enables \u0026ldquo;VPC On-prem\u0026rdquo; to forward DNS requests for S3 to \u0026ldquo;VPC Cloud\u0026rdquo; Click the following link to open the AWS CloudFormation console. The required template will be pre-loaded into the menu. Accept all default and click Create stack. It may take a few minutes for stack deployment to complete. You can continue with the next step without waiting for the deployemnt to finish.\nUpdate on-premise private route table This workshop uses a strongSwan VPN running on an EC2 instance to simulate connectivty between an on-premises datacenter and the AWS cloud. Most of the required components are provisioned before your start. To finalize the VPN configuration, you will modify the \u0026ldquo;VPC On-prem\u0026rdquo; routing table to direct traffic destined for the cloud to the strongSwan VPN instance.\nOpen the Amazon EC2 console\nSelect the instance named infra-vpngw-test. From the Details tab, copy the Instance ID and paste this into your text editor\nNavigate to the VPC menu by using the Search box at the top of the browser window.\nClick on Route Tables, select the RT Private On-prem route table, select the Routes tab, and click Edit Routes.\nClick Add route. Destination: your Cloud VPC cidr range Target: ID of your infra-vpngw-test instance (you saved in your editor at step 1) Click Save changes "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.12-week12/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS and fundamental services (Cloud Fundamentals, IAM, Budget, Support).\nWeek 2: Learning basic VPC and foundational networking concepts.\nWeek 3: Advanced EC2 inside VPC, NAT Gateway, Security Group, DNS Resolver.\nWeek 4: VPC Peering, Transit Gateway, and complex VPC-to-VPC connectivity.\nWeek 5: Compute Services: EC2, Auto Scaling, Backup, and Storage Gateway.\nWeek 6: Advanced Storage: S3, Glacier, FSx, and Storage Gateway.\nWeek 7: Advanced IAM, AWS Organizations, Identity Center, KMS.\nWeek 8: Database Services, ETL (Kinesis/Glue/Athena), DMS Migration.\nWeek 9: Workshop – Designing system architecture on AWS (Architecture Design).\nWeek 10: Workshop – Building Database + Backend + Frontend.\nWeek 11: Workshop – Completing Frontend + Deploying the entire system.\nWeek 12: Workshop – Testing, optimizing \u0026amp; writing the final project report.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS and fundamental services (Cloud Fundamentals, IAM, Budget, Support).\nWeek 2: Learning basic VPC and foundational networking concepts.\nWeek 3: Advanced EC2 inside VPC, NAT Gateway, Security Group, DNS Resolver.\nWeek 4: VPC Peering, Transit Gateway, and complex VPC-to-VPC connectivity.\nWeek 5: Compute Services: EC2, Auto Scaling, Backup, and Storage Gateway.\nWeek 6: Advanced Storage: S3, Glacier, FSx, and Storage Gateway.\nWeek 7: Advanced IAM, AWS Organizations, Identity Center, KMS.\nWeek 8: Database Services, ETL (Kinesis/Glue/Athena), DMS Migration.\nWeek 9: Workshop – Designing system architecture on AWS (Architecture Design).\nWeek 10: Workshop – Building Database + Backend + Frontend.\nWeek 11: Workshop – Completing Frontend + Deploying the entire system.\nWeek 12: Workshop – Testing, optimizing \u0026amp; writing the final project report.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Nâng cao hiệu quả đào tạo phân tích bộ gen vi khuẩn với Amazon WorkSpaces\nTác giả: Satsawat Natakarnkitkul, Charlie Lee, và Sikharin Kongpaiboon\nNgày đăng: ngày 04 tháng 04 năm 2025|\nDanh mục: Amazon WorkSpaces, Education, Healthcare, Higher education, Public Sector | Permalink|\nCác hội thảo phân tích bộ gen vi khuẩn yêu cầu các công cụ bioinformatics chuyên biệt và sức mạnh tính toán lớn để xử lý dữ liệu giải trình tự. Khi Trung tâm Nghiên cứu Y khoa Siriraj lên kế hoạch tổ chức “Hội thảo Nanopore: chuỗi hội thảo tin sinh học về bộ gen vi khuẩn” cho hơn 60 nhà nghiên cứu, họ đã gặp phải thách thức phổ biến: làm thế nào để cung cấp môi trường tính toán hiệu suất cao, đồng nhất cho các phân tích bộ gen phức tạp. Amazon Web Services (AWS) đã giải quyết vấn đề này thông qua Amazon WorkSpaces, thay đổi cách Trung tâm Nghiên cứu Y khoa Siriraj cung cấp đào tạo thực hành về bộ gen vi khuẩn.\nBạn có thể sử dụng Amazon WorkSpaces để cấp phát các máy tính để bàn ảo trên nền tảng đám mây, gọi là WorkSpaces, cho người dùng của mình. Những máy tính để bàn này có thể chạy Microsoft Windows, Amazon Linux 2, Ubuntu Linux, Rocky Linux hoặc Red Hat Enterprise Linux. WorkSpaces loại bỏ nhu cầu mua sắm và triển khai phần cứng hoặc cài đặt phần mềm phức tạp. Bạn có thể nhanh chóng thêm hoặc bớt người dùng khi nhu cầu thay đổi. Người dùng có thể truy cập máy tính để bàn ảo của mình từ nhiều thiết bị hoặc trình duyệt web khác nhau. Với những lợi ích này, người dùng có thể làm việc hiệu quả mà không cần phải lo lắng về máy tính để bàn của họ.\nThách thức Các hội thảo đào tạo về bộ gen vi khuẩn do Trung tâm Nghiên cứu Y khoa Siriraj tổ chức thường gặp phải nhiều khó khăn tài nguyên tính toán, cài đặt phần mềm, cũng như khả năng tiếp cận và mở rộng cơ sở hạ tầng.\nMột trong những thách thức lớn nhất là sự khác biệt về cấu hình phần cứng giữa các học viên. Nhiều người dùng phải sử dụng laptop cá nhân với hệ điều hành, tốc độ xử lý, bộ nhớ khác nhau, dẫn đến hiệu suất không đồng đều. Sự khác biệt này thường gây ra lỗi hệ thống, tốc độ xử lý chậm và không thể chạy các phân tích genome đòi hỏi tài nguyên lớn hiệu quả.\nViệc cài đặt và cấu hình phần mềm là trở ngại chính. Các công cụ bioinformatics như EPI2ME, phổ biến trong việc lắp ráp và phân tích bộ gen vi khuẩn, yêu cầu các gói phụ thuộc (dependencies) và cấu hình đặc thù. Đảm bảo tương thích trên nhiều thiết bị khác nhau thường làm gián đoạn tiến độ, khiến giảng viên mất thời gian xử lý sự cố thay vì tập trung vào thực hành.\nXử lý dữ liệu bộ gen vi khuẩn cần máy tính mạnh mà phần đông học viên không có sẵn. Thiếu tài nguyên tính toán dẫn đến việc không hoàn thành bài tập, gây thất vọng và làm giảm hiệu quả học tập. Laptop cá nhân thường không đủ khả năng xử lý các phép tính phức tạp trong phân tích dữ liệu DNA, làm hạn chế việc thực hành.\nPhương pháp giảng dạy truyền thống cũng giới hạn số lượng học viên mà tổ chức có thể đào tạo. Nhiều tổ chức thiếu cơ sở hạ tầng cần thiết để đáp ứng nhu cầu đào tạo ngày càng tăng, đặc biệt cho các buổi đào tạo kết hợp hoặc trực tuyến.\nXây dựng môi trường học tập trên nền tảng đám mây Oxford Nanopore Centre of Excellence (Thái Lan), Yip In Tsoi ( Đối tác AWS) và AWS đã phối hợp khởi xướng và tổ chức một hội thảo nhằm giải quyết những thách thức cấp bách này trong đào tạo tin sinh học, đặc biệt liên quan đến giới hạn phần cứng, vấn đề tương thích phần mềm, và sức mạnh tính toán. Hội thảo hợp tác này sử dụng WorkSpaces như một môi trường tính toán tập trung trên đám mây cho tất cả học viên, cung cấp một môi trường học tập tiêu chuẩn trên đám mây. WorkSpaces là dịch vụ máy tính để bàn ảo được quản lý toàn phần, cung cấp tài nguyên tính toán đã được cấu hình sẵn, giúp đảm bảo mọi học viên có cùng môi trường làm việc.\nMột trong những lợi ích chính của WorkSpaces là loại bỏ sự trì hoãn do cài đặt và cấu hình phần mềm. Tất cả các công cụ bioinformatics cần thiết cho hội thảo—bao gồm EPI2ME—đã được cài đặt sẵn và tối ưu, giúp học viên bắt đầu thực hành ngay lập tức.\nSức mạnh tính toán của WorkSpaces đóng vai trò quan trọng nâng cao trải nghiệm hội thảo. Nhờ truy cập nguồn tài nguyên đám mây mạnh mẽ, học viên có thể thực hiện lắp ráp bộ gen, căn chỉnh trình tự, và phân tích so sánh genome mà không gặp giới hạn về hiệu suất. Sự đồng đều trong tài nguyên tính toán giúp mọi học viên hoàn thành bài tập cùng tiến độ, tạo môi trường học tập hiệu quả hơn.\nKhả năng mở rộng và tiếp cận cũng là điểm mạnh của WorkSpaces. Học viên có thể đăng nhập WorkSpaces từ bất kỳ thiết bị nào, loại bỏ giới hạn về địa lý và phần cứng. Tính linh hoạt của WorkSpaces cũng giúp tổ chức dễ dàng đáp ứng số lượng học viên lớn mà không phải lo lắng về hạ tầng tính toán.\nKết quả hội thảo Trong ba ngày hội thảo, WorkSpaces được sử dụng rộng rãi. Học viên tham gia các bài tập như giải trình tự bằng công nghệ Oxford Nanopore (ONT), lắp ráp bộ gen bằng EPI2ME, và phân tích so sánh bộ gen gồm cgMLST và nghiên cứu ổ dịch.\nViệc triển khai WorkSpaces giúp hội thảo diễn ra suôn sẻ mà không gặp khó khăn kỹ thuật, cải thiện đáng kể so với các lần trước khi việc cài đặt và khắc phục lỗi có thể mất đến 3 giờ đồng hồ. Hiệu suất tính toán được giữ ổn định, giúp học viên tập trung phân tích dữ liệu thay vì gặp sự cố hoặc xử lý chậm.\nPhản hồi từ học viên cho thấy WorkSpaces đã giúp nâng cao hiệu quả đào tạo tin sinh học. Nhiều học viên cho biết môi trường tính toán tiêu chuẩn giúp họ tập trung vào nội dung học mà không phải lo ngại về hạn chế phần cứng hay lỗi phần mềm. Giảng viên cũng nhận thấy hiệu quả giảng dạy được cải thiện rõ rệt khi không phải mất thời gian xử lý các vấn đề kỹ thuật.\nTương lai phát triển Việc tích hợp thành công WorkSpaces với hội thảo Nanopore cho thấy công nghệ đám mây có thể thay đổi cách đào tạo. Bởi vì các rào cản công nghệ truyền thống đã được loại bỏ, học viên có thể tập trung hơn vào phân tích bộ gen vi khuẩn.\nTrong tương lai, có tiềm năng mở rộng sử dụng WorkSpaces trong các chương trình đào tạo genomics khác—đặc biệt là các dự án quy mô lớn—như:\nNâng cao khả năng phân tích bộ gen với AWS HealthOmics Xử lý và phân tích bộ dữ liệu lớn với AWS Batch Tự động hóa quy trình phân tích genome với AWS Lambda Những giải pháp này có thể cải thiện hơn nữa giáo dục tin sinh học bằng cách tối ưu hóa quy trình phân tích dữ liệu. Các tổ chức cũng đang nghiên cứu tích hợp WorkSpaces vào các mô hình học từ xa, giúp mở rộng sự tham gia của sinh viên và nhà nghiên cứu trên toàn cầu.\nĐể tìm hiểu thêm và bắt đầu, hãy liên hệ với nhóm tài khoản AWS của bạn hoặc nhóm hỗ trợ AWS Public Sector team.\nTài nguyên bổ sung Genomics on AWS Amazon WorkSpaces Documentation Siriraj Long-read Lab (Si-LoL), Oxford Nanopore Centre of Excellence (Thailand) Được đồng viết bởi Oxford Nanopore Centre of Excellence (Thailand), YIP In Tsoi (Đối tác AWS), và AWS.\nTAGS : Amazon Workspaces,AWS education,AWS for higher education,AWS healthcare, genomics, healthcare\nTác giả: Satsawat Natakarnkitkul: Trưởng nhóm dữ liệu và AI cho khu vực ASEAN tại AWS Thái Lan, dẫn dắt các sáng kiến AI tạo sinh trên khắp Đông Nam Á. Với hơn một thập kỷ kinh nghiệm trong chuyển đổi số và các giải pháp AI/ML, ông là chuyên gia đầu ngành trong trí tuệ nhân tạo, khoa học dữ liệu, và kiến trúc đám mây. Ông thường xuyên phát biểu tại các sự kiện công nghệ khu vực ASEAN, và nhiệt huyết sử dụng công nghệ mới như AI tạo sinh để tạo giá trị thực tế trong khu vực công.\nCharlie Lee: Chuyên gia hàng đầu về ngành genomics khu vực châu Á - Thái Bình Dương và Nhật Bản của AWS, có bằng tiến sĩ khoa học máy tính chuyên sâu về tin sinh học. Ông là nhà lãnh đạo trong lĩnh vực tin sinh học, genomics, và chẩn đoán phân tử, đam mê thúc đẩy nghiên cứu và cải thiện chăm sóc sức khỏe qua genomics với các công nghệ giải trình tự tiên tiến và điện toán đám mây.\nSikharin Kongpaiboon: Kiến trúc sư giải pháp tại AWS, hỗ trợ khách hàng hiểu và áp dụng tốt nhất các giải pháp đám mây, tối ưu triển khai. Ông phối hợp chặt chẽ với khách hàng để thiết kế kiến trúc đám mây có khả năng mở rộng, linh hoạt, và chịu lỗi cao, giúp giải quyết các thách thức kinh doanh và tăng tính nhanh nhẹn, hiệu quả, và an toàn.\nCác tài nguyên: AWS in the Public Sector\nAWS for Government\nAWS for Education\nAWS for Nonprofits\nAWS for Public Sector Health\nAWS for Aerospace and Satellite Solutions\nCase Studies\nFix This Podcast\nAdditional Resources\nContact Us\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng cường deployment guardrails với tính năng rolling update cho inference component trên Amazon SageMaker AI inference\nBài viết này có đồng tác giả là : Melanie Li, Andrew Smith, Dustin Liu, Vivek Gangasani, Shikhar Mishra, và June Won\nNgày: 25 tháng 3, 2025 | in Amazon SageMaker, Amazon SageMaker AI, Intermediate (200) Permalink | Comments | Share\nTriển khai các mô hình một cách hiệu quả, tin cậy và tiết kiệm chi phí là một thách thức quan trọng đối với các tổ chức ở mọi quy mô. Khi ngày càng nhiều tổ chức triển khai các foundation model (FM) và các mô hình machine learning (ML) khác vào môi trường production, họ phải đối mặt với những thách thức liên quan đến việc tận dụng tài nguyên, hiệu quả chi phí và duy trì tính khả dụng cao trong quá trình cập nhật. Amazon SageMaker AI đã giới thiệu chức năng inference component có thể giúp các tổ chức giảm chi phí triển khai mô hình bằng cách tối ưu hóa việc sử dụng tài nguyên thông qua khả năng đóng gói và mở rộng mô hình thông minh. Inference component trừu tượng hóa các mô hình ML và cho phép phân bổ tài nguyên chuyên dụng cũng như các chính sách mở rộng cụ thể cho từng mô hình.\nTuy nhiên, việc cập nhật các mô hình này—đặc biệt trong môi trường production với các SLA về độ trễ nghiêm ngặt—về mặt lịch sử có nguy cơ gây downtime hoặc tắc nghẽn tài nguyên. Các triển khai blue/green truyền thống thường gặp khó khăn với những hạn chế về năng lực, khiến việc cập nhật trở nên khó dự đoán đối với các mô hình sử dụng GPU nặng. Để giải quyết vấn đề này, chúng tôi rất vui mừng công bố một cải tiến mạnh mẽ khác cho RageMaker AI:tính năng rolling update cho inference component endpoint, một tính năng được thiết kế để đơn giản hóa việc cập nhật cho các mô hình có kích thước khác nhau đồng thời giảm thiểu chi phí vận hành.\nTrong bài viết này, chúng tôi thảo luận về những thách thức mà các tổ chức phải đối mặt khi cập nhật mô hình trong production. Sau đó, chúng tôi đi sâu vào tính năng rolling update mới cho inference component và cung cấp các ví dụ thực tế sử dụng các mô hình DeepSeek distilled để minh họa tính năng này. Cuối cùng, chúng tôi khám phá cách thiết lập rolling update trong các tình huống khác nhau.\nNhững thách thức với triển khai blue/green Theo truyền thống, RageMaker AI inference đã hỗ trợ mô hình triển khai blue/green để cập nhật inference component trong production. Mặc dù có hiệu quả trong nhiều tình huống, cách tiếp cận này đi kèm với những thách thức cụ thể:\nKém hiệu quả về tài nguyên – Triển khai blue/green yêu cầu cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Đối với các inference component chạy trên các GPU instance đắt tiền như P4d hoặc G5, điều này có nghĩa là có khả năng tăng gấp đôi yêu cầu tài nguyên trong quá trình triển khai. Hãy xem xét một ví dụ trong đó khách hàng có 10 bản sao của một inference component phân bố trên 5 instance ml.p4d.24xlarge, tất cả đều hoạt động với công suất đầy đủ. Với triển khai blue/green, SageMaker AI sẽ cần cung cấp thêm năm instance ml.p4d.24xlarge để lưu trữ phiên bản mới của inference component trước khi chuyển đổi lưu lượng và ngừng sử dụng các instance cũ. Tài nguyên tính toán hạn chế – Đối với khách hàng sử dụng các GPU instance mạnh mẽ như dòng P hoặc G, năng lực cần thiết có thể không có sẵn trong một Availability Zone hoặc Region nhất định. Điều này thường dẫn đến các ngoại lệ về năng lực instance trong quá trình triển khai, gây ra lỗi cập nhật và rollback. Chuyển đổi theo kiểu tất cả hoặc không có gì – Các triển khai blue/green truyền thống chuyển toàn bộ lưu lượng cùng một lúc hoặc dựa trên lịch trình được cấu hình. Điều này để lại không gian hạn chế cho việc xác thực dần dần và tăng phạm vi ảnh hưởng nếu có vấn đề phát sinh với triển khai mới. Mặc dù triển khai blue/green đã là một chiến lược đáng tin cậy cho các bản cập nhật zero-downtime, những hạn chế của nó trở nên rõ ràng khi triển khai các large language model (LLM) quy mô lớn hoặc các mô hình thông lượng cao trên các GPU instance cao cấp. Những thách thức này đòi hỏi một cách tiếp cận tinh tế hơn—một cách tiếp cận xác thực các bản cập nhật từng bước trong khi tối ưu hóa việc sử dụng tài nguyên. Rolling update cho inference component được thiết kế để loại bỏ sự cứng nhắc của các triển khai blue/green. Bằng cách cập nhật các mô hình theo các batch được kiểm soát, mở rộng cơ sở hạ tầng một cách linh hoạt và tích hợp các kiểm tra an toàn theo thời gian thực, chiến lược này đảm bảo các triển khai vẫn tiết kiệm chi phí, đáng tin cậy và có khả năng thích ứng—ngay cả đối với các workload sử dụng GPU nặng.\nRolling deployment để cập nhật inference component Như đã đề cập trước đó, inference component được giới thiệu như một tính năng của RageMaker AI để tối ưu hóa chi phí; chúng cho phép bạn định nghĩa và triển khai các tài nguyên cụ thể cần thiết cho workload suy luận mô hình của bạn. Bằng cách điều chỉnh đúng kích thước tài nguyên tính toán để phù hợp với yêu cầu của mô hình, bạn có thể tiết kiệm chi phí trong quá trình cập nhật so với các phương pháp triển khai truyền thống.\nVới rolling update, RageMaker AI triển khai các phiên bản mô hình mới theo các batch inference component có thể cấu hình trong khi mở rộng instance một cách linh hoạt. Điều này đặc biệt có tác động đối với các LLM:\nTính linh hoạt về kích thước batch – Khi cập nhật các inference component trong một SageMaker AI endpoint, bạn có thể chỉ định kích thước batch cho mỗi bước rolling. Đối với mỗi bước, RageMaker AI cung cấp năng lực dựa trên kích thước batch được chỉ định trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Các mô hình nhỏ hơn như DeepSeek Distilled Llama 8B có thể sử dụng các batch lớn hơn để cập nhật nhanh chóng, và các mô hình lớn hơn như DeepSeek Distilled Llama 70B sử dụng các batch nhỏ hơn để hạn chế tranh chấp GPU. Bảo vệ an toàn tự động – Các alarm Amazon CloudWatch tích hợp giám sát các metric trên một inference component. Bạn có thể cấu hình các alarm để kiểm tra xem phiên bản mới được triển khai của inference component có hoạt động đúng hay không. Nếu các alarm CloudWatch được kích hoạt, RageMaker AI sẽ bắt đầu một rollback tự động. Chức năng mới được triển khai thông qua các phần mở rộng cho RageMaker AI API, chủ yếu với các tham số mới trong API Update Inference Component:\nsagemaker_client.update_inference_component(\nInferenceComponentName=inference_component_name,\nRuntimeConfig={ \u0026ldquo;CopyCount\u0026rdquo;: number },\nSpecification={ \u0026hellip; },\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: { # Value must be between 5% to 50% of the IC\u0026rsquo;s total copy count.\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;: 1 # Minimum value of 1\n},\n\u0026ldquo;MaximumExecutionTimeoutInSeconds\u0026rdquo;: 600, #Minimum value of 600. Maximum value of 28800.\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;:1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120 # Minimum value of 0. Maximum value of 3600\n}\n},\nAutoRollbackConfiguration={\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\n\u0026ldquo;AlarmName\u0026rdquo;: \u0026ldquo;string\u0026rdquo; #Optional\n}\n]\n},\n)\nĐoạn code trên sử dụng các tham số sau:\nMaximumBatchSize – Đây là một tham số bắt buộc và định nghĩa kích thước batch cho mỗi bước rolling trong quy trình triển khai. Đối với mỗi bước, RageMaker AI cung cấp năng lực trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Giá trị phải nằm trong khoảng từ 5–50% số lượng bản sao của inference component. Type – Tham số này có thể chứa một giá trị như COPY_COUNT | CAPACITY_PERCENT, chỉ định loại năng lực endpoint. Value – Định nghĩa kích thước năng lực, dưới dạng số lượng bản sao inference component hoặc phần trăm năng lực. MaximumExecutionTimeoutSeconds – Đây là thời gian tối đa mà rolling deployment sẽ dành cho việc thực thi tổng thể. Vượt quá giới hạn này sẽ gây ra timeout. RollbackMaximumBatchSize – Đây là kích thước batch cho một rollback về endpoint fleet cũ. Nếu trường này vắng mặt, giá trị được đặt thành mặc định, là 100% tổng năng lực. Khi sử dụng mặc định, RageMaker AI cung cấp toàn bộ năng lực của fleet cũ cùng một lúc trong quá trình rollback. Value – Tham số Value của cấu trúc này sẽ chứa giá trị mà Type sẽ được thực thi. Đối với chiến lược rollback, nếu bạn không chỉ định các trường trong đối tượng này, hoặc nếu bạn đặt Value thành 100%, thì SageMaker AI sử dụng chiến lược rollback blue/green và roll lưu lượng trở lại fleet blue. WithIntervalInSeconds – Đây là giới hạn thời gian cho tổng triển khai. Vượt quá giới hạn này sẽ gây ra timeout. AutoRollbackConfiguration – Đây là cấu hình rollback tự động để xử lý lỗi triển khai endpoint và khôi phục. AlarmName – Alarm CloudWatch này được cấu hình để giám sát các metric trên một InferenceComponent Bạn có thể cấu hình nó để kiểm tra xem phiên bản mới được triển khai của InferenceComponent có hoạt động đúng hay không. Để biết thêm thông tin về SageMaker AI API, tham khảo SageMaker AI API Reference.\nTrải nghiệm khách hàng Hãy cùng khám phá cách rolling update hoạt động trong thực tế với một số tình huống phổ biến, sử dụng các LLM có kích thước khác nhau. Bạn có thể tìm thấy notebook ví dụ trong GitHub repo.\nTình huống 1: Nhiều cluster GPU đơn Trong tình huống này, giả sử bạn đang chạy một endpoint với ba instance ml.g5.2xlarge, mỗi instance có một GPU duy nhất. Endpoint lưu trữ một inference component yêu cầu một CPU accelerator, có nghĩa là mỗi instance chứa một bản sao. Khi bạn muốn cập nhật inference component để sử dụng phiên bản inference component mới, bạn có thể sử dụng rolling update để giảm thiểu sự gián đoạn.\nBạn có thể cấu hình một rolling update với kích thước batch là một, có nghĩa là RageMaker AI sẽ cập nhật từng bản sao một. Trong quá trình cập nhật, RageMaker AI trước tiên xác định năng lực có sẵn trong các instance hiện có. Vì không có instance hiện tại nào có không gian cho các workload tạm thời bổ sung, RageMaker AI sẽ khởi chạy các instance ml.g5.2xlarge mới từng cái một để triển khai một bản sao của phiên bản inference component mới lên một GPU instance. Sau khoảng thời gian chờ được chỉ định và container của inference component mới vượt qua kiểm tra healthy, RageMaker AI loại bỏ một bản sao của phiên bản cũ (vì mỗi bản sao được lưu trữ trên một instance, instance này sẽ được dỡ bỏ tương ứng), hoàn tất bản cập nhật cho batch đầu tiên.\nQuy trình này lặp lại cho bản sao thứ hai của inference component, cung cấp một quá trình chuyển đổi suôn sẻ với zero downtime. Bản chất dần dần của bản cập nhật giảm thiểu rủi ro và cho phép bạn duy trì tính khả dụng nhất quán trong suốt quy trình triển khai. Sơ đồ sau đây cho thấy quy trình này.\nTình huống 2: Cập nhật với rollback tự động Trong một tình huống khác, bạn có thể đang cập nhật inference component của mình từ Llama-3.1-8B-Instruct sang DeepSeek-R1-Distill-Llama-8B, nhưng phiên bản mô hình mới có các kỳ vọng API khác nhau. Trong trường hợp sử dụng này, bạn đã cấu hình một alarm CloudWatch để giám sát lỗi 4xx, điều này sẽ cho biết các vấn đề về tương thích API.\nBạn có thể bắt đầu một rolling update với kích thước batch là một bản sao. RageMaker AI triển khai bản sao đầu tiên của phiên bản mới trên một GPU instance mới. Khi instance mới sẵn sàng phục vụ lưu lượng, RageMaker AI sẽ chuyển tiếp một phần các yêu cầu invocation đến mô hình mới này. Tuy nhiên, trong ví dụ này, phiên bản mô hình mới, đang thiếu cấu hình biến môi trường \u0026ldquo;MESSAGES_API_ENABLED\u0026rdquo;, sẽ bắt đầu trả về lỗi 4xx khi nhận các yêu cầu ở định dạng Messages API.\nAlarm CloudWatch được cấu hình phát hiện các lỗi này và chuyển sang trạng thái alarm. RageMaker AI tự động phát hiện trạng thái alarm này và bắt đầu quy trình rollback theo cấu hình rollback. Theo kích thước batch rollback được chỉ định, RageMaker AI loại bỏ phiên bản mô hình mới có vấn đề và duy trì phiên bản gốc đang hoạt động, ngăn chặn sự gián đoạn dịch vụ trên diện rộng. Endpoint trở về trạng thái ban đầu với lưu lượng được xử lý bởi phiên bản mô hình gốc hoạt động đúng.\nĐoạn code sau đây cho thấy cách thiết lập một alarm CloudWatch để giám sát lỗi 4xx:\nCreate alarm cloudwatch.put_metric_alarm(\nAlarmName=f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors',\nComparisonOperator=\u0026lsquo;GreaterThanThreshold\u0026rsquo;,\nEvaluationPeriods=1,\nMetricName=\u0026lsquo;Invocation4XXErrors\u0026rsquo;,\nNamespace=\u0026lsquo;AWS/SageMaker\u0026rsquo;,\nPeriod=300,\nStatistic=\u0026lsquo;Sum\u0026rsquo;,\nThreshold=5.0,\nActionsEnabled=True,\nAlarmDescription=\u0026lsquo;Alarm when greather than 5 4xx errors\u0026rsquo;,\nDimensions=[\n{\n\u0026lsquo;Name\u0026rsquo;: \u0026lsquo;InferenceComponentName\u0026rsquo;,\n\u0026lsquo;Value\u0026rsquo;: inference_component_name\n},\n],\n)\nSau đó bạn có thể sử dụng alarm CloudWatch này trong yêu cầu cập nhật:\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120,\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n}\n},\n\u0026lsquo;AutoRollbackConfiguration\u0026rsquo;: {\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\u0026ldquo;AlarmName\u0026rdquo;: f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors\u0026rsquo;}\n]\n}\n}\nTình huống 3: Cập nhật với năng lực đầy đủ trong các instance hiện có Nếu một endpoint hiện có có nhiều GPU accelerator và không phải tất cả các accelerator đều được sử dụng, bản cập nhật có thể sử dụng các GPU accelerator hiện có mà không cần khởi chạy các instance mới cho endpoint. Xem xét nếu bạn có một endpoint được cấu hình với hai instance ml.g5.12xlarge ban đầu có bốn GPU accelerator trong mỗi instance. Endpoint lưu trữ hai inference component: IC-1 yêu cầu một accelerator và IC-2 cũng yêu cầu một accelerator. Trên một instance ml.g5.12xlarge, có bốn bản sao của IC-1 đã được tạo; trên instance khác, hai bản sao của IC-2 đã được tạo. Vẫn còn hai GPU accelerator có sẵn trên instance thứ hai.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Nó sẽ tạo hai bản sao của phiên bản IC-1 mới trên instance thứ hai. Khi các container đã khởi động và chạy, SageMaker AI sẽ hướng lưu lượng đến các IC-1 mới và sau đó bắt đầu định tuyến lưu lượng đến các inference component mới. RageMaker AI cũng sẽ loại bỏ hai trong số các bản sao IC-1 cũ khỏi instance. Bạn không bị tính phí cho đến khi các inference component mới bắt đầu nhận các invocation và tạo ra các phản hồi.\nBây giờ có thêm hai GPU slot trống. RageMaker AI sẽ cập nhật batch thứ hai, và nó sẽ sử dụng các GPU accelerator trống vừa có sẵn. Sau khi các quy trình hoàn tất, endpoint có bốn IC-1 với phiên bản mới và hai bản sao của IC-2 không bị thay đổi.\nTình huống 4: Cập nhật yêu cầu năng lực instance bổ sung Xem xét nếu bạn có một endpoint được cấu hình với ban đầu một instance ml.g5.12xlarge (tổng cộng 4 GPU) và được cấu hình managed instance scaling (MIS) với số instance tối đa được đặt thành hai. Endpoint lưu trữ hai inference component: IC-1 yêu cầu 1 GPU với hai bản sao (Llama 8B), và IC-2 (mô hình DeepSeek Distilled Llama 14B) cũng yêu cầu 1 GPU với hai bản sao—sử dụng tất cả 4 GPU có sẵn.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng không có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Thay vì làm thất bại bản cập nhật, vì bạn đã cấu hình MIS, RageMaker AI sẽ tự động cung cấp một instance g5.12.xlarge thứ hai để lưu trữ các inference component mới.\nTrong quá trình cập nhật, RageMaker AI triển khai hay bản sao của phiên bản IC-1 mới lên instance mới được cung cấp, như được hiển thị trong sơ đồ sau. Sau khi các inference component mới đã khởi động và chạy, RageMaker AI bắt đầu loại bỏ các bản sao IC-1 cũ khỏi các instance gốc. Đến cuối bản cập nhật, instance đầu tiên sẽ lưu trữ IC-2 sử dụng 2 GPU, và instance thứ hai mới được cung cấp sẽ lưu trữ IC-1 đã cập nhật với hai bản sao sử dụng 2 GPU. Sẽ có các không gian mới có sẵn trong hai instance, và bạn có thể triển khai thêm các bản sao inference component hoặc các mô hình mới vào cùng một endpoint bằng cách sử dụng các tài nguyên GPU có sẵn. Nếu bạn thiết lập managed instance auto scaling và đặt inference component auto scaling về không, bạn có thể scale down các bản sao inference component về không, điều này sẽ dẫn đến instance tương ứng được scale down. Khi inference component được scale up, SageMaker AI sẽ khởi chạy các inference component trong instance hiện có với các GPU accelerator có sẵn, như đã đề cập trong tình huống 3.\nTình huống 5: Cập nhật đối mặt với năng lực không đủ Trong các tình huống không có đủ năng lực GPU, RageMaker AI cung cấp phản hồi rõ ràng về các ràng buộc năng lực. Xem xét nếu bạn có một endpoint chạy trên 30 instance ml.g6e.16xlarge, mỗi instance đã được sử dụng đầy đủ với các inference component. Bạn muốn cập nhật một inference component hiện có bằng cách sử dụng rolling deployment với kích thước batch là 4, nhưng sau khi bốn batch đầu tiên được cập nhật, không có đủ năng lực GPU có sẵn cho phần còn lại của bản cập nhật. Trong trường hợp này, RageMaker AI sẽ tự động rollback về thiết lập trước đó và dừng quy trình cập nhật.\nCó thể có hai trường hợp cho trạng thái cuối cùng của rollback này. Trong trường hợp đầu tiên, rollback đã thành công vì có năng lực mới có sẵn để khởi chạy các instance cho phiên bản mô hình cũ. Tuy nhiên, có thể có một trường hợp khác trong đó vấn đề năng lực vẫn tồn tại trong quá trình rolling back, và endpoint sẽ hiển thị là UPDATE_ROLLBACK_FAILED. Các instance hiện có vẫn có thể phục vụ lưu lượng, nhưng để chuyển endpoint ra khỏi trạng thái failed, bạn cần liên hệ với nhóm AWS support của mình.\nCác cân nhắc bổ sung Như đã đề cập trước đó, khi sử dụng triển khai blue/green để cập nhật các inference component trên một endpoint, bạn cần cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Khi bạn đang sử dụng rolling update cho các inference component trên endpoint, bạn có thể sử dụng phương trình sau để tính số lượng service quota tài khoản cho loại instance cần thiết. GPU instance cần thiết cho endpoint có X số GPU accelerator, và mỗi bản sao inference component yêu cầu Y số GPU accelerator. Kích thước batch tối đa được đặt thành Z và endpoint hiện tại có N instance. Do đó, service quota cấp tài khoản cần thiết cho loại instance này cho endpoint phải lớn hơn đầu ra của phương trình:\nROUNDUP(Z x Y / X) + N\nVí dụ, giả sử endpoint hiện tại có 8 (N) instance ml.g5.12xlarge, có 4 GPU accelerator của mỗi instance. Bạn đặt kích thước batch tối đa thành 2 (Z) bản sao, và mỗi bản sao cần 1 (Y) GPU accelerator. Giá trị service quota AWS tối thiểu cho ml.g5.12xlarge là ROUNDUP(2 x 1 / 4) + 8 = 9. Trong một tình huống khác, khi mỗi bản sao của inference component yêu cầu 4 GPU accelerator, thì service quota cấp tài khoản cần thiết cho cùng một instance phải là ROUNDUP(2 x 4 / 4) + 8 = 10.\nKết luận Các bản cập nhật cuốn chiếu (rolling updates) cho các thành phần suy luận đại diện cho một bước tiến quan trọng trong khả năng triển khai của SageMaker AI. Tính năng này trực tiếp giải quyết các thách thức trong việc cập nhật mô hình đang chạy trong môi trường sản xuất, đặc biệt là với những khối lượng công việc nặng về GPU. Nó giúp loại bỏ việc phải ước lượng dung lượng thủ công, đồng thời giảm thiểu rủi ro khi cần hoàn tác (rollback).\nBằng cách kết hợp quy trình cập nhật theo lô (batch-based updates) cùng với các biện pháp bảo vệ tự động, SageMaker AI đảm bảo rằng các quá trình triển khai luôn linh hoạt và ổn định.\nCác lợi ích chính bao gồm:\nGiảm chi phí tài nguyên trong quá trình triển khai, không cần cấp phát thêm cụm máy chủ dự phòng. Cải thiện cơ chế bảo vệ trong quá trình triển khai nhờ cập nhật dần và khả năng tự động hoàn tác khi xảy ra lỗi. Duy trì khả năng hoạt động liên tục trong khi cập nhật, với kích thước lô có thể cấu hình. Đơn giản hóa việc triển khai các mô hình phức tạp cần nhiều bộ tăng tốc (multi-accelerator models). Dù bạn đang triển khai mô hình nhỏ gọn hay các mô hình lớn sử dụng nhiều bộ tăng tốc, rolling updates mang lại một phương pháp hiệu quả hơn, tiết kiệm chi phí và an toàn hơn để giữ cho các mô hình máy học của bạn luôn được cập nhật trong môi trường sản xuất.\nChúng tôi khuyến khích bạn dùng thử khả năng mới này trên các endpointSageMaker AI của mình và khám phá cách nó có thể nâng cao hiệu quả hoạt động ML của bạn. Để biết thêm thông tin, vui lòng tham khảo SageMaker AI documentation hoặc liên hệ với nhóm tài khoản AWS của bạn.\nVề các tác giả Melanie Li, Tiến sĩ, là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS, trụ sở tại Sydney, Úc. Cô tập trung vào việc hỗ trợ khách hàng xây dựng các giải pháp ứng dụng các công cụ AI và máy học tiên tiến nhất. Cô đã tham gia vào nhiều sáng kiến Generative AI trên toàn khu vực APJ, tận dụng sức mạnh của Large Language Models (LLMs). Trước khi gia nhập AWS, Tiến sĩ Li từng đảm nhiệm vai trò nhà khoa học dữ liệu trong lĩnh vực tài chính và bán lẻ.\nAndrew Smith là Kỹ sư Hỗ trợ Đám mây trong nhóm SageMaker, Vision \u0026amp; Other tại AWS, trụ sở Sydney, Úc. Anh hỗ trợ khách hàng sử dụng nhiều dịch vụ AI/ML của AWS, đặc biệt có chuyên môn sâu về Amazon SageMaker. Ngoài công việc, anh thích dành thời gian cho gia đình, bạn bè và tìm hiểu các công nghệ mới.\nDustin Liu là Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, tập trung hỗ trợ các công ty khởi nghiệp và doanh nghiệp SaaS trong lĩnh vực dịch vụ tài chính và bảo hiểm (FSI). Anh có nền tảng đa dạng trong kỹ thuật dữ liệu (data engineering), khoa học dữ liệu (data science) và máy học (machine learning), đồng thời đam mê ứng dụng AI/ML để thúc đẩy đổi mới và chuyển đổi doanh nghiệp.\nVivek Gangasani là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS. Anh giúp các công ty khởi nghiệp về Generative AI xây dựng các giải pháp sáng tạo bằng cách sử dụng dịch vụ AWS và hạ tầng tính toán tăng tốc. Hiện tại, anh tập trung vào việc phát triển các chiến lược tinh chỉnh (fine-tuning) và tối ưu hiệu năng suy luận (inference performance) cho các mô hình ngôn ngữ lớn (LLMs). Ngoài công việc, Vivek thích leo núi, xem phim và khám phá ẩm thực.\nShikher Mishra là Kỹ sư Phát triển Phần mềm (Software Development Engineer) thuộc nhóm SageMaker Inference, với hơn 9 năm kinh nghiệm trong ngành. Anh đam mê xây dựng các giải pháp mở rộng, hiệu quả, giúp khách hàng triển khai và quản lý ứng dụng máy học một cách dễ dàng. Thời gian rảnh, Shikher yêu thích thể thao ngoài trời, leo núi và du lịch.\nJune Won là Quản lý sản phẩm (Product Manager) của Amazon SageMaker JumpStart. Anh tập trung vào việc giúp khách hàng dễ dàng tìm kiếm và sử dụng các mô hình nền tảng (foundation models) để xây dựng ứng dụng Generative AI. Kinh nghiệm của anh tại Amazon còn bao gồm phát triển ứng dụng mua sắm di động và giải pháp giao hàng chặng cuối (last-mile delivery).\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/3-blogstranslated/3.2-blog2/","title":"Blog 1","tags":[],"description":"","content":"Thông báo kết thúc hỗ trợ và khả năng khám phá nâng cao cho Amazon EKS Ngày 05 tháng 03 năm 2025\nTác giả: Praseeda Sathaye (Principal Solutions Architect, Containers \u0026amp; OSS), AJ Davis (AWS Enterprise Support) và Arvind Viswanathan (Principal Solutions Architect)\nGiới thiệu Trong thế giới ứng dụng container hóa đang phát triển nhanh chóng, việc duy trì khả năng phục hồi và khả năng quan sát trên các môi trường Kubernetes đã trở thành một thách thức quan trọng. Khi các tổ chức ngày càng áp dụng Amazon Elastic Kubernetes Service (Amazon EKS) để quản lý khối lượng công việc container hóa của họ, nhu cầu về quản lý vòng đời phiên bản cluster và cơ chế khám phá trở nên cực kỳ quan trọng. Khi môi trường Amazon EKS trở nên phức tạp hơn và mở rộng trên nhiều AWS Regions và tài khoản, người dùng thường gặp khó khăn trong việc theo dõi phiên bản cluster, vòng đời hỗ trợ và trạng thái triển khai tổng thể.\nGiám sát chủ động vòng đời cluster EKS và kết thúc hỗ trợ là rất quan trọng để đảm bảo tính bảo mật, ổn định và tuân thủ của các triển khai Kubernetes. Hơn nữa, việc có được khả năng hiển thị các triển khai cluster EKS trên toàn bộ AWS Organization là điều cần thiết cho việc quản lý tài nguyên hiệu quả, lập kế hoạch chiến lược và duy trì bảng kiểm kê chính xác.\nTrong bài viết này, để giải quyết những điểm yếu này, chúng tôi chia sẻ hai giải pháp mạnh mẽ cung cấp khả năng quan sát các cluster EKS:\nThông báo kết thúc hỗ trợ Khám phá và báo cáo Giải pháp đầu tiên sử dụng AWS Health, Amazon EventBridge và Amazon Simple Notification Service (Amazon SNS)/Amazon Simple Queue Service (Amazon SQS) để giám sát các sự kiện cụ thể của Amazon EKS, đặc biệt đối với các cluster sắp kết thúc hỗ trợ (tiêu chuẩn và mở rộng). Việc cung cấp thông báo sớm khi một cluster EKS sắp kết thúc cửa sổ hỗ trợ cho phép giải pháp này trao quyền cho bạn chủ động lập kế hoạch và cập nhật phiên bản Kubernetes của cluster.\nBổ sung cho điều này, giải pháp thứ hai là một cơ chế khám phá và báo cáo tự động xác định và tổng hợp thông tin chi tiết về các cluster EKS trên tất cả các AWS Regions và tài khoản trong Organization của bạn. Khả năng hiển thị toàn diện này về các phiên bản cluster, tags liên quan và các chi tiết chính khác giúp kiểm tra tuân thủ, quản lý bảng kiểm kê tài nguyên chính xác và lập kế hoạch nâng cấp chiến lược.\nCùng nhau, hai giải pháp này cung cấp một framework mạnh mẽ để quản lý vòng đời cluster EKS hiệu quả, cho phép các tổ chức luôn đi trước các vấn đề tiềm ẩn, tối ưu hóa việc sử dụng tài nguyên và đưa ra các quyết định sáng suốt phù hợp với mục tiêu chiến lược dài hạn của họ.\nĐiều kiện tiên quyết Bạn cần những điều sau để hoàn thành hướng dẫn:\nMột AWS account với Organizations được bật Gói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support để sử dụng AWS Health API Kiến thức cơ bản về Amazon EKS, AWS Health, EventBridge, AWS Lambda, AWS Identity and Access Management (IAM), Amazon S3, Amazon SNS, Amazon SQS và AWS Cloud Development Kit (AWS CDK) Khả năng ủy quyền từ tài khoản quản lý đến tài khoản tooling được sử dụng để tập trung thông báo và thực hiện khám phá cluster EKS trên toàn bộ Organization Kiến thức về Python Thiết lập ban đầu Các bước sau hướng dẫn bạn qua quá trình thiết lập ban đầu.\nBật AWS Health Organizational View trong tài khoản quản lý Bật Organizational View in AWS Health để có được chế độ xem tập trung, tổng hợp các sự kiện AWS Health trên toàn bộ Organization của bạn. Bạn có thể xác minh rằng điều này được bật thông qua console hoặc bằng cách chạy lệnh sau bằng AWS Command Line Interface (AWS CLI):\naws health describe-health-service-status-for-organization. Bạn sẽ thấy kết quả sau:\n{\u0026ldquo;healthServiceAccessStatusForOrganization\u0026rdquo;: \u0026ldquo;ENABLED\u0026rdquo; }\nGói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support là cần thiết để sử dụng AWS Health API và hoàn thành bước này.\nỦy quyền quản trị từ tài khoản quản lý đến tài khoản tooling trung tâm Thiết lập một tài khoản AWS trong Organization làm tài khoản tooling cho giải pháp này. Tài khoản này được sử dụng để tập trung thông báo và khám phá.\nTừ tài khoản quản lý, ủy quyền quản trị AWS CloudFormation StackSets bằng cách làm theo các bước được mô tả trong bài viết này: CloudFormation StackSets delegated administration.\nKết quả tương tự cũng có thể đạt được bằng cách chạy lệnh sau từ tài khoản quản lý. Thay thế 012345678901 bằng AWS account ID của tài khoản tooling của bạn.\naws organizations register-delegated-administrator \\\n\u0026ndash;serviceprincipal=member.org.stacksets.cloudformation.amazonaws.com \\\n\u0026ndash;account-id=\u0026ldquo;012345678901\u0026rdquo;\nĐây là lần duy nhất chúng ta cần truy cập tài khoản quản lý. Các bước còn lại được hoàn thành từ trong tài khoản tooling.\nBootstrap AWS CDK Chọn một Region chính nơi tất cả báo cáo và sự kiện được hợp nhất trong tài khoản tooling trung tâm. Đặt biến AWS_DEFAULT_REGION thành Region chính này.\nĐối với giải pháp khám phá và báo cáo, bạn phải bootstrap AWS CDK trong Region chính này trên toàn bộ Organization. Hơn nữa, AWS CDK cũng phải được bootstrap trong tất cả các AWS Regions nơi các cluster EKS được triển khai để nhận thông báo kết thúc hỗ trợ. Để đơn giản hóa hướng dẫn này, chúng tôi chỉ demo triển khai tài nguyên đến Region chính mà bạn đã chọn.\nCác bước để bootstrap AWS CDK trên nhiều AWS Regions và tài khoản có sẵn trong bài viết này: Bootstrapping multiple AWS accounts for AWS CDK using CloudFormation StackSets.\nTải xuống các AWS CDK stacks Chúng tôi cung cấp các AWS CDK stacks để bạn nhanh chóng triển khai giải pháp trong môi trường của mình. Tải mã từ our GitHub repository và thiết lập môi trường bằng cách chạy các lệnh sau trong thư mục cdk:\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\nHướng dẫn chi tiết Các bước sau sẽ hướng dẫn bạn qua các giải pháp này.\nGiải pháp 1: Thông báo kết thúc hỗ trợ cluster EKS Giải pháp đầu tiên của chúng tôi giải quyết nhu cầu quan trọng về nhận thức kịp thời về các sự kiện vòng đời cluster EKS, đặc biệt là việc tiếp cận ngày kết thúc hỗ trợ tiêu chuẩn. Việc sử dụng AWS Health, EventBridge và Amazon SNS (và tùy chọn Amazon SQS) cho phép chúng tôi tạo một hệ thống tập trung:\nGiám sát các sự kiện AWS Health trên nhiều AWS Regions và tài khoản Tập trung vào các sự kiện cụ thể của Amazon EKS, đặc biệt là AWS_EKS_PLANNED_LIFECYCLE_EVENT Cung cấp thông báo sớm khi một cluster EKS còn 180 ngày nữa sẽ đạt đến cuối giai đoạn hỗ trợ tiêu chuẩn và hỗ trợ mở rộng Cách tiếp cận tập trung này đảm bảo rằng người dùng Amazon EKS nhận được đủ thời gian để lập kế hoạch và thực hiện nâng cấp phiên bản, duy trì tính bảo mật và ổn định của môi trường Kubernetes của họ, như được hiển thị trong hình sau.\nHình 1: Tổng quan giải pháp – thông báo kết thúc hỗ trợ\nBước 1: Triển khai AWS CDK stack eks-health-events Triển khai AWS CDK stack eks-health-events vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-health-events \u0026ndash;app \u0026ldquo;python3 tooling_account.py\u0026rdquo; —require-approval never\nĐiều này triển khai AWS CDK app trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nEvent bus SNS topic và SQS queue để giám sát các sự kiện EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SNS EventBridge rule để chuyển tiếp giám sát các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SQS Resource policies cho các event rules để publish đến Amazon SNS và Amazon SQS Bước 2: Triển khai AWS CDK stack eks-health-events-stack-set Triển khai AWS CDK stack eks-health-events-stack-set.\ncdk deploy eks-health-events-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; —require-approval never\nĐiều này sử dụng CloudFormation StackSets để triển khai các tài nguyên sau vào Region chính đã chọn trên tất cả các tài khoản trong Organization ngoại trừ tài khoản Management:\nLocal event bus EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến central event bus được cung cấp trong Bước 2 Resource policies cho các event rules để publish đến central event bus Bước 3: Cấu hình thông báo SNS Duyệt đến dịch vụ Amazon SNS có tên eks-health-events-EKSHealthEvents- và tạo một subscription cho topic mới được tạo (ví dụ: địa chỉ email nhóm).\nBước 4: Xác thực giải pháp Bạn có thể kiểm tra và xác thực rằng các EventBridge rules, SQS queue và SNS topic đã được tạo bởi các CloudFormation stacks có tên eks-health-events và eks-health-events-stack-set. Từ thời điểm này trở đi, khi các cluster EKS của bạn còn 180 ngày nữa sẽ đạt đến cuối hỗ trợ (tiêu chuẩn và mở rộng), các EventBridge rules sẽ áp dụng và Amazon SNS và/hoặc Amazon SQS được kích hoạt, như được hiển thị trong các hình sau.\nHình 2: Xác thực triển khai EventBridge\nHình 3: Xác thực triển khai SQS\nHình 4: Xác thực triển khai SNS\nHình 5: Mẫu thông báo kết thúc hỗ trợ\nGiải pháp 2: Khám phá và báo cáo cluster EKS Bổ sung cho giải pháp thông báo kết thúc hỗ trợ cluster EKS, giải pháp thứ hai của chúng tôi cung cấp cái nhìn toàn diện về các cluster EKS trên toàn bộ Organization. Giải pháp này:\nXác định các cluster EKS trong tất cả các AWS Regions và tài khoản trong một Organization Thu thập thông tin chi tiết về từng cluster, chẳng hạn như chi tiết tài khoản, region, tên cluster, phiên bản và các tags liên quan Tổng hợp dữ liệu về các phiên bản cluster, cung cấp thông tin chi tiết về phân phối phiên bản Tạo cả báo cáo chi tiết và tóm tắt, được lưu trữ tập trung để truy cập trực tiếp Việc cung cấp khả năng hiển thị trên toàn tổ chức này cho phép giải pháp giúp các nhóm duy trì bảng kiểm kê chính xác về tài nguyên Amazon EKS, tạo điều kiện thuận lợi cho việc kiểm tra tuân thủ và hỗ trợ lập kế hoạch nâng cấp chiến lược, như được hiển thị trong hình sau.\nHình 6: Tổng quan giải pháp – khám phá và báo cáo\nBước 1: Triển khai AWS CDK stack eks-discovery Triển khai AWS CDK stack eks-discovery-lambda vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-discovery-lambda —require-approval never\nĐiều này triển khai AWS CDK stack có tên eks-discovery-lambda trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nLambda function để khám phá các cluster EKS trên tất cả các AWS Regions và tài khoản S3 bucket để lưu trữ kết quả SNS topic cho thông báo EventBridge scheduler để thực thi định kỳ Các IAM roles và policies cần thiết Lambda function thu thập chi tiết cluster, tạo báo cáo và gửi thông báo.\nBước 2: Sửa đổi EventBridge scheduler theo nhu cầu Nếu bạn muốn tùy chỉnh lịch khám phá cluster EKS, hãy điều hướng đến EventBridge và trong phần schedules tìm EKSDiscoveryWeeklySchedule mới được tạo. Đây là một scheduler dựa trên cron, như được hiển thị trong hình sau.\nHình 7: Tùy chỉnh lịch cho khám phá cluster\nĐể nhận thông báo từ Amazon SNS, bạn phải tạo một subscription cho topic. Để làm điều này, hãy điều hướng đến dịch vụ Amazon SNS, tìm Topic mới được tạo có tên EKSDiscoverySNSTopic và cấu hình giao thức để đáp ứng yêu cầu của bạn (ví dụ: gửi email đến một nhóm).\nBước 3: Triển khai cross-account role mà Lambda function có thể assume để thực hiện khám phá Lambda function bạn triển khai trong Bước 1 dựa vào một cross-account role trong mỗi tài khoản trong Organization để thực hiện khám phá cluster.\nTriển khai AWS CDK stack eks-discovery-stack-set để triển khai cross-account role này.\ncdk deploy eks-discovery-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;require-approval never\nBước 4: Xác thực giải pháp Để xác thực giải pháp, hãy điều hướng đến Lambda function mới được tạo và test với một event mới và một đối tượng JSON rỗng. Khi Lambda hoàn thành, hãy xác minh rằng S3 bucket nhận được file zip và xác nhận rằng bạn đã nhận được thông báo SNS, như được hiển thị trong các hình sau.\nHình 8: Mẫu output khám phá cluster trong S3 bucket\nHình 9: Mẫu nội dung của output file\nHình 10: Mẫu danh sách clusters\nHình 11: Mẫu số lượng clusters theo phiên bản\nBước 5: (Tùy chọn) Giám sát giải pháp Bạn có thể muốn giám sát giải pháp. Điều này có thể được thực hiện bằng cách thiết lập Amazon CloudWatch Alarms để giám sát việc thực thi của Lambda function và bất kỳ lỗi tiềm ẩn nào. Hơn nữa, hãy thường xuyên xem xét các báo cáo được tạo trong S3 bucket và định kỳ xem xét và cập nhật các quyền IAM nếu cần.\nKhắc phục sự cố Đảm bảo rằng tất cả các IAM roles và policies được thiết lập chính xác và có các quyền cần thiết. Kiểm tra CloudWatch Logs để tìm bất kỳ thông báo lỗi nào trong các Lambda functions hoặc EventBridge rules. Cân nhắc về bảo mật Xem xét và điều chỉnh các IAM roles và policies để tuân thủ nguyên tắc đặc quyền tối thiểu và môi trường của bạn. Thường xuyên kiểm toán quyền truy cập vào hệ thống quản lý sự kiện tập trung. Dọn dẹp Chạy các lệnh sau để dọn dẹp các tài nguyên đã cung cấp:\ncdk destroy \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;all \u0026ndash;force\ncdk destroy \u0026ndash;all \u0026ndash;force\nLệnh đầu tiên xóa các CloudFormation StackSets đã được triển khai trên toàn bộ Organization bằng AWS CDK App có tên stack_sets.py.\nLệnh thứ hai dọn dẹp các tài nguyên được cung cấp trong tài khoản tooling trung tâm bằng AWS CDK App có tên tooling_account.py.\nKết luận Hướng dẫn này có thể giúp bạn thiết lập một hệ thống mạnh mẽ sử dụng các dịch vụ AWS để cung cấp thông báo chủ động về kết thúc hỗ trợ tiêu chuẩn. Điều này cho phép lập kế hoạch kịp thời cho các nâng cấp, giảm thiểu rủi ro từ các cluster lỗi thời trong khi duy trì tính bảo mật, ổn định và tuân thủ. Hơn nữa, giải pháp khám phá và báo cáo cluster Amazon EKS đánh dấu một bước tiến đáng kể trong việc quản lý các môi trường Kubernetes đa tài khoản phức tạp trên AWS. Giải pháp tăng cường khả năng hiển thị, hợp lý hóa nỗ lực tuân thủ, tạo điều kiện thuận lợi cho việc lập kế hoạch chiến lược và hỗ trợ ra quyết định sáng suốt cho việc nâng cấp cluster và phân bổ tài nguyên.\nKhi các tổ chức tiếp tục mở rộng quy mô ứng dụng container hóa của họ, các giải pháp này trở thành tài sản vô giá. Chúng cho phép các nhóm duy trì cái nhìn tổng quan rõ ràng về cảnh quan Amazon EKS của họ, tối ưu hóa việc sử dụng tài nguyên và đảm bảo các thực hành quản lý nhất quán trên các triển khai đa dạng. Việc triển khai các giải pháp này cho phép bạn thực hiện một bước tiến đáng kể trong việc quản lý khả năng quan sát, khả năng phục hồi và quản trị của các môi trường Amazon EKS của bạn. Đến lượt nó, điều này đảm bảo thành công lâu dài và khả năng mở rộng của các sáng kiến Kubernetes của bạn trên AWS.\nChúng tôi khuyến nghị thử cả hai giải pháp để bắt đầu tăng cường khả năng quan sát cluster EKS của bạn ngay hôm nay!\nNguồn gốc: AWS Containers Blog Ngày xuất bản: 12 tháng 3, 2025 Danh mục: Amazon EKS, AWS Health, Container Management, Kubernetes\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Understand AWS account structure and responsibilities. Learn how to create and secure an AWS account. Set up IAM users, groups, and permission policies. Enable MFA and configure billing alerts. Become familiar with AWS Console navigation. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Overview of AWS accounts and root user responsibilities - Understand IAM concepts (Users, Groups, Policies) 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/ 2 - Create AWS account - Set up payment method - Verify email \u0026amp; phone number - First login and explore AWS Console 09/10/2025 09/10/2025 https://000001.awsstudygroup.com/ 3 - Secure root account + Enable MFA + Configure password policy + Limit root user usage - Set up Billing preferences and Free Tier usage monitoring 09/11/2025 09/11/2025 https://000001.awsstudygroup.com/ 4 - Create IAM Group (Administrators) - Attach AdministratorAccess policy - Create IAM User - Configure user login and enable MFA 09/12/2025 09/12/2025 https://000001.awsstudygroup.com/ 5 - Create Budget and Billing Alerts - Review account security checklist - Practice IAM login - Explore AWS Console navigation - Summarize learnings and issues encountered 09/13/2025 09/13/2025 https://000001.awsstudygroup.com/ Week 1 Achievements: Understood AWS account components:\nRoot User IAM Users IAM Groups Permission Policies Successfully created and activated a new AWS account.\nSecured the root account by enabling MFA and establishing password standards.\nSet up billing preferences including Free Tier usage alerts and budget notifications.\nCreated IAM Group and IAM User following AWS security best practices.\nEnabled MFA for IAM User and practiced secure login flow.\nLearned AWS Console navigation and how to locate services quickly.\nCompleted initial security configuration required before using AWS services in later lessons.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Create an S3 Interface endpoint","tags":[],"description":"","content":"In this section you will create and test an S3 interface endpoint using the simulated on-premises environment deployed as part of this workshop.\nReturn to the Amazon VPC menu. In the navigation pane, choose Endpoints, then click Create Endpoint.\nIn Create endpoint console:\nName the interface endpoint In Service category, choose aws services In the Search box, type S3 and press Enter. Select the endpoint named com.amazonaws.us-east-1.s3. Ensure that the Type column indicates Interface. For VPC, select VPC Cloud from the drop-down. Make sure to choose \u0026ldquo;VPC Cloud\u0026rdquo; and not \u0026ldquo;VPC On-prem\u0026rdquo;\nExpand Additional settings and ensure that Enable DNS name is not selected (we will use this in the next part of the workshop) Select 2 subnets in the following AZs: us-east-1a and us-east-1b For Security group, choose SGforS3Endpoint: Keep the default policy - full access and click Create endpoint Congratulation on successfully creating S3 interface endpoint. In the next step, we will test the interface endpoint.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.2-prerequiste/","title":"Prerequiste","tags":[],"description":"","content":"IAM permissions Add the following IAM permission policy to your user account to deploy and cleanup this workshop.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Provision resources using CloudFormation In this lab, we will use N.Virginia region (us-east-1).\nTo prepare the workshop environment, deploy this CloudFormation Template (click link): PrivateLinkWorkshop . Accept all of the defaults when deploying the template.\nTick 2 acknowledgement boxes Choose Create stack The ClouddFormation deployment requires about 15 minutes to complete.\n2 VPCs have been created 3 EC2s have been created "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Test the Gateway Endpoint","tags":[],"description":"","content":"Create S3 bucket Navigate to S3 management console In the Bucket console, choose Create bucket In the Create bucket console Name the bucket: choose a name that hasn\u0026rsquo;t been given to any bucket globally (hint: lab number and your name) Leave other fields as they are (default) Scroll down and choose Create bucket Successfully create S3 bucket. Connect to EC2 with session manager For this workshop, you will use AWS Session Manager to access several EC2 instances. Session Manager is a fully managed AWS Systems Manager capability that allows you to manage your Amazon EC2 instances and on-premises virtual machines (VMs) through an interactive one-click browser-based shell. Session Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys.\nFirst cloud journey Lab for indepth understanding of Session manager.\nIn the AWS Management Console, start typing Systems Manager in the quick search box and press Enter: From the Systems Manager menu, find Node Management in the left menu and click Session Manager: Click Start Session, and select the EC2 instance named Test-Gateway-Endpoint. This EC2 instance is already running in \u0026ldquo;VPC Cloud\u0026rdquo; and will be used to test connectivity to Amazon S3 through the Gateway endpoint you just created (s3-gwe).\nSession Manager will open a new browser tab with a shell prompt: sh-4.2 $\nYou have successfully start a session - connect to the EC2 instance in VPC cloud. In the next step, we will create a S3 bucket and a file in it.\nCreate a file and upload to s3 bucket Change to the ssm-user\u0026rsquo;s home directory by typing cd ~ in the CLI Create a new file to use for testing with the command fallocate -l 1G testfile.xyz, which will create a file of 1GB size named \u0026ldquo;testfile.xyz\u0026rdquo;. Upload file to S3 bucket with command aws s3 cp testfile.xyz s3://your-bucket-name. Replace your-bucket-name with the name of S3 bucket that you created earlier. You have successfully uploaded the file to your S3 bucket. You can now terminate the session.\nCheck object in S3 bucket Navigate to S3 console. Click the name of your s3 bucket In the Bucket console, you will see the file you have uploaded to your S3 bucket Section summary Congratulation on completing access to S3 from VPC. In this section, you created a Gateway endpoint for Amazon S3, and used the AWS CLI to upload an object. The upload worked because the Gateway endpoint allowed communication to S3, without needing an Internet Gateway attached to \u0026ldquo;VPC Cloud\u0026rdquo;. This demonstrates the functionality of the Gateway endpoint as a secure path to S3 without traversing the Public Internet.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/4-eventparticipated/4.1-event1/","title":"Event 2","tags":[],"description":"","content":"Summary Report: Club Session – \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Purpose of the Session Explore how Generative AI is transforming modern software development. Understand how AI can be fully integrated into the Software Development Life Cycle (SDLC) from architecture to maintenance. Experience hands-on examples of AI-powered development tools such as Amazon Q Developer and Kiro. Speakers \u0026amp; Organizers Main Facilitators: Toan Huynh – Presented AI-Driven SDLC and demoed Amazon Q Developer My Nguyen – Demonstrated Kiro Coordinators: Diem My, Dai Truong, Dinh Nguyen (AWS GenAI Builder Club Vietnam) Key Content \u0026amp; Learnings 1. Overview of the AI-Driven Development Life Cycle Generative AI is reshaping the entire SDLC, not just assisting with small tasks. AI automates repetitive work such as boilerplate coding, generating test cases, and basic debugging. Developers are shifting from writing every line of code to designing, supervising, and collaborating with AI. 2. Amazon Q Developer – An End-to-End AI Developer Assistant Supports all stages of SDLC: planning, requirement analysis, architecture design coding, code explanation, refactoring, language migration debugging and testing deployment guidance and troubleshooting Deep AWS integration enhances productivity for cloud-native workloads. Built with strong privacy principles—enterprise data is not used to train global models. 3. Kiro – Practical AI Pair Programming Understands complex codebases and provides intelligent modification suggestions. Accelerates development by generating accurate, production-ready code. Acts as a learning companion to quickly explore new languages or frameworks. Key Takeaways Trends \u0026amp; Future Direction AI will not replace developers; instead, it elevates their role toward problem-solving, system design, and quality assurance. Speed becomes a competitive advantage for organizations that adopt AI across the SDLC. Skills to Develop Prompt engineering becomes essential: specifying requirements clearly and validating AI-generated output. Architectural thinking and oversight skills are needed to evaluate AI-generated code safely. Strong fundamentals remain crucial: algorithms, data structures, and system design enable developers to guide AI effectively. Personal Action Plan Register and use Amazon Q Developer in VSCode/JetBrains for daily tasks. Practice prompt engineering for coding scenarios—code generation, testing, debugging. Engage actively with the AWS GenAI Builder Club community. Apply an AI-driven development workflow to a real module in a personal or team project. Personal Reflection This club session felt like witnessing the next evolution of software engineering.\nSeeing Amazon Q Developer and Kiro operate in real time—proposing improvements, detecting potential vulnerabilities, and converting natural language prompts into working code—was truly eye-opening.\nThe most impactful message was: “AI empowers, not replaces.”\nDevelopers who learn to collaborate with AI will have a tremendous advantage in the future.\nThis session encouraged me to be proactive in mastering AI tools and to integrate them into my workflow as an essential part of becoming a next-generation software engineer.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Understand AWS Budgets and how to use them to manage and monitor AWS costs. Learn different types of AWS Budgets: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Practice creating budgets using templates and custom settings, and cleaning up resources. Understand AWS Support: support plans, how to access AWS Support, and how to create and manage support requests. Build awareness of cost control and how to get help from AWS when issues occur. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Study AWS Budgets overview + What is AWS Budgets? + Why use budgets to control costs? + Types of budgets (Cost, Usage, RI, Savings Plans) 09/16/2025 09/16/2025 https://000007.awsstudygroup.com/ 2 - Hands-on with Budgets (1): + Create Budget by Template + Create a Cost Budget with alert thresholds + Review budget details and notification settings 09/17/2025 09/17/2025 https://000007.awsstudygroup.com/ 3 - Hands-on with Budgets (2): + Create a Usage Budget for a specific service (e.g., EC2) + Create RI Budget + Understand when to use each type of budget 09/18/2025 09/18/2025 https://000007.awsstudygroup.com/ 4 - Hands-on with Budgets (3): + Create Savings Plans Budget + Review alerts and examples of cost overrun scenarios + Clean up budgets and related resources after the lab 09/19/2025 09/19/2025 https://000007.awsstudygroup.com/ 5 - Study AWS Support: + AWS Support Plans and their differences + How to access AWS Support Center - Hands-on: + Navigate to Support Center + Create a support case + View / update / close support requests 09/20/2025 09/20/2025 https://000009.awsstudygroup.com/ Week 2 Achievements: Understood what AWS Budgets is and why it is important for cost management. Learned the differences between Cost Budget, Usage Budget, RI Budget, and Savings Plans Budget. Successfully created budgets using templates and custom settings in the AWS console. Configured budget alerts to receive notifications when costs or usage exceed thresholds. Practiced cleaning up budgets and related resources after completing the lab. Understood the purpose of AWS Support and the different support plans available. Learned how to access AWS Support Center, create a support case, and manage existing support requests. Increased awareness of both cost control and support processes when operating workloads on AWS. "},{"uri":"https://khanguyense.github.io/fcj_workshop/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Academic Research Chatbot AWS RAG-based solution for smart academic support and research 1. Executive Summary Academic Research Chatbot is an AI assistant supporting academic research, helping students and lecturers search, summarize, and analyze scientific documents (PDFs, papers) through natural conversation with accurate source citations.\nKey Highlights:\nCore Technology: Combines IDP (Amazon Textract) to process documents (including scans) and RAG (Amazon Bedrock - Claude 3.5 Sonnet) to generate intelligent responses. Optimized Architecture: Hybrid model using 1 EC2 t3.small combined with Serverless services (Amplify, Cognito, S3, DynamoDB) to balance performance and cost. Feasibility: Serves ~50 internal users with operating costs ~$60/month, fast deployment time (20 days), and maximizes AWS Free Tier. 2. Problem Statement Current Problem Students and researchers have to work with a large number of academic documents (conference papers, journals, theses, technical reports). Many documents are old scanned PDFs (pre-2000), without a text layer, making searching for content, data, and tables very time-consuming. Public AI tools (ChatGPT, Perplexity, NotebookLM, etc.) are not directly connected to the school/department\u0026rsquo;s internal document repository, making it difficult to ensure security and access rights by subject or research group. The current infrastructure lacks a unified access point to:\nManage research documents by subject/topic. Allow researchers to ask questions directly on their own papers. Ensure answers have clear citations (paper, page, table, section). Consequence: Researchers have to manually read, take notes, and copy data from multiple papers; lecturers find it difficult to quickly synthesize information when preparing lectures or topics; academic data is scattered across many personal machines, difficult to standardize and reuse. Solution Academic Research Chatbot proposes building an internal academic Q\u0026amp;A platform based on AWS, where:\nDev/Admin loads research document repository: Upload PDFs to Amazon S3, metadata is stored in Amazon DynamoDB. An EC2 worker consumes the Amazon SQS queue, calls Amazon Textract to OCR, extract text, tables, forms, including scanned documents. Worker normalizes/chunks content, sends to Amazon Bedrock Titan Text Embeddings v2 to generate embeddings, and indexes into Qdrant on EC2. Researchers ask questions via web interface (Amplify + CloudFront): Questions are embedded, querying Qdrant to retrieve the most relevant segments (Retrieval). These segments are passed to Claude 3.5 Sonnet on Amazon Bedrock to generate answers with accurate citations (paper, page, section, table) and explanations in academic context. All access is protected by Amazon Cognito (researcher vs admin authorization), logs \u0026amp; metrics are monitored via Amazon CloudWatch + SNS (alerts on worker errors, queue backlog, high EC2 CPU). Benefits and ROI Academic Efficiency:\nReduces 40–60% of time researchers spend finding data, F1-scores, p-values, sample sizes, experimental equipment, or method descriptions from multiple papers. Reduces citation errors due to forgetting pages/tables, as the chatbot always returns sources and locations. Internal Knowledge Management: Research documents are centralized in an S3 + DynamoDB repository, easy to backup, authorize, and expand. Can be reused for many courses, topics, and labs without building a new system. Low \u0026amp; Controllable Infrastructure Costs: Hybrid model 1 EC2 + managed AI services keeps operating costs for 50 internal users at around \u0026lt; $50/month, mainly paying for EC2, 2–3 VPC endpoint interfaces, and Bedrock/Textract usage. The system is designed to be deployed in about 20 days by a team of 4, suitable for a research/internship project but still has product architecture quality. Long-term Value: Creates a platform to later integrate learning behavior analysis dashboards, paper recommendation modules, or expand to multi-language and multi-field learning assistants. 3. Solution Architecture Academic Research Chatbot applies the AWS Hybrid RAG Architecture model with IDP (Intelligent Document Processing), combining a single EC2 (FastAPI + Qdrant + Worker) with managed AI services (Textract, Bedrock) to optimize costs while ensuring performance for about 50 internal users.\nData Processing and Conversation Flow AWS Services Used\nAmazon Route 53: DNS management for chatbot platform domain. Amazon CloudFront: CDN distributing web interface (chat + admin) with low latency. AWS Amplify Hosting: Hosts web application (React/Next) for Researchers and Dev/Admin. Amazon Cognito: User authentication, researcher vs admin role management. Amazon S3: Stores original PDF files uploaded by Dev/Admin (raw documents). Amazon SQS (doc_ingestion_queue): Job queue for document processing. Amazon Textract: IDP/OCR for scanned PDFs and digital PDFs. Amazon Bedrock: Titan Text Embeddings v2: Generates embedding vectors for text chunks. Claude 3.5 Sonnet: Generates academic answers from context + user questions (RAG). Amazon DynamoDB: Documents table: document metadata, pipeline status (UPLOADED, IDP_RUNNING, EMBEDDING_DONE, FAILED). Amazon EC2 (t3.small, private subnet): Runs FastAPI backend (REST API for chat and admin). Runs Qdrant Vector DB to store and query embeddings. Runs Worker process consuming SQS, calling Textract + Titan, indexing into Qdrant, updating DynamoDB. VPC + ALB + VPC Endpoints: VPC + private subnet for EC2 (not directly exposed to Internet). Application Load Balancer (ALB): entry point for all APIs from Amplify to EC2. Gateway Endpoint (S3, DynamoDB) and Interface Endpoint (Textract, Bedrock, SQS – if used) for EC2 to call AWS services without NAT Gateway. Amazon CloudWatch + Amazon SNS: Collects logs and metrics from EC2, ALB, SQS. CloudWatch Alarms send alerts via SNS when CPU is high, SQS backlog, worker errors, etc. AWS CodePipeline / CodeBuild: Automates build \u0026amp; deploy for backend (FastAPI on EC2). Component Design\nUsers: Researchers: Q\u0026amp;A, academic content lookup. Dev/Admin: Upload, manage, and re-index documents. Document Processing (IDP): PDFs uploaded by Dev/Admin to S3. Worker on EC2 calls Textract for OCR and text/table extraction. Indexing \u0026amp; Vector DB: Worker normalizes, chunks content. Calls Bedrock Titan Embeddings v2 to create embeddings. Saves embeddings + metadata to Qdrant on EC2. AI Conversation (RAG): FastAPI embeds question, queries Qdrant for top-k relevant segments. Sends context + question to Claude 3.5 Sonnet (Bedrock) to generate answer with citation. User Management: Cognito authenticates and authorizes researcher / admin. Storage \u0026amp; State: DynamoDB stores document metadata (doc_id, status, owner, …) and (optional) chat history. 4. Technical Implementation Implementation Phases The project consists of 2 main parts — web platform (UI + auth) and RAG + IDP backend — deployed across 4 phases:\nResearch \u0026amp; Architecture Finalization: Review requirements (50 researchers, 1 EC2, IDP + RAG). Finalize architecture: VPC, EC2 (FastAPI + Qdrant + Worker), Amplify, Cognito, S3, SQS, DynamoDB, Textract, Bedrock. POC \u0026amp; Connectivity Check: Create EC2, VPC endpoints, test calling Textract, Titan Embeddings, Claude 3.5 Sonnet. Run simple Qdrant on EC2, test vector insert/search. Create skeleton FastAPI + a minimal Chat UI on Amplify. Feature Completion: Build /api/chat (FastAPI) + RAG pipeline: embed query → Qdrant → Claude + citation. Build /api/admin/: upload PDF, save to S3 + DynamoDB, push message to SQS. Write Worker on EC2: SQS → Textract → normalize/chunk → Titan → Qdrant → update DynamoDB. Complete Chat UI and Admin UI (upload + view document status). Testing, Optimization, Internal Demo Deployment: End-to-end test with a set of ~50–100 papers. Add CloudWatch Logs/Alarms, SNS notify on error or queue backlog. Adjust EC2, Qdrant configuration, batch size to optimize time and cost. Prepare user guide and demo for the group of 50 researchers. Technical Requirements\nFrontend \u0026amp; Auth: React/Next.js hosted on AWS Amplify, CloudFront CDN, Route 53 DNS. Amazon Cognito manages identity and permissions (Researcher/Admin). Backend \u0026amp; Compute: EC2 t3.small (Private Subnet) running All-in-one: FastAPI, Qdrant Vector DB, and Worker. Asynchronous processing: Worker reads SQS, triggers Textract and Bedrock to index data. IDP \u0026amp; RAG: Storage: S3 (Original files), DynamoDB (Metadata \u0026amp; Status). AI Core: Textract (OCR scanned docs), Bedrock Titan (Embedding), Claude 3.5 Sonnet (Question Answering). Network \u0026amp; Observability: Network: VPC Private Subnet, VPC Endpoints for secure connection to AWS Services. Monitoring: CloudWatch Logs/Metrics + SNS alerts (High CPU, Worker errors). 5. Timeline \u0026amp; Milestones The project is executed over approximately 6 weeks with specific phases:\nWeek 1-2 (Days 1-10): Research \u0026amp; Design Detailed architecture design, scope definition, service selection. Planning for operational cost optimization and deployment. Week 3 (Days 11-15): AWS Infrastructure Setup Configure VPC, Subnets, Security Groups, IAM Roles. Deploy EC2 t3.small, S3 bucket, DynamoDB tables. Setup VPC Endpoints (Gateway + Interface). Week 4 (Days 16-20): Backend APIs \u0026amp; IDP Pipeline Build FastAPI endpoints (/api/chat, /api/admin/upload). Integrate IDP pipeline: SQS → Worker → Textract → Embeddings → Qdrant. Connect Bedrock (Titan Embeddings + Claude 3.5 Sonnet). Week 5 (Days 21-25): Testing \u0026amp; Error Handling End-to-end testing with a set of ~50-100 papers. Handle edge cases, retry logic, error handling. Optimize chunking strategy and retrieval accuracy. Week 6 (Days 26-30): Deployment \u0026amp; Documentation Finalize UI/UX for Admin and Researcher. Setup CloudWatch Alarms + SNS notifications. Prepare user guide and demo for the group of 50 researchers. 6. Budget Estimation You can view costs on the AWS Pricing Calculator Or download the Budget Estimation File.\nInfrastructure Costs (Estimated Monthly)\nFixed Infrastructure (~$40–45): Compute \u0026amp; Network: EC2 t3.small ($15) + VPC Endpoints ($20). Storage \u0026amp; Web: S3, DynamoDB, SQS, Amplify, CloudWatch (~$5–10). AI Costs (Variable): Amazon Textract: ~$15–25 (batch processing first 10,000 pages). Amazon Bedrock: $5–15 (serving 50 users). Total: **$50–60/month** for internal research environment. 7. Risk Assessment Risk Matrix\nHallucination (AI fabrication): High impact, medium probability. Budget Overrun (AI Services): Medium impact, medium probability. Infrastructure Failure (EC2/Qdrant): High impact, low probability. Mitigation Strategies\nAI Quality: Mandatory source citations, limit input context from Qdrant. Cost: Set up AWS Budgets/Alarms, control document ingestion volume. Infrastructure \u0026amp; Security: Periodic EBS backups, data encryption (S3/DynamoDB), strict permissions via Cognito/IAM. Contingency Plans\nSystem Failure: Restore from Snapshot, pause ingestion (buffer via SQS). Cost Overrun: Temporarily lock new uploads, limit daily query quotas. 8. Expected Outcomes Technical Improvements\nTransform scattered document repositories (PDF/Scan) into digital knowledge queryable and automatically citable. Significantly reduce manual search time thanks to RAG + IDP technology. Long-term Value\nBuild a digitized research platform for 50+ researchers, easily scalable. Create a foundation for advanced features: Document recommendations, research trend analysis, and Literature Review support. "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.3-s3-vpc/","title":"Access S3 from VPC","tags":[],"description":"","content":"Using Gateway endpoint In this section, you will create a Gateway eendpoint to access Amazon S3 from an EC2 instance. The Gateway endpoint will allow upload an object to S3 buckets without using the Public Internet. To create an endpoint, you must specify the VPC in which you want to create the endpoint, and the service (in this case, S3) to which you want to establish the connection.\nContent Create gateway endpoint Test gateway endpoint "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Test the Interface Endpoint","tags":[],"description":"","content":"Get the regional DNS name of S3 interface endpoint From the Amazon VPC menu, choose Endpoints.\nClick the name of newly created endpoint: s3-interface-endpoint. Click details and save the regional DNS name of the endpoint (the first one) to your text-editor for later use.\nConnect to EC2 instance in \u0026ldquo;VPC On-prem\u0026rdquo; Navigate to Session manager by typing \u0026ldquo;session manager\u0026rdquo; in the search box\nClick Start Session, and select the EC2 instance named Test-Interface-Endpoint. This EC2 instance is running in \u0026ldquo;VPC On-prem\u0026rdquo; and will be used to test connectivty to Amazon S3 through the Interface endpoint we just created. Session Manager will open a new browser tab with a shell prompt: sh-4.2 $\nChange to the ssm-user\u0026rsquo;s home directory with command \u0026ldquo;cd ~\u0026rdquo;\nCreate a file named testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file to the same S3 bucket we created in section 3.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; This command requires the \u0026ndash;endpoint-url parameter, because you need to use the endpoint-specific DNS name to access S3 using an Interface endpoint. Do not include the leading \u0026rsquo; * \u0026rsquo; when copying/pasting the regional DNS name. Provide your S3 bucket name created earlier Now the file has been added to your S3 bucket. Let check your S3 bucket in the next step.\nCheck Object in S3 bucket Navigate to S3 console Click Buckets Click the name of your bucket and you will see testfile2.xyz has been added to your bucket "},{"uri":"https://khanguyense.github.io/fcj_workshop/4-eventparticipated/4.2-event2/","title":"Event 3","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\u0026rdquo; Purpose of the Workshop Provide an overview of the AI/ML/GenAI ecosystem on AWS, focusing on the most important services. Equip attendees with practical knowledge of the AI/ML workflow—from data preparation to model training and deployment using Amazon SageMaker. Introduce the application of Generative AI with Amazon Bedrock, including prompt engineering, RAG, and building automation agents. Create an environment for students and developers to connect and exchange real-world AI/ML experience on the cloud. Speakers / Instructors (According to the workshop program) Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Trần Thị Minh Anh – Senior AI/ML Specialist Solutions Architect, AWS Lê Quang Huy – Cloud Engineer \u0026amp; AI Enthusiast Key Content \u0026amp; Learnings 1. Overview of AWS AI/ML/GenAI Ecosystem Vietnam landscape: AI adoption is growing rapidly; demand for AI/ML and cloud-skilled engineers continues to rise. Learning roadmap: From foundational courses to advanced certifications, emphasizing hands-on practice. Three service groups: AI Services (ready-to-use), ML Services (customizable), and Generative AI (opening new possibilities). 2. Amazon SageMaker – A Complete ML Platform Supports the entire ML lifecycle in a single platform. SageMaker Studio provides an integrated development environment that accelerates model development. Enables MLOps, training automation, hyperparameter tuning, and model deployment. 3. Generative AI with Amazon Bedrock Offers multiple Foundation Models such as Claude, Llama, and Titan for different tasks. Advanced Prompt Engineering: using Chain-of-Thought, few-shot techniques for improved output quality. RAG (Retrieval-Augmented Generation): combines LLMs with private data to reduce hallucination and expand knowledge scope. Bedrock Agents: enable models to perform multi-step tasks and interact with external systems. Guardrails: ensure safe content and compliance. Key Takeaways Technology Insights SageMaker is not just a training tool but a comprehensive ML lifecycle management platform. Effective Generative AI relies on the combination of models, prompt techniques, and supporting architectures like RAG. Data remains the most critical factor influencing model quality. Mindset \u0026amp; Methodology Start with real-world problems instead of chasing technology trends. Apply an iterative approach: fast prototyping → gather feedback → improve. Always evaluate cost to ensure project feasibility. Practical Skills Prompt engineering requires continuous practice. Proficiency in AWS Console/SDK is essential for building real-world AI products. Personal Action Plan After the Workshop Practice using AWS Free Tier — start with SageMaker Studio Lab to explore ML workflows. Build a first GenAI application — for example, creating a simple chatbot using Amazon Bedrock. Deepen learning through AWS Skill Builder — complete learning paths for ML and Generative AI. Join Vietnam AI/ML communities to stay updated with case studies and hands-on knowledge. Personal Experience at the Event The “AI/ML/GenAI on AWS” workshop provided a clearer and more practical perspective on how to approach AI in a professional direction. The modern AWS office environment, the enthusiasm of the speakers, and their easy-to-understand explanations made the content very engaging.\nThe live demo was the most impressive part. Seeing Ms. Minh Anh build a working RAG system and Bedrock Agent in a short time made me realize how accessible AI prototyping has become when using the right tools.\nInsights about cost management and MLOps were especially valuable—they helped me understand that AI is not just about building a model, but also about managing, monitoring, and optimizing it continuously.\nAfter the workshop, I feel more confident in pursuing AI/ML on AWS, as I now have a clearer and more practical roadmap to follow.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":" ⚠️ Note: The information below is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nThis section will list and introduce the blogs you have translated. For example:\nBlog 1 - Getting started with healthcare data lakes: Using microservices This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 2 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 3 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 4 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 5 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 6 - \u0026hellip; This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Deepen understanding of AWS IAM access control: Users, Groups, Policies, and Roles. Learn how to design and implement secure access patterns using IAM Roles and least privilege. Practice creating IAM Groups, Users, Roles and configuring role switching scenarios. Understand core Amazon VPC networking concepts: Subnets, Route Tables, Internet Gateway, NAT Gateway. Get hands-on experience with VPC security (Security Groups, Network ACLs) and an introduction to Site-to-Site VPN. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Study IAM access control overview + IAM Users \u0026amp; IAM Groups + IAM Policies + IAM Roles - Review security objectives and principle of least privilege 09/23/2025 09/23/2025 https://000002.awsstudygroup.com/ 2 - Hands-on IAM (1): + Create Admin IAM Group + Create Admin User and add to group + Login as Admin User and verify permissions 09/24/2025 09/24/2025 https://000002.awsstudygroup.com/ 3 - Hands-on IAM (2): + Create Admin Role + Create OperatorUser + Configure trust relationships for role switching + Test “Switch Role” from OperatorUser + Review and clean up config 09/25/2025 09/25/2025 https://000002.awsstudygroup.com/ 4 - Study Amazon VPC fundamentals: + Subnets + Route Tables + Internet Gateway + NAT Gateway - Learn VPC security components: + Security Groups + Network ACLs 09/26/2025 09/26/2025 https://000003.awsstudygroup.com/ 5 - Hands-on VPC \u0026amp; Networking: + Create VPC, Subnets, Internet Gateway, Route Tables, Security Groups + Enable VPC Flow Logs + Launch EC2 instance in VPC and test connectivity + Read through Site-to-Site VPN setup steps 09/27/2025 09/27/2025 https://000003.awsstudygroup.com/ Week 3 Achievements: Gained a solid understanding of IAM access control concepts:\nIAM Users and IAM Groups IAM Policies (permission-based access) IAM Roles and trust relationships Implemented a basic IAM administrative structure:\nCreated Admin Group and Admin User Verified permissions using group-based policies Practiced advanced IAM patterns:\nCreated Admin Role and OperatorUser Configured and tested “Switch Role” flows Applied the principle of least privilege when assigning permissions Understood Amazon VPC core components:\nSubnets, Route Tables, Internet Gateway, NAT Gateway Security Groups vs. Network ACLs Built a small VPC environment:\nCreated VPC, subnets, routing, and security layers Launched EC2 instance inside VPC and verified connectivity Enabled VPC Flow Logs for traffic visibility Reviewed the overall steps to set up AWS Site-to-Site VPN for hybrid connectivity.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.4-s3-onprem/","title":"Access S3 from on-premises","tags":[],"description":"","content":"Overview In this section, you will create an Interface endpoint to access Amazon S3 from a simulated on-premises environment. The Interface endpoint will allow you to route to Amazon S3 over a VPN connection from your simulated on-premises environment.\nWhy using Interface endpoint:\nGateway endpoints only work with resources running in the VPC where they are created. Interface endpoints work with resources running in VPC, and also resources running in on-premises environments. Connectivty from your on-premises environment to the cloud can be provided by AWS Site-to-Site VPN or AWS Direct Connect. Interface endpoints allow you to connect to services powered by AWS PrivateLink. These services include some AWS services, services hosted by other AWS customers and partners in their own VPCs (referred to as PrivateLink Endpoint Services), and supported AWS Marketplace Partner services. For this workshop, we will focus on connecting to Amazon S3. "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"On-premises DNS Simulation","tags":[],"description":"","content":"AWS PrivateLink endpoints have a fixed IP address in each Availability Zone where they are deployed, for the life of the endpoint (until it is deleted). These IP addresses are attached to Elastic Network Interfaces (ENIs). AWS recommends using DNS to resolve the IP addresses for endpoints so that downstream applications use the latest IP addresses when ENIs are added to new AZs, or deleted over time.\nIn this section, you will create a forwarding rule to send DNS resolution requests from a simulated on-premises environment to a Route 53 Private Hosted Zone. This section leverages the infrastructure deployed by CloudFormation in the Prepare the environment section.\nCreate DNS Alias Records for the Interface endpoint Navigate to the Route 53 management console (Hosted Zones section). The CloudFormation template you deployed in the Prepare the environment section created this Private Hosted Zone. Click on the name of the Private Hosted Zone, s3.us-east-1.amazonaws.com: Create a new record in the Private Hosted Zone: Record name and record type keep default options Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor (you saved when doing section 4.3) Click Add another record, and add a second record using the following values. Click Create records when finished to create both records. Record name: *. Record type: keep default value (type A) Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor The new records appear in the Route 53 console:\nCreate a Resolver Forwarding Rule Route 53 Resolver Forwarding Rules allow you to forward DNS queries from your VPC to other sources for name resolution. Outside of a workshop environment, you might use this feature to forward DNS queries from your VPC to DNS servers running on-premises. In this section, you will simulate an on-premises conditional forwarder by creating a forwarding rule that forwards DNS queries for Amazon S3 to a Private Hosted Zone running in \u0026ldquo;VPC Cloud\u0026rdquo; in-order to resolve the PrivateLink interface endpoint regional DNS name.\nFrom the Route 53 management console, click Inbound endpoints on the left side bar In the Inbound endpoints console, click the ID of the inbound endpoint Copy the two IP addresses listed to your text editor From the Route 53 menu, choose Resolver \u0026gt; Rules, and click Create rule: In the Create rule console: Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: Enter both IP addresses from your text editor (inbound endpoint addresses) and then click Submit You have successfully created resolver forwarding rule.\nTest the on-premises DNS Simulation Connect to Test-Interface-Endpoint EC2 instance with Session manager Test DNS resolution. The dig command will return the IP addresses assigned to the VPC Interface endpoint running in VPC Cloud (your IP\u0026rsquo;s will be different): dig +short s3.us-east-1.amazonaws.com The IP addresses returned are the VPC endpoint IP addresses, NOT the Resolver IP addresses you pasted from your text editor. The IP addresses of the Resolver endpoint and the VPC endpoint look similar because they are all from the VPC Cloud CIDR block.\nNavigate to the VPC menu (Endpoints section), select the S3 Interface endpoint. Click the Subnets tab and verify that the IP addresses returned by Dig match the VPC endpoint: Return to your shell and use the AWS CLI to test listing your S3 buckets: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Terminate your Session Manager session: In this section you created an Interface endpoint for Amazon S3. This endpoint can be reached from on-premises through Site-to-Site VPN or AWS Direct Connect. Route 53 Resolver outbound endpoints simulated forwarding DNS requests from on-premises to a Private Hosted Zone running the cloud. Route 53 inbound Endpoints recieved the resolution request and returned a response containing the IP addresses of the VPC interface endpoint. Using DNS to resolve the endpoint IP addresses provides high availability in-case of an Availability Zone outage.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/4-eventparticipated/4.3-event3/","title":"Event 4","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AWS Cloud Mastery Series #2: DevOps on AWS\u0026rdquo; Purpose of the Workshop Provide a comprehensive overview of DevOps culture, principles, and practices on AWS. Demonstrate how to build a complete CI/CD pipeline—from source control to automated deployment. Introduce major Infrastructure as Code (IaC) tools on AWS and their practical applications. Equip attendees with knowledge on containerization, observability, and operational best practices. Speakers / Main Instructors (Expected) Đỗ Huy Thắng – DevOps Lead, VNG Nguyễn Thị Thu Hà – Senior DevOps Engineer, AWS Phạm Tuấn Anh – Solutions Architect, AWS Key Topics \u0026amp; Learnings 1. DevOps Culture \u0026amp; Core Principles DevOps is not just about tools—it represents a collaborative culture between Development and Operations. DORA metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) are critical indicators of DevOps performance. Shift-left Testing \u0026amp; Security helps detect issues earlier and reduce remediation cost. 2. CI/CD Pipeline on AWS AWS DevTools (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) enable fully automated release workflows. Deployment strategies include Blue/Green, Canary, and Rolling Updates. Live demonstration: commit → build → test → deploy to EC2/ECS. 3. Infrastructure as Code (IaC) AWS CloudFormation: declarative IaC using YAML/JSON templates. AWS CDK: imperative IaC using languages like Python or TypeScript, offering strong reusability. Drift Detection ensures infrastructure remains consistent with defined configurations. 4. Containers \u0026amp; Microservices Docker packages applications into lightweight, portable, isolated containers. Comparison of Amazon ECS vs Amazon EKS to choose the right orchestration tool. AWS App Runner offers serverless container deployment with minimal operational overhead. 5. Monitoring \u0026amp; Observability Amazon CloudWatch: metrics, logs, alarms, dashboards for real-time system health. AWS X-Ray: distributed tracing to analyze performance and identify latency bottlenecks. Best practices include meaningful alerts, dashboards aligned with SLOs, and a structured postmortem process. Key Takeaways Mindset \u0026amp; Culture DevOps is a continuous improvement journey. Automation is the backbone of DevOps. Adopt a “blameless postmortem” mindset to learn from failures. Technical Knowledge CI/CD is about creating a reliable delivery workflow, not just running scripts. IaC enables consistency, version control, and environment reproducibility. Observability provides deeper insights into root cause analysis. Career Skills DevOps engineers need broad knowledge: networking, security, coding, system operations. Advanced debugging skills are essential for distributed systems. Personal Action Plan Build a personal CI/CD pipeline using CodeCommit \u0026amp; CodePipeline. Practice AWS CDK using Python to deploy core AWS resources. Package a small application into Docker and deploy it on ECS Fargate. Create a CloudWatch dashboard with essential metrics and alarms. Personal Reflection This workshop offered highly practical insights that developers often overlook.\nThe CI/CD and IaC demonstrations were particularly impressive, showing how automation reduces risk and accelerates release cycles.\nReal-world case studies from VNG and AWS emphasized the critical role of monitoring and DevOps culture.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I participated in five events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nDate \u0026amp; Time: 09:00 - 17:00 , September 18, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AI-Driven Development Life Cycle: Reimagining Software Engineering\nDate \u0026amp; Time: 14:00 - 16:30, October 3, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nDate \u0026amp; Time: 8:00 - 11:3, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #2\nDate \u0026amp; Time: 8:30 - 17:00, November 17, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #3\nDate \u0026amp; Time: 8:30 - 12:00, November 29, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Understand how to launch and manage both Windows and Linux EC2 instances. Learn how to deploy applications on EC2 (Node.js \u0026amp; AWS User Management App). Understand IAM governance and cost usage governance in EC2 environments. Learn how applications securely access AWS services using IAM roles instead of access keys. Practice attaching IAM roles to EC2 and testing application access. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Study EC2 introduction \u0026amp; preparation steps + EC2 concepts + Resources required + IAM \u0026amp; networking prerequisites 09/30/2025 09/30/2025 https://000004.awsstudygroup.com/ 2 - Launch EC2 instances: + Launch Windows Server 2022 instance + Launch Amazon Linux instance + Connect and validate OS-level access 10/01/2025 10/01/2025 https://000004.awsstudygroup.com/ 3 - Deploy applications on EC2: + Deploy AWS User Management App on Amazon Linux + Deploy Node.js application on Windows EC2 10/02/2025 10/02/2025 https://000004.awsstudygroup.com/ 4 - IAM Governance \u0026amp; Authorization: + Understand cost \u0026amp; usage governance with IAM + Compare Access Key vs IAM Role + Learn risks of long-term access keys 10/03/2025 10/03/2025 https://000048.awsstudygroup.com/ 5 - IAM Role Hands-on: + Create IAM Role for EC2 + Attach IAM Role to EC2 instance + Test application accessing AWS services via IAM Role + Clean up resources 10/04/2025 10/04/2025 https://000048.awsstudygroup.com/ Week 4 Achievements: Successfully launched both Windows and Linux EC2 instances. Understood how to prepare and configure an EC2 environment for application deployment. Deployed two applications: AWS User Management Application on Linux Node.js Application on Windows Learned about IAM governance and how permissions affect cost and security. Understood why Access Keys should not be used for applications. Created and attached IAM Roles to EC2 for secure access to AWS services. Verified application access using IAM Role-based credentials. Cleaned up all unused resources to avoid unnecessary costs. "},{"uri":"https://khanguyense.github.io/fcj_workshop/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Next Step: Create Your Workspace \u0026amp; Connect Your Cloud Your workspace is the control center where you\u0026rsquo;ll:\nConnect cloud accounts Monitor spending Get AI-powered savings recommendations "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"When you create an interface or gateway endpoint, you can attach an endpoint policy to it that controls access to the service to which you are connecting. A VPC endpoint policy is an IAM resource policy that you attach to an endpoint. If you do not attach a policy when you create an endpoint, AWS attaches a default policy for you that allows full access to the service through the endpoint.\nYou can create a policy that restricts access to specific S3 buckets only. This is useful if you only want certain S3 Buckets to be accessible through the endpoint.\nIn this section you will create a VPC endpoint policy that restricts access to the S3 bucket specified in the VPC endpoint policy.\nConnect to an EC2 instance and verify connectivity to S3 Start a new AWS Session Manager session on the instance named Test-Gateway-Endpoint. From the session, verify that you can list the contents of the bucket you created in Part 1: Access S3 from VPC: aws s3 ls s3://\\\u0026lt;your-bucket-name\\\u0026gt; The bucket contents include the two 1 GB files uploaded in earlier.\nCreate a new S3 bucket; follow the naming pattern you used in Part 1, but add a \u0026lsquo;-2\u0026rsquo; to the name. Leave other fields as default and click create Successfully create bucket\nNavigate to: Services \u0026gt; VPC \u0026gt; Endpoints, then select the Gateway VPC endpoint you created earlier. Click the Policy tab. Click Edit policy. The default policy allows access to all S3 Buckets through the VPC endpoint.\nIn Edit Policy console, copy \u0026amp; Paste the following policy, then replace yourbucketname-2 with your 2nd bucket name. This policy will allow access through the VPC endpoint to your new bucket, but not any other bucket in Amazon S3. Click Save to apply the policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Successfully customize policy\nFrom your session on the Test-Gateway-Endpoint instance, test access to the S3 bucket you created in Part 1: Access S3 from VPC aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy:\nReturn to your home directory on your EC2 instance cd~ Create a file fallocate -l 1G test-bucket2.xyz Copy file to 2nd bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; This operation succeeds because it is permitted by the VPC endpoint policy.\nThen we test access to the first bucket by copy the file to 1st bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy.\nPart 3 Summary: In this section, you created a VPC endpoint policy for Amazon S3, and used the AWS CLI to test the policy. AWS CLI actions targeted to your original S3 bucket failed because you applied a policy that only allowed access to the second bucket you created. AWS CLI actions targeted for your second bucket succeeded because the policy allowed them. These policies can be useful in situations where you need to control access to resources through VPC endpoints.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/","title":"Workshop","tags":[],"description":"","content":" ⚠️ Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nSecure Hybrid Access to S3 using VPC Endpoints Overview AWS PrivateLink provides private connectivity to AWS services from VPCs and your on-premises networks, without exposing your traffic to the Public Internet.\nIn this lab, you will learn how to create, configure, and test VPC endpoints that enable your workloads to reach AWS services without traversing the Public Internet.\nYou will create two types of endpoints to access Amazon S3: a Gateway VPC endpoint, and an Interface VPC endpoint. These two types of VPC endpoints offer different benefits depending on if you are accessing Amazon S3 from the cloud or your on-premises location\nGateway - Create a gateway endpoint to send traffic to Amazon S3 or DynamoDB using private IP addresses.You route traffic from your VPC to the gateway endpoint using route tables. Interface - Create an interface endpoint to send traffic to endpoint services that use a Network Load Balancer to distribute traffic. Traffic destined for the endpoint service is resolved using DNS. Content Workshop overview Prerequiste Access S3 from VPC Access S3 from On-premises VPC Endpoint Policies (Bonus) Clean up "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Learn the core components of EC2 and how compute operates in AWS. Understand Auto Scaling, EBS, Instance Store, User Data, Metadata. Practice backup, Storage Gateway, and deploying EC2 for storage-related use cases. Tasks to be carried out this week: Day Task Start Date End Date Reference 2 - Learn about EC2, instance types, AMI, key pair - Understand EBS, Instance Store, User Data, Metadata 06/10/2025 06/10/2025 https://youtu.be/-t5h4N6vfBs?si=GeVdhO9IEDjzzS_D https://youtu.be/e7XeKdOVq40?si=T3I4pgPoEfVytcU3 https://youtu.be/yAR6QRT3N1k?si=GQghyBwLCpijrDON https://youtu.be/hKr_TfGP7NY?si=gR2MqaLAFrqL-KBo https://youtu.be/6IHNDJ85aoQ?si=M0puk6DJpliO7ahf https://youtu.be/_v_43Wi7zjo?si=qNDVWzKcQFNO2mGh https://youtu.be/Ew3QRaKJQSA?si=xNvXvD8yFhnSMJby 3 - Understand EC2 Auto Scaling and how VM scaling works - Learn about storage and compute services (EFS/FSx, Lightsail, MGN overview) 07/10/2025 07/10/2025 https://youtu.be/bbLcPitXJSY?si=eyVnxvL9ho0LpUYy https://youtu.be/hFVYG8WqfU0?si=9Px4wmR4IRZxk15n 4 - Hands-on: + Deploy AWS Backup + Create backup plan + Test restore \u0026amp; cleanup + Clean up backup 08/10/2025 08/10/2025 https://000013.awsstudygroup.com 5 - Hands-on: + Create an S3 bucket for Storage Gateway + Create EC2 for Storage Gateway + Create Storage Gateway + File Share + Clean up Storage Gateway 09/10/2025 09/10/2025 https://000024.awsstudygroup.com 6 - Hands-on: + Create bucket, upload data + Enable static website hosting + Configure public access block + Configure CloudFront and test website + Clean up website + CloudFront + bucket 10/10/2025 10/10/2025 https://000057.awsstudygroup.com Week 5 Achievements: Summary:\nThis week I learned how EC2 operates, different instance storage types, Auto Scaling, and backup mechanisms. I also practiced Storage Gateway and deployed an S3 static website. Theory learned:\nEC2 architecture, AMI, key pair EBS vs Instance Store User Data / Metadata EC2 Auto Scaling Storage Gateway and fundamentals of AWS Backup Hands-on labs:\nCreate backup plan + test restore Create Storage Gateway + file share Deploy static website using S3 + CloudFront "},{"uri":"https://khanguyense.github.io/fcj_workshop/5-workshop/5.6-cleanup/","title":"Clean up","tags":[],"description":"","content":"Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "},{"uri":"https://khanguyense.github.io/fcj_workshop/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at Amazon Web Services Vietnam Company Limited from 08/09/2025 to 09/12/2025, I had the opportunity to learn, practice, and apply the knowledge I acquired at university in a real working environment.\nI participated in hands-on training and specialized workshops on AWS Cloud, through which I strengthened my skills in working with cloud services, technology analysis, technical reporting, and communication in a professional environment.\nRegarding work ethic, I consistently strived to complete assigned tasks, complied with company policies, and actively communicated with colleagues to improve work efficiency.\nTo objectively reflect on my internship experience, I provide the following self-evaluation:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, tool proficiency, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Self-learning, taking on tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring work quality ☐ ✅ ☐ 5 Discipline Compliance with schedules, regulations, and work processes ✅ ☐ ☐ 6 Willingness to improve Openness to feedback and continuous self-development ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and contributing to team activities ✅ ☐ ☐ 9 Professional conduct Respectful behavior toward colleagues, partners, and the workplace environment ✅ ☐ ☐ 10 Problem-solving skills Identifying issues, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to projects/organization Work effectiveness, improvement initiatives, and recognition from the team ☐ ✅ ☐ 12 Overall performance General assessment of the entire internship period ✅ ☐ ☐ Strengths Quick learner with the ability to acquire new knowledge efficiently. Strong adherence to work principles and guidelines. Responsible in completing assigned tasks. Friendly, cooperative, and supportive in team environments. Areas for Improvement Communication confidence: Need to be more proactive and confident in communication. Deep problem exploration: Improve the ability to analyze issues deeply instead of focusing only on surface-level solutions. Development Plan Create a detailed study and practice schedule to improve learning efficiency. Actively participate in discussions to enhance communication confidence and presentation skills. "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Learn the overview of AWS storage services (S3, Glacier, Backup, Storage Gateway, Snow Family). Understand how S3 works: access point, storage class, CORS, static website hosting. Practice the entire workflow with S3, Backup, Storage Gateway, and File Systems. Tasks to be carried out this week: Day Task Start Date End Date Reference 2 - Learn the overview of AWS storage services: S3, EBS, Backup, Storage Gateway, Snow Family - Study Access Point, Storage Class, and data access models - Understand S3 static website, CORS, Object key, Glacier 13/10/2025 13/10/2025 https://youtu.be/hsCfP0IxoaM?si=O3vMWs7Trr1fugJD https://youtu.be/_yunukwcAwc?si=ZhkTKr-_OkyUNImI https://youtu.be/mPBjB6Ltl_Q?si=qs6j0n7AeD2Mxwbz https://youtu.be/YXn8Q_Hpsu4?si=XojTnkR_LLC1KwEv 3 Hands-on: + Create S3 bucket + Deploy backup infrastructure + Create backup plan and set notification + Test restore \u0026amp; clean up backup resources 14/10/2025 14/10/2025 https://000013.awsstudygroup.com 4 - Learn VMware Workstation - Hands-on: + Export VM from on-prem + Upload VM to AWS + Import as EC2 + Export back as AMI + Clean up import/export environment 15/10/2025 15/10/2025 https://000014.awsstudygroup.com 5 - Hands-on: + Create Storage Gateway + Create advanced File Share + Connect File Share from on-prem machine + Clean up Storage Gateway + File Shares 16/10/2025 16/10/2025 https://000024.awsstudygroup.com 6 - Hands-on (lab25): + Create FSx file system (SSD/HDD, Multi-AZ) + Create \u0026amp; configure file shares + Test \u0026amp; monitor performance + Manage user sessions + quotas - Hands-on (lab57): + Create bucket, upload data, enable static website + Configure public access + object permissions + Create \u0026amp; configure CloudFront distribution + Enable versioning \u0026amp; object replication - Clean up environment (lab25), bucket, CloudFront, replication 17/10/2025 17/10/2025 https://000025.awsstudygroup.com https://000057.awsstudygroup.com Week 6 Achievements: Summary:\nThis week I learned the AWS storage ecosystem including S3, Glacier, Backup, Storage Gateway, and file systems. I focused heavily on hands-on labs to understand data management, backup–restore, and AWS storage mechanisms. Theory learned:\nS3 Storage Class, Access Point, CORS Glacier, lifecycle, backup concepts Storage Gateway and file system architecture VM import/export Hands-on labs:\nBackup \u0026amp; restore Import on-prem VM into AWS Create Multi-AZ file system Create static website, CloudFront, versioning, replication Practice Storage Gateway – create file share, connect, test data transfer between on-prem and AWS "},{"uri":"https://khanguyense.github.io/fcj_workshop/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment at AWS through the FCJ program is highly professional and well-organized. The learning and working space is structured effectively, enabling me to focus and absorb knowledge efficiently. FCJ regularly organizes workshops, which help me expand my understanding and stay updated with the latest technologies available on AWS.\n2. Support from Mentor / Team Admin\nMy mentor provided detailed guidance, explained clearly whenever I did not fully understand, and consistently encouraged me to ask questions. I truly appreciate that the mentor let me try and solve problems on my own instead of giving me the answer immediately, which helped me become more proactive and improve quickly. The admin team was also very supportive, preparing all necessary documents and procedures to ensure a smooth working process. Whenever I had questions, both the mentor and admin team responded quickly and provided thorough explanations, motivating me throughout the internship.\n3. Relevance of Work to My Academic Major\nDuring the internship, I learned many important skills—from technical knowledge such as working with AWS services to soft skills like teamwork, presentation, and report writing. The sharing sessions from experts and FCJ members gave me new perspectives and valuable insights for shaping my future career development.\n4. Learning \u0026amp; Skill Development Opportunities\nThroughout the internship, I gained a wide range of new skills, including the use of project management tools, effective teamwork, and professional communication in a corporate setting. My mentor also shared a lot of practical experience that helped me build clearer career directions, especially in the DevOps and cloud domain.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously, yet maintains a friendly and enjoyable atmosphere. When urgent projects arise, everyone collaborates and supports one another regardless of their position or role. This helped me feel like a true part of the team, even though I was only an intern.\n6. Internship Policies / Benefits\nThe company offers an internship allowance and provides flexible working hours when necessary. Additionally, the opportunity to participate in internal training sessions, workshops, and knowledge-sharing activities is a major advantage that supports continuous learning.\nAdditional Questions What did you find most satisfying during your internship?\nI was most satisfied with the opportunity to work directly with DevOps and AWS tasks. Being able to deploy infrastructure, configure services, and troubleshoot real issues helped me improve quickly. I also learned a great deal about DevSecOps practices, including IAM management, CI/CD pipelines, and system operations.\nWhat do you think the company should improve for future interns?\nI think the program could include additional advanced DevOps workshops, such as building complete CI/CD pipelines, running incident simulation exercises, or conducting mini-projects in teams. This would help interns gain a deeper understanding of real-world system operations.\nIf recommending to a friend, would you suggest they intern here? Why or why not?\nYes, definitely! The program provides highly practical knowledge in DevOps and AWS, with hands-on experience rather than just theory. The mentors are supportive, the environment is professional yet friendly, and it is especially suitable for students pursuing a Cloud/DevOps career path.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience?\nI suggest adding more group practical exercises followed by a final consolidated project. This would help interns strengthen teamwork and apply knowledge in a more integrated manner.\nWould you like to continue this program in the future?\nIf given the opportunity, I would love to continue the program. I hope to take part in more advanced topics such as building complete DevOps systems, multi-environment CI/CD pipelines, and AWS cost optimization.\n"},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Learn the complete IAM system: user, group, role, policy, permission boundary. Understand AWS authentication \u0026amp; authorization mechanisms, how to write JSON policies, and how policy evaluation works. Get familiar with AWS Organizations, Organizational Units (OU), and Service Control Policies (SCP). Practice IAM + Organization labs to understand how large-scale account management works. Tasks to be carried out this week: Day Task Start Date End Date Reference 2 - Learn the IAM fundamentals: user, group, role, policy - Understand policy evaluation: explicit deny, implicit deny, allow 20/10/2025 20/10/2025 https://youtu.be/tsobAlSg19g?si=9f3mlIWPtrCcNuKg https://youtu.be/N_vlJGAqZxo?si=e8oiWCObco95CoKh 3 - Hands-on: + Create user/group/role + Attach inline \u0026amp; managed policies + Test S3/EC2 access under different policies - Learn permission boundaries and session policies 21/10/2025 21/10/2025 https://000028.awsstudygroup.com 4 - Study AWS Organizations: OU structure, multi-account setup - Understand SCP concepts, deny list vs allow list 22/10/2025 22/10/2025 https://youtu.be/5oQY8Rogz9Y?si=h8DlUb8ZLI4HbbvM https://youtu.be/NW1xrMkNMjU?si=dhT0T3y2JYVK8QwT 5 - Hands-on: + Create Organization + OU + Apply SCP deny EC2 / deny S3 + Verify SCP effectiveness combined with IAM policies + Rearrange OU, remove SCP 23/10/2025 23/10/2025 https://000030.awsstudygroup.com https://000044.awsstudygroup.com/ 6 - Team activity: + Discuss workshop ideas + Plan execution + Divide tasks for workshop 24/10/2025 24/10/2025 Week 7 Achievements: Summary:\nThis week I learned the foundation of AWS access management, including IAM and Organizations. I now understand how policy evaluation works, how to write JSON policies, and how SCPs apply across multi-account environments. Theory learned:\nConcepts of User – Group – Role – Policy and how evaluation works Inline policy, managed policy, permission boundary AWS Organizations structure, OU SCP concepts and differences compared to IAM policies Landing Zone \u0026amp; Control Tower overview Hands-on labs:\nCreate user/group/role and test different access levels Write JSON policies and test allow/deny behaviors Create Organization, OU, and apply SCP Validate SCP + IAM policy combinations in practice "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Learn about database systems on AWS: RDS, Aurora, Redshift, ElastiCache. Practice building a database subnet group, test connectivity, backup \u0026amp; restore. Learn data analytics services such as Kinesis, Glue, Athena, QuickSight. Tasks to be carried out this week: Day Task Start Date End Date Reference Materials 2 - Learn about Databases: RDS, Aurora, Redshift, ElastiCache - Learn about Multi-AZ architecture, read replicas, backup/restore 27/10/2025 27/10/2025 https://youtu.be/OOD2RwWuLRw?si=9JsOs0PNfO1TdAUl https://youtu.be/qbrobQZrokY?si=ePJjzYXWg3qE_Ca6 https://youtu.be/UvdiRW34aNI?si=8g3FwgsJ3VLT-_nf 3 - Practice: + Create VPC + SG for EC2 + RDS + Create DB subnet group + Deploy EC2 + Create RDS instance + Backup \u0026amp; Restore 28/10/2025 28/10/2025 https://000005.awsstudygroup.com 4 - Practice: + Connect to MSSQL/Oracle + Schema Conversion + Create DMS Task + Inspect logs, troubleshoot 29/10/2025 29/10/2025 https://000043.awsstudygroup.com 5 - Learn about Data Analytics (Kinesis, Glue, Athena, QuickSight) - Practice: + Create DynamoDB table + Enable autoscaling + CRUD test + Create Global Table and clean up resources 30/10/2025 30/10/2025 https://000039.awsstudygroup.com 6 - Practice (lab35): + Create S3 bucket + Create Kinesis Firehose ingestion + Glue crawler + Query data with Athena + Create QuickSight dashboard - Practice (lab40): + Check cost allocation + Tagging resources + Additional queries \u0026amp; resource cleanup 31/10/2025 31/10/2025 https://000035.awsstudygroup.com https://000040.awsstudygroup.com Week 8 Achievements: Overview:\nThis week, I focused on AWS database and data analytics services, including RDS, Aurora, DynamoDB, DMS, Kinesis, Glue, Athena, and QuickSight. I gained a solid understanding of database architecture, connectivity, backup/restore, autoscaling, as well as the end-to-end data analytics pipeline from ingestion -\u0026gt; ETL -\u0026gt; query -\u0026gt; visualization. Theory Learned:\nConcepts of RDS, Aurora architecture, Multi-AZ, read replicas Backup, snapshot, parameter group, option group DynamoDB: partition key, sort key, throughput, autoscaling, DAX Overview of Data Analytics: Kinesis Firehose, Glue crawler, Athena, QuickSight Database Migration concepts: schema conversion, DMS task Lab Practice:\nCreated VPC + security groups for EC2/RDS Created DB subnet group, deployed EC2 and RDS MySQL Performed Backup \u0026amp; Restore Connected to MSSQL/Oracle, practiced Schema Conversion \u0026amp; created DMS task Created DynamoDB table, enabled autoscaling, CRUD test, created Global Table \u0026amp; cleanup Built analytics pipeline: Kinesis Firehose -\u0026gt; S3, Glue crawler, Athena queries, and QuickSight dashboard Performed additional tasks: tagging, cost allocation, and resource cleanup "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Learn the overall Serverless architecture and its core components: API Gateway, Lambda, DynamoDB. Design the full application architecture: backend, frontend, authentication, security, and integrations. Explore the security and edge layer: CloudFront, Route 53, WAF. Learn the authentication system with Amazon Cognito and how tokens are issued for APIs. Analyze how CI/CD is implemented using CodePipeline, CodeBuild, GitLab, and IaC (CloudFormation). Learn AWS observability and monitoring systems: CloudWatch, X-Ray, SNS. Tasks to be carried out this week: Day Task Start Date End Date Reference Materials 2 - Learn Serverless architecture - API Gateway, Lambda, DynamoDB \u0026amp; integration mechanisms 03/11/2025 03/11/2025 3 - Design full architecture (BE + FE + Auth + Edge) - Draw architecture diagram \u0026amp; request flow 04/11/2025 04/11/2025 4 - Learn CloudFront, Route 53, WAF - Design security layer in front of API Gateway 05/11/2025 05/11/2025 5 - Learn Cognito (User Pool, Token) - Analyze how API Gateway validates JWT tokens 06/11/2025 06/11/2025 6 - Learn CI/CD: CloudFormation, CodePipeline, CodeBuild - Observability system: CloudWatch, X-Ray, SNS 07/11/2025 07/11/2025 Week 9 Achievements: Overview:\nThis week, I focused on understanding and designing the Serverless architecture for the application. I gained a solid understanding of how API Gateway – Lambda – DynamoDB work together, and explored the security layer using CloudFront/WAF as well as authentication via Cognito. I also learned the CI/CD workflow and logging/monitoring mechanisms to prepare for the coding phases in the upcoming weeks. Theory Learned:\nServerless architecture, pay-per-use model, and autoscaling principles. API Gateway REST API, Lambda integration, and DynamoDB table workflow. CloudFront + WAF + Route 53 for API protection. Cognito User Pool \u0026amp; Tokens (ID/Access), JWT flow through API Gateway authorizer. CI/CD with CodePipeline + CodeBuild + CloudFormation. CloudWatch logs/metrics, SNS alerts, tracing using X-Ray. Practice / Deliverables:\nFull system architecture diagram (BE – FE – Auth – Edge). Request flow from client -\u0026gt; CloudFront -\u0026gt; API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB. Security diagram: CDN, DNS, WAF, throttling \u0026amp; protection at API Gateway. Preliminary CI/CD pipeline design using CloudFormation \u0026amp; CodePipeline. Authentication flow design: Cognito -\u0026gt; API Gateway JWT Authorizer. "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Complete 100% of the Backend CRUD using .NET running on Aspire AppHost. Build and test the DynamoDB data model on the local environment (Docker). Integrate DynamoDB Local with NoSQL Workbench to validate the data model. Collaborate with the FE team to complete the basic UI and connect to local APIs. Prepare a solid foundation before moving into Week 11 (migrating code to Lambda + API Gateway). Tasks to be carried out this week: Day Task Start Date End Date Reference Materials 2 - Verify \u0026amp; reinstall BE environment: .NET SDK, Docker Desktop, NoSQL Workbench - Understand system architecture diagram and backend processing flow 10/11/2025 10/11/2025 3 - Set up DynamoDB Local using Docker - Connect \u0026amp; visualize via NoSQL Workbench, manually test CRUD operations 11/11/2025 11/11/2025 4 - Implement DAL/Repository using .NET + AWSSDK.DynamoDBv2 - Integrate DI into Aspire AppHost - Implement business logic in BLL 12/11/2025 12/11/2025 5 - Build CRUD API Controllers - Perform unit tests \u0026amp; integration tests in the local environment 13/11/2025 13/11/2025 6 - Collaborate with the FE team - Build basic UI (List/Create) - FE connects to Local API and performs end-to-end testing 14/11/2025 14/11/2025 Week 10 Achievements: Overview:\nThis week, I completed the entire backend running locally using Aspire AppHost, built the DynamoDB data model, tested CRUD operations, and integrated with the frontend. By ensuring a complete and stable local architecture and codebase, I established a strong foundation for transitioning to Lambda/API Gateway in Week 11. Theoretical knowledge acquired:\nDynamoDB data modeling based on Single-Table Design, Access Patterns, PK/SK. Knowledge about DynamoDB Local, NoSQL Workbench, Docker setup. Using AWSSDK.DynamoDBv2 in .NET and integrating Dependency Injection. Backend structure in ASP.NET (Controller -\u0026gt; BLL -\u0026gt; Repository). How FE calls local APIs, handles responses, and renders UI. Practical work / Deliverables:\nSet up DynamoDB Local using Docker and managed schema via NoSQL Workbench. Built Repository + BLL + Controllers using .NET 8 / Aspire AppHost. Completed 5–6 CRUD APIs (POST/GET/PUT/DELETE/List). Wrote unit tests for BLL and integration tests for API. FE team built List + Create UI and successfully tested with local API. "},{"uri":"https://khanguyense.github.io/fcj_workshop/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Complete the remaining FE interface together with the Frontend team. Coordinate end-to-end testing between FE and BE. Learn the overall deployment workflow of the system (API, FE, database, infrastructure) to gain general understanding, even if not directly responsible. Prepare the necessary notes for Week 12 (documentation \u0026amp; final summary). Tasks to be carried out this week: Day Task Start Date End Date Reference Materials 2 - Work with the FE team to complete the remaining UI components - Review API contract alignment between FE and BE 17/11/2025 17/11/2025 3 - FE integrates full CRUD API flows - Fix schema, payload, and status code mismatches during FE testing 18/11/2025 18/11/2025 4 - Perform full end-to-end testing: List -\u0026gt; Create -\u0026gt; Update -\u0026gt; Delete from FE to BE - Update response models/validations to match FE expectations 19/11/2025 19/11/2025 \u0026lt; \u0026gt; 5 - Learn the team’s deployment workflow (CI/CD, API Gateway, Lambda, S3 + CloudFront) - Take notes for Week 12 documentation 20/11/2025 20/11/2025 6 - Summarize FE and BE issues during the week - Review the entire BE codebase to prepare for deployment environment (even though not the one deploying) 21/11/2025 21/11/2025 Week 11 Achievements: Overview:\nThis week, I mainly collaborated with the FE team to finalize UI components and complete API integration. Since the backend was completed in Week 10, I helped fix issues, standardize API contracts, and conduct full end-to-end testing.\nAdditionally, I learned the team’s deployment workflow (Lambda, API Gateway, S3/CloudFront, CI/CD) to prepare documentation for Week 12. Theoretical knowledge acquired:\nHow FE calls CRUD APIs and debugs requests. API Contract: input/output schemas, error formats, status codes. Deployment workflow: .NET -\u0026gt; Lambda, API Gateway routing, FE build -\u0026gt; S3/CloudFront. Overview of CI/CD pipeline and how to prepare code for deployment (configs, logging). Practical work / Deliverables:\nCollaborated with FE to complete List/Create/Update/Delete screens. Adjusted backend according to FE requirements (schema, validation, status codes). Conducted full end-to-end testing between FE ↔ BE on local environment. Documented deployment workflow for use in Week 12. Compiled FE and BE issues and updated the team backlog. "},{"uri":"https://khanguyense.github.io/fcj_workshop/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://khanguyense.github.io/fcj_workshop/tags/","title":"Tags","tags":[],"description":"","content":""}]